import type { Model } from '../types.js';

export const modelsDev = [
  {
    id: "alibaba:qwen3-coder-plus",
    provider: "alibaba",
    vendorId: "qwen3-coder-plus",
    displayName: "Qwen3 Coder Plus",
    family: "qwen3-coder-plus",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1,"outputPerMTokens":5},
    pricingSource: "models.dev",
    aliases: ["alibaba/qwen3-coder-plus"],
    releasedAt: "2025-07-23",
    source: "https://www.alibabacloud.com/help/en/model-studio/models",
    contextSource: "https://www.alibabacloud.com/help/en/model-studio/models",
    verifiedAt: "2025-07-23",
  },
  {
    id: "amazon-bedrock:ai21.jamba-1-5-large-v1:0",
    provider: "amazon-bedrock",
    vendorId: "ai21.jamba-1-5-large-v1:0",
    displayName: "Jamba 1.5 Large",
    family: "ai21.jamba-1-5-large-v1:0",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":8},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/ai21.jamba-1-5-large-v1:0"],
    releasedAt: "2024-08-15",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-08-15",
  },
  {
    id: "amazon-bedrock:ai21.jamba-1-5-mini-v1:0",
    provider: "amazon-bedrock",
    vendorId: "ai21.jamba-1-5-mini-v1:0",
    displayName: "Jamba 1.5 Mini",
    family: "ai21.jamba-1-5-mini-v1:0",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.4},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/ai21.jamba-1-5-mini-v1:0"],
    releasedAt: "2024-08-15",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-08-15",
  },
  {
    id: "amazon-bedrock:amazon.nova-lite-v1:0",
    provider: "amazon-bedrock",
    vendorId: "amazon.nova-lite-v1:0",
    displayName: "Nova Lite",
    family: "amazon.nova-lite-v1:0",
    status: "stable",
    context: {"combinedMax":300000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.06,"outputPerMTokens":0.24},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/amazon.nova-lite-v1:0"],
    releasedAt: "2024-12-03",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-12-03",
  },
  {
    id: "amazon-bedrock:amazon.nova-micro-v1:0",
    provider: "amazon-bedrock",
    vendorId: "amazon.nova-micro-v1:0",
    displayName: "Nova Micro",
    family: "amazon.nova-micro-v1:0",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.035,"outputPerMTokens":0.14},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/amazon.nova-micro-v1:0"],
    releasedAt: "2024-12-03",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-12-03",
  },
  {
    id: "amazon-bedrock:amazon.nova-premier-v1:0",
    provider: "amazon-bedrock",
    vendorId: "amazon.nova-premier-v1:0",
    displayName: "Nova Premier",
    family: "amazon.nova-premier-v1:0",
    status: "stable",
    context: {"combinedMax":1000000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2.5,"outputPerMTokens":12.5},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/amazon.nova-premier-v1:0"],
    releasedAt: "2024-12-03",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-12-03",
  },
  {
    id: "amazon-bedrock:amazon.nova-pro-v1:0",
    provider: "amazon-bedrock",
    vendorId: "amazon.nova-pro-v1:0",
    displayName: "Nova Pro",
    family: "amazon.nova-pro-v1:0",
    status: "stable",
    context: {"combinedMax":300000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.8,"outputPerMTokens":3.2},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/amazon.nova-pro-v1:0"],
    releasedAt: "2024-12-03",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-12-03",
  },
  {
    id: "amazon-bedrock:anthropic.claude-3-5-haiku-20241022-v1:0",
    provider: "amazon-bedrock",
    vendorId: "anthropic.claude-3-5-haiku-20241022-v1:0",
    displayName: "Claude Haiku 3.5",
    family: "anthropic.claude-3-5-haiku-20241022-v1:0",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.8,"outputPerMTokens":4},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/anthropic.claude-3-5-haiku-20241022-v1:0"],
    releasedAt: "2024-10-22",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-10-22",
  },
  {
    id: "amazon-bedrock:anthropic.claude-3-5-sonnet-20240620-v1:0",
    provider: "amazon-bedrock",
    vendorId: "anthropic.claude-3-5-sonnet-20240620-v1:0",
    displayName: "Claude Sonnet 3.5",
    family: "anthropic.claude-3-5-sonnet-20240620-v1:0",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/anthropic.claude-3-5-sonnet-20240620-v1:0"],
    releasedAt: "2024-06-20",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-06-20",
  },
  {
    id: "amazon-bedrock:anthropic.claude-3-5-sonnet-20241022-v2:0",
    provider: "amazon-bedrock",
    vendorId: "anthropic.claude-3-5-sonnet-20241022-v2:0",
    displayName: "Claude Sonnet 3.5 v2",
    family: "anthropic.claude-3-5-sonnet-20241022-v2:0",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0"],
    releasedAt: "2024-10-22",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-10-22",
  },
  {
    id: "amazon-bedrock:anthropic.claude-3-7-sonnet-20250219-v1:0",
    provider: "amazon-bedrock",
    vendorId: "anthropic.claude-3-7-sonnet-20250219-v1:0",
    displayName: "Claude Sonnet 3.7",
    family: "anthropic.claude-3-7-sonnet-20250219-v1:0",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/anthropic.claude-3-7-sonnet-20250219-v1:0"],
    releasedAt: "2025-02-19",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2025-02-19",
  },
  {
    id: "amazon-bedrock:anthropic.claude-3-haiku-20240307-v1:0",
    provider: "amazon-bedrock",
    vendorId: "anthropic.claude-3-haiku-20240307-v1:0",
    displayName: "Claude Haiku 3",
    family: "anthropic.claude-3-haiku-20240307-v1:0",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.25,"outputPerMTokens":1.25},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/anthropic.claude-3-haiku-20240307-v1:0"],
    releasedAt: "2024-03-13",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-03-13",
  },
  {
    id: "amazon-bedrock:anthropic.claude-3-opus-20240229-v1:0",
    provider: "amazon-bedrock",
    vendorId: "anthropic.claude-3-opus-20240229-v1:0",
    displayName: "Claude Opus 3",
    family: "anthropic.claude-3-opus-20240229-v1:0",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/anthropic.claude-3-opus-20240229-v1:0"],
    releasedAt: "2024-02-29",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-02-29",
  },
  {
    id: "amazon-bedrock:anthropic.claude-3-sonnet-20240229-v1:0",
    provider: "amazon-bedrock",
    vendorId: "anthropic.claude-3-sonnet-20240229-v1:0",
    displayName: "Claude Sonnet 3",
    family: "anthropic.claude-3-sonnet-20240229-v1:0",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/anthropic.claude-3-sonnet-20240229-v1:0"],
    releasedAt: "2024-03-04",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-03-04",
  },
  {
    id: "amazon-bedrock:anthropic.claude-instant-v1",
    provider: "amazon-bedrock",
    vendorId: "anthropic.claude-instant-v1",
    displayName: "Claude Instant",
    family: "anthropic.claude-instant-v1",
    status: "stable",
    context: {"combinedMax":100000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.8,"outputPerMTokens":2.4},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/anthropic.claude-instant-v1"],
    releasedAt: "2023-03-01",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2023-03-01",
  },
  {
    id: "amazon-bedrock:anthropic.claude-opus-4-1-20250805-v1:0",
    provider: "amazon-bedrock",
    vendorId: "anthropic.claude-opus-4-1-20250805-v1:0",
    displayName: "Claude Opus 4.1",
    family: "anthropic.claude-opus-4-1-20250805-v1:0",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/anthropic.claude-opus-4-1-20250805-v1:0"],
    releasedAt: "2025-08-05",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2025-08-05",
  },
  {
    id: "amazon-bedrock:anthropic.claude-opus-4-20250514-v1:0",
    provider: "amazon-bedrock",
    vendorId: "anthropic.claude-opus-4-20250514-v1:0",
    displayName: "Claude Opus 4",
    family: "anthropic.claude-opus-4-20250514-v1:0",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/anthropic.claude-opus-4-20250514-v1:0"],
    releasedAt: "2025-05-22",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2025-05-22",
  },
  {
    id: "amazon-bedrock:anthropic.claude-sonnet-4-20250514-v1:0",
    provider: "amazon-bedrock",
    vendorId: "anthropic.claude-sonnet-4-20250514-v1:0",
    displayName: "Claude Sonnet 4",
    family: "anthropic.claude-sonnet-4-20250514-v1:0",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/anthropic.claude-sonnet-4-20250514-v1:0"],
    releasedAt: "2025-05-22",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2025-05-22",
  },
  {
    id: "amazon-bedrock:anthropic.claude-v2",
    provider: "amazon-bedrock",
    vendorId: "anthropic.claude-v2",
    displayName: "Claude 2",
    family: "anthropic.claude-v2",
    status: "stable",
    context: {"combinedMax":100000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":8,"outputPerMTokens":24},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/anthropic.claude-v2"],
    releasedAt: "2023-07-11",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2023-07-11",
  },
  {
    id: "amazon-bedrock:anthropic.claude-v2:1",
    provider: "amazon-bedrock",
    vendorId: "anthropic.claude-v2:1",
    displayName: "Claude 2.1",
    family: "anthropic.claude-v2:1",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":8,"outputPerMTokens":24},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/anthropic.claude-v2:1"],
    releasedAt: "2023-11-21",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2023-11-21",
  },
  {
    id: "amazon-bedrock:cohere.command-light-text-v14",
    provider: "amazon-bedrock",
    vendorId: "cohere.command-light-text-v14",
    displayName: "Command Light",
    family: "cohere.command-light-text-v14",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/cohere.command-light-text-v14"],
    releasedAt: "2023-11-01",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2023-11-01",
  },
  {
    id: "amazon-bedrock:cohere.command-r-plus-v1:0",
    provider: "amazon-bedrock",
    vendorId: "cohere.command-r-plus-v1:0",
    displayName: "Command R+",
    family: "cohere.command-r-plus-v1:0",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/cohere.command-r-plus-v1:0"],
    releasedAt: "2024-04-04",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-04-04",
  },
  {
    id: "amazon-bedrock:cohere.command-r-v1:0",
    provider: "amazon-bedrock",
    vendorId: "cohere.command-r-v1:0",
    displayName: "Command R",
    family: "cohere.command-r-v1:0",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.5,"outputPerMTokens":1.5},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/cohere.command-r-v1:0"],
    releasedAt: "2024-03-11",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-03-11",
  },
  {
    id: "amazon-bedrock:cohere.command-text-v14",
    provider: "amazon-bedrock",
    vendorId: "cohere.command-text-v14",
    displayName: "Command",
    family: "cohere.command-text-v14",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.5,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/cohere.command-text-v14"],
    releasedAt: "2023-11-01",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2023-11-01",
  },
  {
    id: "amazon-bedrock:deepseek.r1-v1:0",
    provider: "amazon-bedrock",
    vendorId: "deepseek.r1-v1:0",
    displayName: "DeepSeek-R1",
    family: "deepseek.r1-v1:0",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.35,"outputPerMTokens":5.4},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/deepseek.r1-v1:0"],
    releasedAt: "2025-01-20",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2025-05-29",
  },
  {
    id: "amazon-bedrock:meta.llama3-1-70b-instruct-v1:0",
    provider: "amazon-bedrock",
    vendorId: "meta.llama3-1-70b-instruct-v1:0",
    displayName: "Llama 3.1 70B Instruct",
    family: "meta.llama3-1-70b-instruct-v1:0",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.72,"outputPerMTokens":0.72},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/meta.llama3-1-70b-instruct-v1:0"],
    releasedAt: "2024-07-23",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-07-23",
  },
  {
    id: "amazon-bedrock:meta.llama3-1-8b-instruct-v1:0",
    provider: "amazon-bedrock",
    vendorId: "meta.llama3-1-8b-instruct-v1:0",
    displayName: "Llama 3.1 8B Instruct",
    family: "meta.llama3-1-8b-instruct-v1:0",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.22,"outputPerMTokens":0.22},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/meta.llama3-1-8b-instruct-v1:0"],
    releasedAt: "2024-07-23",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-07-23",
  },
  {
    id: "amazon-bedrock:meta.llama3-2-11b-instruct-v1:0",
    provider: "amazon-bedrock",
    vendorId: "meta.llama3-2-11b-instruct-v1:0",
    displayName: "Llama 3.2 11B Instruct",
    family: "meta.llama3-2-11b-instruct-v1:0",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.16,"outputPerMTokens":0.16},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/meta.llama3-2-11b-instruct-v1:0"],
    releasedAt: "2024-09-25",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-09-25",
  },
  {
    id: "amazon-bedrock:meta.llama3-2-1b-instruct-v1:0",
    provider: "amazon-bedrock",
    vendorId: "meta.llama3-2-1b-instruct-v1:0",
    displayName: "Llama 3.2 1B Instruct",
    family: "meta.llama3-2-1b-instruct-v1:0",
    status: "stable",
    context: {"combinedMax":131000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.1},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/meta.llama3-2-1b-instruct-v1:0"],
    releasedAt: "2024-09-25",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-09-25",
  },
  {
    id: "amazon-bedrock:meta.llama3-2-3b-instruct-v1:0",
    provider: "amazon-bedrock",
    vendorId: "meta.llama3-2-3b-instruct-v1:0",
    displayName: "Llama 3.2 3B Instruct",
    family: "meta.llama3-2-3b-instruct-v1:0",
    status: "stable",
    context: {"combinedMax":131000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.15},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/meta.llama3-2-3b-instruct-v1:0"],
    releasedAt: "2024-09-25",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-09-25",
  },
  {
    id: "amazon-bedrock:meta.llama3-2-90b-instruct-v1:0",
    provider: "amazon-bedrock",
    vendorId: "meta.llama3-2-90b-instruct-v1:0",
    displayName: "Llama 3.2 90B Instruct",
    family: "meta.llama3-2-90b-instruct-v1:0",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.72,"outputPerMTokens":0.72},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/meta.llama3-2-90b-instruct-v1:0"],
    releasedAt: "2024-09-25",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-09-25",
  },
  {
    id: "amazon-bedrock:meta.llama3-3-70b-instruct-v1:0",
    provider: "amazon-bedrock",
    vendorId: "meta.llama3-3-70b-instruct-v1:0",
    displayName: "Llama 3.3 70B Instruct",
    family: "meta.llama3-3-70b-instruct-v1:0",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.72,"outputPerMTokens":0.72},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/meta.llama3-3-70b-instruct-v1:0"],
    releasedAt: "2024-12-06",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-12-06",
  },
  {
    id: "amazon-bedrock:meta.llama3-70b-instruct-v1:0",
    provider: "amazon-bedrock",
    vendorId: "meta.llama3-70b-instruct-v1:0",
    displayName: "Llama 3 70B Instruct",
    family: "meta.llama3-70b-instruct-v1:0",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":2048},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2.65,"outputPerMTokens":3.5},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/meta.llama3-70b-instruct-v1:0"],
    releasedAt: "2024-07-23",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-07-23",
  },
  {
    id: "amazon-bedrock:meta.llama3-8b-instruct-v1:0",
    provider: "amazon-bedrock",
    vendorId: "meta.llama3-8b-instruct-v1:0",
    displayName: "Llama 3 8B Instruct",
    family: "meta.llama3-8b-instruct-v1:0",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":2048},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/meta.llama3-8b-instruct-v1:0"],
    releasedAt: "2024-07-23",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2024-07-23",
  },
  {
    id: "amazon-bedrock:meta.llama4-maverick-17b-instruct-v1:0",
    provider: "amazon-bedrock",
    vendorId: "meta.llama4-maverick-17b-instruct-v1:0",
    displayName: "Llama 4 Maverick 17B Instruct",
    family: "meta.llama4-maverick-17b-instruct-v1:0",
    status: "stable",
    context: {"combinedMax":1000000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.24,"outputPerMTokens":0.97},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/meta.llama4-maverick-17b-instruct-v1:0"],
    releasedAt: "2025-04-05",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2025-04-05",
  },
  {
    id: "amazon-bedrock:meta.llama4-scout-17b-instruct-v1:0",
    provider: "amazon-bedrock",
    vendorId: "meta.llama4-scout-17b-instruct-v1:0",
    displayName: "Llama 4 Scout 17B Instruct",
    family: "meta.llama4-scout-17b-instruct-v1:0",
    status: "stable",
    context: {"combinedMax":3500000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.17,"outputPerMTokens":0.66},
    pricingSource: "models.dev",
    aliases: ["amazon-bedrock/meta.llama4-scout-17b-instruct-v1:0"],
    releasedAt: "2025-04-05",
    source: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    contextSource: "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
    verifiedAt: "2025-04-05",
  },
  {
    id: "anthropic:claude-3-5-haiku-20241022",
    provider: "anthropic",
    vendorId: "claude-3-5-haiku-20241022",
    displayName: "Claude Haiku 3.5",
    family: "claude-3-5-haiku-20241022",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.8,"outputPerMTokens":4},
    pricingSource: "models.dev",
    aliases: ["anthropic/claude-3-5-haiku-20241022"],
    releasedAt: "2024-10-22",
    source: "https://docs.anthropic.com/en/docs/about-claude/models",
    contextSource: "https://docs.anthropic.com/en/docs/about-claude/models",
    verifiedAt: "2024-10-22",
  },
  {
    id: "anthropic:claude-3-5-sonnet-20240620",
    provider: "anthropic",
    vendorId: "claude-3-5-sonnet-20240620",
    displayName: "Claude Sonnet 3.5",
    family: "claude-3-5-sonnet-20240620",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["anthropic/claude-3-5-sonnet-20240620"],
    releasedAt: "2024-06-20",
    source: "https://docs.anthropic.com/en/docs/about-claude/models",
    contextSource: "https://docs.anthropic.com/en/docs/about-claude/models",
    verifiedAt: "2024-06-20",
  },
  {
    id: "anthropic:claude-3-5-sonnet-20241022",
    provider: "anthropic",
    vendorId: "claude-3-5-sonnet-20241022",
    displayName: "Claude Sonnet 3.5 v2",
    family: "claude-3-5-sonnet-20241022",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["anthropic/claude-3-5-sonnet-20241022"],
    releasedAt: "2024-10-22",
    source: "https://docs.anthropic.com/en/docs/about-claude/models",
    contextSource: "https://docs.anthropic.com/en/docs/about-claude/models",
    verifiedAt: "2024-10-22",
  },
  {
    id: "anthropic:claude-3-7-sonnet-20250219",
    provider: "anthropic",
    vendorId: "claude-3-7-sonnet-20250219",
    displayName: "Claude Sonnet 3.7",
    family: "claude-3-7-sonnet-20250219",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["anthropic/claude-3-7-sonnet-20250219"],
    releasedAt: "2025-02-19",
    source: "https://docs.anthropic.com/en/docs/about-claude/models",
    contextSource: "https://docs.anthropic.com/en/docs/about-claude/models",
    verifiedAt: "2025-02-19",
  },
  {
    id: "anthropic:claude-3-haiku-20240307",
    provider: "anthropic",
    vendorId: "claude-3-haiku-20240307",
    displayName: "Claude Haiku 3",
    family: "claude-3-haiku-20240307",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.25,"outputPerMTokens":1.25},
    pricingSource: "models.dev",
    aliases: ["anthropic/claude-3-haiku-20240307"],
    releasedAt: "2024-03-13",
    source: "https://docs.anthropic.com/en/docs/about-claude/models",
    contextSource: "https://docs.anthropic.com/en/docs/about-claude/models",
    verifiedAt: "2024-03-13",
  },
  {
    id: "anthropic:claude-3-opus-20240229",
    provider: "anthropic",
    vendorId: "claude-3-opus-20240229",
    displayName: "Claude Opus 3",
    family: "claude-3-opus-20240229",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["anthropic/claude-3-opus-20240229"],
    releasedAt: "2024-02-29",
    source: "https://docs.anthropic.com/en/docs/about-claude/models",
    contextSource: "https://docs.anthropic.com/en/docs/about-claude/models",
    verifiedAt: "2024-02-29",
  },
  {
    id: "anthropic:claude-3-sonnet-20240229",
    provider: "anthropic",
    vendorId: "claude-3-sonnet-20240229",
    displayName: "Claude Sonnet 3",
    family: "claude-3-sonnet-20240229",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["anthropic/claude-3-sonnet-20240229"],
    releasedAt: "2024-03-04",
    source: "https://docs.anthropic.com/en/docs/about-claude/models",
    contextSource: "https://docs.anthropic.com/en/docs/about-claude/models",
    verifiedAt: "2024-03-04",
  },
  {
    id: "anthropic:claude-opus-4-1-20250805",
    provider: "anthropic",
    vendorId: "claude-opus-4-1-20250805",
    displayName: "Claude Opus 4.1",
    family: "claude-opus-4-1-20250805",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["anthropic/claude-opus-4-1-20250805"],
    releasedAt: "2025-08-05",
    source: "https://docs.anthropic.com/en/docs/about-claude/models",
    contextSource: "https://docs.anthropic.com/en/docs/about-claude/models",
    verifiedAt: "2025-08-05",
  },
  {
    id: "anthropic:claude-opus-4-20250514",
    provider: "anthropic",
    vendorId: "claude-opus-4-20250514",
    displayName: "Claude Opus 4",
    family: "claude-opus-4-20250514",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["anthropic/claude-opus-4-20250514"],
    releasedAt: "2025-05-22",
    source: "https://docs.anthropic.com/en/docs/about-claude/models",
    contextSource: "https://docs.anthropic.com/en/docs/about-claude/models",
    verifiedAt: "2025-05-22",
  },
  {
    id: "anthropic:claude-sonnet-4-20250514",
    provider: "anthropic",
    vendorId: "claude-sonnet-4-20250514",
    displayName: "Claude Sonnet 4",
    family: "claude-sonnet-4-20250514",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["anthropic/claude-sonnet-4-20250514"],
    releasedAt: "2025-05-22",
    source: "https://docs.anthropic.com/en/docs/about-claude/models",
    contextSource: "https://docs.anthropic.com/en/docs/about-claude/models",
    verifiedAt: "2025-05-22",
  },
  {
    id: "azure:codex-mini",
    provider: "azure",
    vendorId: "codex-mini",
    displayName: "Codex Mini",
    family: "codex-mini",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.5,"outputPerMTokens":6},
    pricingSource: "models.dev",
    aliases: ["azure/codex-mini"],
    releasedAt: "2025-05-16",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2025-05-16",
  },
  {
    id: "azure:gpt-3.5-turbo-0125",
    provider: "azure",
    vendorId: "gpt-3.5-turbo-0125",
    displayName: "GPT-3.5 Turbo 0125",
    family: "gpt-3.5-turbo-0125",
    status: "stable",
    context: {"combinedMax":16384,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.5,"outputPerMTokens":1.5},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-3.5-turbo-0125"],
    releasedAt: "2024-01-25",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2024-01-25",
  },
  {
    id: "azure:gpt-3.5-turbo-0301",
    provider: "azure",
    vendorId: "gpt-3.5-turbo-0301",
    displayName: "GPT-3.5 Turbo 0301",
    family: "gpt-3.5-turbo-0301",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.5,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-3.5-turbo-0301"],
    releasedAt: "2023-03-01",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2023-03-01",
  },
  {
    id: "azure:gpt-3.5-turbo-0613",
    provider: "azure",
    vendorId: "gpt-3.5-turbo-0613",
    displayName: "GPT-3.5 Turbo 0613",
    family: "gpt-3.5-turbo-0613",
    status: "stable",
    context: {"combinedMax":16384,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":4},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-3.5-turbo-0613"],
    releasedAt: "2023-06-13",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2023-06-13",
  },
  {
    id: "azure:gpt-3.5-turbo-1106",
    provider: "azure",
    vendorId: "gpt-3.5-turbo-1106",
    displayName: "GPT-3.5 Turbo 1106",
    family: "gpt-3.5-turbo-1106",
    status: "stable",
    context: {"combinedMax":16384,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-3.5-turbo-1106"],
    releasedAt: "2023-11-06",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2023-11-06",
  },
  {
    id: "azure:gpt-3.5-turbo-instruct",
    provider: "azure",
    vendorId: "gpt-3.5-turbo-instruct",
    displayName: "GPT-3.5 Turbo Instruct",
    family: "gpt-3.5-turbo-instruct",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.5,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-3.5-turbo-instruct"],
    releasedAt: "2023-09-21",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2023-09-21",
  },
  {
    id: "azure:gpt-4",
    provider: "azure",
    vendorId: "gpt-4",
    displayName: "GPT-4",
    family: "gpt-4",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":60,"outputPerMTokens":120},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-4"],
    releasedAt: "2023-03-14",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2023-03-14",
  },
  {
    id: "azure:gpt-4-32k",
    provider: "azure",
    vendorId: "gpt-4-32k",
    displayName: "GPT-4 32K",
    family: "gpt-4-32k",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":60,"outputPerMTokens":120},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-4-32k"],
    releasedAt: "2023-03-14",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2023-03-14",
  },
  {
    id: "azure:gpt-4-turbo",
    provider: "azure",
    vendorId: "gpt-4-turbo",
    displayName: "GPT-4 Turbo",
    family: "gpt-4-turbo",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":10,"outputPerMTokens":30},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-4-turbo"],
    releasedAt: "2023-11-06",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2024-04-09",
  },
  {
    id: "azure:gpt-4-turbo-vision",
    provider: "azure",
    vendorId: "gpt-4-turbo-vision",
    displayName: "GPT-4 Turbo Vision",
    family: "gpt-4-turbo-vision",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":10,"outputPerMTokens":30},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-4-turbo-vision"],
    releasedAt: "2023-11-06",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2024-04-09",
  },
  {
    id: "azure:gpt-4.1",
    provider: "azure",
    vendorId: "gpt-4.1",
    displayName: "GPT-4.1",
    family: "gpt-4.1",
    status: "stable",
    context: {"combinedMax":1047576,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":8},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-4.1"],
    releasedAt: "2025-04-14",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2025-04-14",
  },
  {
    id: "azure:gpt-4.1-mini",
    provider: "azure",
    vendorId: "gpt-4.1-mini",
    displayName: "GPT-4.1 mini",
    family: "gpt-4.1-mini",
    status: "stable",
    context: {"combinedMax":1047576,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.4,"outputPerMTokens":1.6},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-4.1-mini"],
    releasedAt: "2025-04-14",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2025-04-14",
  },
  {
    id: "azure:gpt-4.1-nano",
    provider: "azure",
    vendorId: "gpt-4.1-nano",
    displayName: "GPT-4.1 nano",
    family: "gpt-4.1-nano",
    status: "stable",
    context: {"combinedMax":1047576,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.4},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-4.1-nano"],
    releasedAt: "2025-04-14",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2025-04-14",
  },
  {
    id: "azure:gpt-4o",
    provider: "azure",
    vendorId: "gpt-4o",
    displayName: "GPT-4o",
    family: "gpt-4o",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2.5,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-4o"],
    releasedAt: "2024-05-13",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2024-05-13",
  },
  {
    id: "azure:gpt-4o-mini",
    provider: "azure",
    vendorId: "gpt-4o-mini",
    displayName: "GPT-4o mini",
    family: "gpt-4o-mini",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-4o-mini"],
    releasedAt: "2024-07-18",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2024-07-18",
  },
  {
    id: "azure:gpt-5",
    provider: "azure",
    vendorId: "gpt-5",
    displayName: "GPT-5",
    family: "gpt-5",
    status: "stable",
    context: {"combinedMax":272000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-5"],
    releasedAt: "2025-08-07",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "azure:gpt-5-chat",
    provider: "azure",
    vendorId: "gpt-5-chat",
    displayName: "GPT-5 Chat",
    family: "gpt-5-chat",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-5-chat"],
    releasedAt: "2025-08-07",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "azure:gpt-5-mini",
    provider: "azure",
    vendorId: "gpt-5-mini",
    displayName: "GPT-5 Mini",
    family: "gpt-5-mini",
    status: "stable",
    context: {"combinedMax":272000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.25,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-5-mini"],
    releasedAt: "2025-08-07",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "azure:gpt-5-nano",
    provider: "azure",
    vendorId: "gpt-5-nano",
    displayName: "GPT-5 Nano",
    family: "gpt-5-nano",
    status: "stable",
    context: {"combinedMax":272000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.05,"outputPerMTokens":0.4},
    pricingSource: "models.dev",
    aliases: ["azure/gpt-5-nano"],
    releasedAt: "2025-08-07",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "azure:o1",
    provider: "azure",
    vendorId: "o1",
    displayName: "o1",
    family: "o1",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":60},
    pricingSource: "models.dev",
    aliases: ["azure/o1"],
    releasedAt: "2024-12-05",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2024-12-05",
  },
  {
    id: "azure:o1-mini",
    provider: "azure",
    vendorId: "o1-mini",
    displayName: "o1-mini",
    family: "o1-mini",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.1,"outputPerMTokens":4.4},
    pricingSource: "models.dev",
    aliases: ["azure/o1-mini"],
    releasedAt: "2024-09-12",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2024-09-12",
  },
  {
    id: "azure:o1-preview",
    provider: "azure",
    vendorId: "o1-preview",
    displayName: "o1-preview",
    family: "o1-preview",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":16.5,"outputPerMTokens":66},
    pricingSource: "models.dev",
    aliases: ["azure/o1-preview"],
    releasedAt: "2024-09-12",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2024-09-12",
  },
  {
    id: "azure:o3",
    provider: "azure",
    vendorId: "o3",
    displayName: "o3",
    family: "o3",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":8},
    pricingSource: "models.dev",
    aliases: ["azure/o3"],
    releasedAt: "2025-04-16",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2025-04-16",
  },
  {
    id: "azure:o3-mini",
    provider: "azure",
    vendorId: "o3-mini",
    displayName: "o3-mini",
    family: "o3-mini",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.1,"outputPerMTokens":4.4},
    pricingSource: "models.dev",
    aliases: ["azure/o3-mini"],
    releasedAt: "2024-12-20",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2025-01-29",
  },
  {
    id: "azure:o4-mini",
    provider: "azure",
    vendorId: "o4-mini",
    displayName: "o4-mini",
    family: "o4-mini",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.1,"outputPerMTokens":4.4},
    pricingSource: "models.dev",
    aliases: ["azure/o4-mini"],
    releasedAt: "2025-04-16",
    source: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    contextSource: "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
    verifiedAt: "2025-04-16",
  },
  {
    id: "baseten:Moonshotai-Kimi-K2-Instruct-0905",
    provider: "baseten",
    vendorId: "Moonshotai-Kimi-K2-Instruct-0905",
    displayName: "moonshotai/Kimi-K2-Instruct-0905",
    family: "Moonshotai-Kimi-K2-Instruct-0905",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":262144},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":2.5},
    pricingSource: "models.dev",
    aliases: ["baseten/Moonshotai-Kimi-K2-Instruct-0905"],
    releasedAt: "2025-09-05",
    source: "https://docs.baseten.co/development/model-apis/overview",
    contextSource: "https://docs.baseten.co/development/model-apis/overview",
    verifiedAt: "2025-09-05",
  },
  {
    id: "baseten:Qwen-Qwen3-Coder-480B-A35B-Instruct",
    provider: "baseten",
    vendorId: "Qwen-Qwen3-Coder-480B-A35B-Instruct",
    displayName: "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    family: "Qwen-Qwen3-Coder-480B-A35B-Instruct",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":66536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.38,"outputPerMTokens":1.53},
    pricingSource: "models.dev",
    aliases: ["baseten/Qwen-Qwen3-Coder-480B-A35B-Instruct"],
    releasedAt: "2025-07-23",
    source: "https://docs.baseten.co/development/model-apis/overview",
    contextSource: "https://docs.baseten.co/development/model-apis/overview",
    verifiedAt: "2025-07-23",
  },
  {
    id: "cerebras:gpt-oss-120b",
    provider: "cerebras",
    vendorId: "gpt-oss-120b",
    displayName: "GPT OSS 120B",
    family: "gpt-oss-120b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.25,"outputPerMTokens":0.69},
    pricingSource: "models.dev",
    aliases: ["cerebras/gpt-oss-120b"],
    releasedAt: "2025-08-05",
    source: "https://inference-docs.cerebras.ai/models/overview",
    contextSource: "https://inference-docs.cerebras.ai/models/overview",
    verifiedAt: "2025-08-05",
  },
  {
    id: "cerebras:qwen-3-235b-a22b-instruct-2507",
    provider: "cerebras",
    vendorId: "qwen-3-235b-a22b-instruct-2507",
    displayName: "Qwen 3 235B Instruct",
    family: "qwen-3-235b-a22b-instruct-2507",
    status: "stable",
    context: {"combinedMax":131000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":1.2},
    pricingSource: "models.dev",
    aliases: ["cerebras/qwen-3-235b-a22b-instruct-2507"],
    releasedAt: "2025-07-22",
    source: "https://inference-docs.cerebras.ai/models/overview",
    contextSource: "https://inference-docs.cerebras.ai/models/overview",
    verifiedAt: "2025-07-22",
  },
  {
    id: "cerebras:qwen-3-coder-480b",
    provider: "cerebras",
    vendorId: "qwen-3-coder-480b",
    displayName: "Qwen 3 Coder 480B",
    family: "qwen-3-coder-480b",
    status: "stable",
    context: {"combinedMax":131000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["cerebras/qwen-3-coder-480b"],
    releasedAt: "2025-07-23",
    source: "https://inference-docs.cerebras.ai/models/overview",
    contextSource: "https://inference-docs.cerebras.ai/models/overview",
    verifiedAt: "2025-07-23",
  },
  {
    id: "chutes:chutesai/Devstral-Small-2505",
    provider: "chutes",
    vendorId: "chutesai/Devstral-Small-2505",
    displayName: "Devstral Small (2505)",
    family: "chutesai/Devstral-Small-2505",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.02,"outputPerMTokens":0.08},
    pricingSource: "models.dev",
    aliases: ["chutes/chutesai/Devstral-Small-2505"],
    releasedAt: "2025-05-21",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-05-21",
  },
  {
    id: "chutes:chutesai/Mistral-Small-3.2-24B-Instruct-2506",
    provider: "chutes",
    vendorId: "chutesai/Mistral-Small-3.2-24B-Instruct-2506",
    displayName: "Mistral Small 3.2 24B Instruct (2506)",
    family: "chutesai/Mistral-Small-3.2-24B-Instruct-2506",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.02,"outputPerMTokens":0.08},
    pricingSource: "models.dev",
    aliases: ["chutes/chutesai/Mistral-Small-3.2-24B-Instruct-2506"],
    releasedAt: "2025-06-20",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-06-20",
  },
  {
    id: "chutes:deepseek-ai/DeepSeek-R1-0528",
    provider: "chutes",
    vendorId: "deepseek-ai/DeepSeek-R1-0528",
    displayName: "DeepSeek R1 (0528)",
    family: "deepseek-ai/DeepSeek-R1-0528",
    status: "stable",
    context: {"combinedMax":75000,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.18,"outputPerMTokens":0.72},
    pricingSource: "models.dev",
    aliases: ["chutes/deepseek-ai/DeepSeek-R1-0528"],
    releasedAt: "2025-08-01",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-08-01",
  },
  {
    id: "chutes:deepseek-ai/DeepSeek-R1-0528-Qwen3-8B",
    provider: "chutes",
    vendorId: "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B",
    displayName: "DeepSeek R1 0528 Qwen3 8B",
    family: "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.02,"outputPerMTokens":0.07},
    pricingSource: "models.dev",
    aliases: ["chutes/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B"],
    releasedAt: "2025-05-29",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-05-29",
  },
  {
    id: "chutes:deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    provider: "chutes",
    vendorId: "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    displayName: "DeepSeek R1 Distill Llama 70B",
    family: "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.03,"outputPerMTokens":0.14},
    pricingSource: "models.dev",
    aliases: ["chutes/deepseek-ai/DeepSeek-R1-Distill-Llama-70B"],
    releasedAt: "2025-01-23",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-01-23",
  },
  {
    id: "chutes:deepseek-ai/DeepSeek-V3-0324",
    provider: "chutes",
    vendorId: "deepseek-ai/DeepSeek-V3-0324",
    displayName: "DeepSeek V3 (0324)",
    family: "deepseek-ai/DeepSeek-V3-0324",
    status: "stable",
    context: {"combinedMax":75000,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.18,"outputPerMTokens":0.72},
    pricingSource: "models.dev",
    aliases: ["chutes/deepseek-ai/DeepSeek-V3-0324"],
    releasedAt: "2025-08-01",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-08-01",
  },
  {
    id: "chutes:deepseek-ai/DeepSeek-V3.1",
    provider: "chutes",
    vendorId: "deepseek-ai/DeepSeek-V3.1",
    displayName: "DeepSeek V3.1",
    family: "deepseek-ai/DeepSeek-V3.1",
    status: "stable",
    context: {"combinedMax":163840,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.8},
    pricingSource: "models.dev",
    aliases: ["chutes/deepseek-ai/DeepSeek-V3.1"],
    releasedAt: "2025-08-21",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-08-21",
  },
  {
    id: "chutes:deepseek-ai/DeepSeek-V3.1:THINKING",
    provider: "chutes",
    vendorId: "deepseek-ai/DeepSeek-V3.1:THINKING",
    displayName: "DeepSeek V3.1 Reasoning",
    family: "deepseek-ai/DeepSeek-V3.1:THINKING",
    status: "stable",
    context: {"combinedMax":163840,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.8},
    pricingSource: "models.dev",
    aliases: ["chutes/deepseek-ai/DeepSeek-V3.1:THINKING"],
    releasedAt: "2025-08-21",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-08-21",
  },
  {
    id: "chutes:moonshotai/Kimi-K2-Instruct-75k",
    provider: "chutes",
    vendorId: "moonshotai/Kimi-K2-Instruct-75k",
    displayName: "Kimi K2 Instruct",
    family: "moonshotai/Kimi-K2-Instruct-75k",
    status: "stable",
    context: {"combinedMax":75000,"outputMax":75000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.59},
    pricingSource: "models.dev",
    aliases: ["chutes/moonshotai/Kimi-K2-Instruct-75k"],
    releasedAt: "2025-08-01",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-08-01",
  },
  {
    id: "chutes:openai/gpt-oss-120b",
    provider: "chutes",
    vendorId: "openai/gpt-oss-120b",
    displayName: "GPT OSS 120B",
    family: "openai/gpt-oss-120b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.41},
    pricingSource: "models.dev",
    aliases: ["chutes/openai/gpt-oss-120b"],
    releasedAt: "2025-08-05",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-08-05",
  },
  {
    id: "chutes:Qwen/Qwen3-235B-A22B-Instruct-2507",
    provider: "chutes",
    vendorId: "Qwen/Qwen3-235B-A22B-Instruct-2507",
    displayName: "Qwen3 235B A22B Instruct 2507",
    family: "Qwen/Qwen3-235B-A22B-Instruct-2507",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.078,"outputPerMTokens":0.312},
    pricingSource: "models.dev",
    aliases: ["chutes/Qwen/Qwen3-235B-A22B-Instruct-2507"],
    releasedAt: "2025-04-28",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-07-21",
  },
  {
    id: "chutes:Qwen/Qwen3-235B-A22B-Thinking-2507",
    provider: "chutes",
    vendorId: "Qwen/Qwen3-235B-A22B-Thinking-2507",
    displayName: "Qwen3-235B-A22B-Thinking-2507",
    family: "Qwen/Qwen3-235B-A22B-Thinking-2507",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":262144},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.078,"outputPerMTokens":0.312},
    pricingSource: "models.dev",
    aliases: ["chutes/Qwen/Qwen3-235B-A22B-Thinking-2507"],
    releasedAt: "2025-07-25",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-07-25",
  },
  {
    id: "chutes:Qwen/Qwen3-30B-A3B",
    provider: "chutes",
    vendorId: "Qwen/Qwen3-30B-A3B",
    displayName: "Qwen3 30B A3B",
    family: "Qwen/Qwen3-30B-A3B",
    status: "stable",
    context: {"combinedMax":40960,"outputMax":40960},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.02,"outputPerMTokens":0.08},
    pricingSource: "models.dev",
    aliases: ["chutes/Qwen/Qwen3-30B-A3B"],
    releasedAt: "2025-04-28",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-04-28",
  },
  {
    id: "chutes:Qwen/Qwen3-30B-A3B-Instruct-2507",
    provider: "chutes",
    vendorId: "Qwen/Qwen3-30B-A3B-Instruct-2507",
    displayName: "Qwen3 30B A3B Instruct 2507",
    family: "Qwen/Qwen3-30B-A3B-Instruct-2507",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":262144},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.05,"outputPerMTokens":0.2},
    pricingSource: "models.dev",
    aliases: ["chutes/Qwen/Qwen3-30B-A3B-Instruct-2507"],
    releasedAt: "2025-07-25",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-07-25",
  },
  {
    id: "chutes:Qwen/Qwen3-Coder-30B-A3B-Instruct",
    provider: "chutes",
    vendorId: "Qwen/Qwen3-Coder-30B-A3B-Instruct",
    displayName: "Qwen3 Coder 30B A3B Instruct",
    family: "Qwen/Qwen3-Coder-30B-A3B-Instruct",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":262144},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["chutes/Qwen/Qwen3-Coder-30B-A3B-Instruct"],
    releasedAt: "2025-07-25",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-07-25",
  },
  {
    id: "chutes:Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    provider: "chutes",
    vendorId: "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    displayName: "Qwen3 Coder 480B A35B Instruct (FP8)",
    family: "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":262144},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.8},
    pricingSource: "models.dev",
    aliases: ["chutes/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8"],
    releasedAt: "2025-08-01",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-08-01",
  },
  {
    id: "chutes:tngtech/DeepSeek-R1T-Chimera",
    provider: "chutes",
    vendorId: "tngtech/DeepSeek-R1T-Chimera",
    displayName: "DeepSeek R1T Chimera",
    family: "tngtech/DeepSeek-R1T-Chimera",
    status: "stable",
    context: {"combinedMax":163840,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.18,"outputPerMTokens":0.72},
    pricingSource: "models.dev",
    aliases: ["chutes/tngtech/DeepSeek-R1T-Chimera"],
    releasedAt: "2025-04-26",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-04-26",
  },
  {
    id: "chutes:tngtech/DeepSeek-TNG-R1T2-Chimera",
    provider: "chutes",
    vendorId: "tngtech/DeepSeek-TNG-R1T2-Chimera",
    displayName: "DeepSeek TNG R1T2 Chimera",
    family: "tngtech/DeepSeek-TNG-R1T2-Chimera",
    status: "stable",
    context: {"combinedMax":163840,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.8},
    pricingSource: "models.dev",
    aliases: ["chutes/tngtech/DeepSeek-TNG-R1T2-Chimera"],
    releasedAt: "2025-07-08",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-07-08",
  },
  {
    id: "chutes:zai-org/GLM-4.5-Air",
    provider: "chutes",
    vendorId: "zai-org/GLM-4.5-Air",
    displayName: "GLM 4.5 Air",
    family: "zai-org/GLM-4.5-Air",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":98304},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["chutes/zai-org/GLM-4.5-Air"],
    releasedAt: "2025-07-28",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-07-28",
  },
  {
    id: "chutes:zai-org/GLM-4.5-FP8",
    provider: "chutes",
    vendorId: "zai-org/GLM-4.5-FP8",
    displayName: "GLM 4.5 FP8",
    family: "zai-org/GLM-4.5-FP8",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["chutes/zai-org/GLM-4.5-FP8"],
    releasedAt: "2025-07-28",
    source: "https://llm.chutes.ai/v1/models",
    contextSource: "https://llm.chutes.ai/v1/models",
    verifiedAt: "2025-07-28",
  },
  {
    id: "cloudflare-workers-ai:bart-large-cnn",
    provider: "cloudflare-workers-ai",
    vendorId: "bart-large-cnn",
    displayName: "@cf/facebook/bart-large-cnn",
    family: "bart-large-cnn",
    status: "stable",
    context: {"combinedMax":0,"outputMax":0},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/bart-large-cnn"],
    releasedAt: "2022-03-02",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-02-13",
  },
  {
    id: "cloudflare-workers-ai:deepseek-coder-6.7b-base-awq",
    provider: "cloudflare-workers-ai",
    vendorId: "deepseek-coder-6.7b-base-awq",
    displayName: "@hf/thebloke/deepseek-coder-6.7b-base-awq",
    family: "deepseek-coder-6.7b-base-awq",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/deepseek-coder-6.7b-base-awq"],
    releasedAt: "2023-11-05",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2023-11-09",
  },
  {
    id: "cloudflare-workers-ai:deepseek-coder-6.7b-instruct-awq",
    provider: "cloudflare-workers-ai",
    vendorId: "deepseek-coder-6.7b-instruct-awq",
    displayName: "@hf/thebloke/deepseek-coder-6.7b-instruct-awq",
    family: "deepseek-coder-6.7b-instruct-awq",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/deepseek-coder-6.7b-instruct-awq"],
    releasedAt: "2023-11-05",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2023-11-13",
  },
  {
    id: "cloudflare-workers-ai:deepseek-math-7b-instruct",
    provider: "cloudflare-workers-ai",
    vendorId: "deepseek-math-7b-instruct",
    displayName: "@cf/deepseek-ai/deepseek-math-7b-instruct",
    family: "deepseek-math-7b-instruct",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/deepseek-math-7b-instruct"],
    releasedAt: "2024-02-05",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-02-06",
  },
  {
    id: "cloudflare-workers-ai:deepseek-r1-distill-qwen-32b",
    provider: "cloudflare-workers-ai",
    vendorId: "deepseek-r1-distill-qwen-32b",
    displayName: "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
    family: "deepseek-r1-distill-qwen-32b",
    status: "stable",
    context: {"combinedMax":80000,"outputMax":80000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.5,"outputPerMTokens":4.88},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/deepseek-r1-distill-qwen-32b"],
    releasedAt: "2025-01-20",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2025-02-24",
  },
  {
    id: "cloudflare-workers-ai:discolm-german-7b-v1-awq",
    provider: "cloudflare-workers-ai",
    vendorId: "discolm-german-7b-v1-awq",
    displayName: "@cf/thebloke/discolm-german-7b-v1-awq",
    family: "discolm-german-7b-v1-awq",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/discolm-german-7b-v1-awq"],
    releasedAt: "2024-01-18",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-01-24",
  },
  {
    id: "cloudflare-workers-ai:dreamshaper-8-lcm",
    provider: "cloudflare-workers-ai",
    vendorId: "dreamshaper-8-lcm",
    displayName: "@cf/lykon/dreamshaper-8-lcm",
    family: "dreamshaper-8-lcm",
    status: "stable",
    context: {"combinedMax":0,"outputMax":0},
    modalities: {"textIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/dreamshaper-8-lcm"],
    releasedAt: "2023-12-06",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2023-12-07",
  },
  {
    id: "cloudflare-workers-ai:falcon-7b-instruct",
    provider: "cloudflare-workers-ai",
    vendorId: "falcon-7b-instruct",
    displayName: "@cf/tiiuae/falcon-7b-instruct",
    family: "falcon-7b-instruct",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/falcon-7b-instruct"],
    releasedAt: "2023-04-25",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-10-12",
  },
  {
    id: "cloudflare-workers-ai:flux-1-schnell",
    provider: "cloudflare-workers-ai",
    vendorId: "flux-1-schnell",
    displayName: "@cf/black-forest-labs/flux-1-schnell",
    family: "flux-1-schnell",
    status: "stable",
    context: {"combinedMax":2048,"outputMax":0},
    modalities: {"textIn":true},
    pricing: {"inputPerMTokens":0.000053,"outputPerMTokens":0.00011},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/flux-1-schnell"],
    releasedAt: "2024-07-31",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-08-16",
  },
  {
    id: "cloudflare-workers-ai:gemma-2b-it-lora",
    provider: "cloudflare-workers-ai",
    vendorId: "gemma-2b-it-lora",
    displayName: "@cf/google/gemma-2b-it-lora",
    family: "gemma-2b-it-lora",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/gemma-2b-it-lora"],
    releasedAt: "2024-04-02",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-04-02",
  },
  {
    id: "cloudflare-workers-ai:gemma-3-12b-it",
    provider: "cloudflare-workers-ai",
    vendorId: "gemma-3-12b-it",
    displayName: "@cf/google/gemma-3-12b-it",
    family: "gemma-3-12b-it",
    status: "stable",
    context: {"combinedMax":80000,"outputMax":80000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.35,"outputPerMTokens":0.56},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/gemma-3-12b-it"],
    releasedAt: "2025-03-01",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2025-03-21",
  },
  {
    id: "cloudflare-workers-ai:gemma-7b-it",
    provider: "cloudflare-workers-ai",
    vendorId: "gemma-7b-it",
    displayName: "@hf/google/gemma-7b-it",
    family: "gemma-7b-it",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/gemma-7b-it"],
    releasedAt: "2024-02-13",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-08-14",
  },
  {
    id: "cloudflare-workers-ai:gemma-7b-it-lora",
    provider: "cloudflare-workers-ai",
    vendorId: "gemma-7b-it-lora",
    displayName: "@cf/google/gemma-7b-it-lora",
    family: "gemma-7b-it-lora",
    status: "stable",
    context: {"combinedMax":3500,"outputMax":3500},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/gemma-7b-it-lora"],
    releasedAt: "2024-04-02",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-04-02",
  },
  {
    id: "cloudflare-workers-ai:gpt-oss-120b",
    provider: "cloudflare-workers-ai",
    vendorId: "gpt-oss-120b",
    displayName: "@cf/openai/gpt-oss-120b",
    family: "gpt-oss-120b",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.35,"outputPerMTokens":0.75},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/gpt-oss-120b"],
    releasedAt: "2025-08-04",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2025-08-14",
  },
  {
    id: "cloudflare-workers-ai:gpt-oss-20b",
    provider: "cloudflare-workers-ai",
    vendorId: "gpt-oss-20b",
    displayName: "@cf/openai/gpt-oss-20b",
    family: "gpt-oss-20b",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.3},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/gpt-oss-20b"],
    releasedAt: "2025-08-04",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2025-08-14",
  },
  {
    id: "cloudflare-workers-ai:hermes-2-pro-mistral-7b",
    provider: "cloudflare-workers-ai",
    vendorId: "hermes-2-pro-mistral-7b",
    displayName: "@hf/nousresearch/hermes-2-pro-mistral-7b",
    family: "hermes-2-pro-mistral-7b",
    status: "stable",
    context: {"combinedMax":24000,"outputMax":24000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/hermes-2-pro-mistral-7b"],
    releasedAt: "2024-03-11",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-09-08",
  },
  {
    id: "cloudflare-workers-ai:llama-2-13b-chat-awq",
    provider: "cloudflare-workers-ai",
    vendorId: "llama-2-13b-chat-awq",
    displayName: "@hf/thebloke/llama-2-13b-chat-awq",
    family: "llama-2-13b-chat-awq",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llama-2-13b-chat-awq"],
    releasedAt: "2023-09-19",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2023-11-09",
  },
  {
    id: "cloudflare-workers-ai:llama-2-7b-chat-fp16",
    provider: "cloudflare-workers-ai",
    vendorId: "llama-2-7b-chat-fp16",
    displayName: "@cf/meta/llama-2-7b-chat-fp16",
    family: "llama-2-7b-chat-fp16",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.56,"outputPerMTokens":6.67},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llama-2-7b-chat-fp16"],
    releasedAt: "2023-07-26",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2023-07-26",
  },
  {
    id: "cloudflare-workers-ai:llama-2-7b-chat-hf-lora",
    provider: "cloudflare-workers-ai",
    vendorId: "llama-2-7b-chat-hf-lora",
    displayName: "@cf/meta-llama/llama-2-7b-chat-hf-lora",
    family: "llama-2-7b-chat-hf-lora",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llama-2-7b-chat-hf-lora"],
    releasedAt: "2023-07-13",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-04-17",
  },
  {
    id: "cloudflare-workers-ai:llama-2-7b-chat-int8",
    provider: "cloudflare-workers-ai",
    vendorId: "llama-2-7b-chat-int8",
    displayName: "@cf/meta/llama-2-7b-chat-int8",
    family: "llama-2-7b-chat-int8",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llama-2-7b-chat-int8"],
    releasedAt: "2023-09-25",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2023-09-25",
  },
  {
    id: "cloudflare-workers-ai:llama-3-8b-instruct",
    provider: "cloudflare-workers-ai",
    vendorId: "llama-3-8b-instruct",
    displayName: "@cf/meta/llama-3-8b-instruct",
    family: "llama-3-8b-instruct",
    status: "stable",
    context: {"combinedMax":7968,"outputMax":7968},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.28,"outputPerMTokens":0.83},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llama-3-8b-instruct"],
    releasedAt: "2024-04-17",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2025-06-19",
  },
  {
    id: "cloudflare-workers-ai:llama-3-8b-instruct-awq",
    provider: "cloudflare-workers-ai",
    vendorId: "llama-3-8b-instruct-awq",
    displayName: "@cf/meta/llama-3-8b-instruct-awq",
    family: "llama-3-8b-instruct-awq",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.12,"outputPerMTokens":0.27},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llama-3-8b-instruct-awq"],
    releasedAt: "2024-05-09",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-05-09",
  },
  {
    id: "cloudflare-workers-ai:llama-3.1-70b-instruct",
    provider: "cloudflare-workers-ai",
    vendorId: "llama-3.1-70b-instruct",
    displayName: "@cf/meta/llama-3.1-70b-instruct",
    family: "llama-3.1-70b-instruct",
    status: "stable",
    context: {"combinedMax":24000,"outputMax":24000},
    modalities: {"textIn":true,"textOut":true},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llama-3.1-70b-instruct"],
    releasedAt: "2024-07-16",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-12-15",
  },
  {
    id: "cloudflare-workers-ai:llama-3.1-8b-instruct",
    provider: "cloudflare-workers-ai",
    vendorId: "llama-3.1-8b-instruct",
    displayName: "@cf/meta/llama-3.1-8b-instruct",
    family: "llama-3.1-8b-instruct",
    status: "stable",
    context: {"combinedMax":7968,"outputMax":7968},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.28,"outputPerMTokens":0.83},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llama-3.1-8b-instruct"],
    releasedAt: "2024-07-18",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-09-25",
  },
  {
    id: "cloudflare-workers-ai:llama-3.1-8b-instruct-awq",
    provider: "cloudflare-workers-ai",
    vendorId: "llama-3.1-8b-instruct-awq",
    displayName: "@cf/meta/llama-3.1-8b-instruct-awq",
    family: "llama-3.1-8b-instruct-awq",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.12,"outputPerMTokens":0.27},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llama-3.1-8b-instruct-awq"],
    releasedAt: "2024-07-25",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-07-25",
  },
  {
    id: "cloudflare-workers-ai:llama-3.1-8b-instruct-fast",
    provider: "cloudflare-workers-ai",
    vendorId: "llama-3.1-8b-instruct-fast",
    displayName: "@cf/meta/llama-3.1-8b-instruct-fast",
    family: "llama-3.1-8b-instruct-fast",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llama-3.1-8b-instruct-fast"],
    releasedAt: "2024-07-18",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-09-25",
  },
  {
    id: "cloudflare-workers-ai:llama-3.1-8b-instruct-fp8",
    provider: "cloudflare-workers-ai",
    vendorId: "llama-3.1-8b-instruct-fp8",
    displayName: "@cf/meta/llama-3.1-8b-instruct-fp8",
    family: "llama-3.1-8b-instruct-fp8",
    status: "stable",
    context: {"combinedMax":32000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.29},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llama-3.1-8b-instruct-fp8"],
    releasedAt: "2024-07-25",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-07-25",
  },
  {
    id: "cloudflare-workers-ai:llama-3.2-11b-vision-instruct",
    provider: "cloudflare-workers-ai",
    vendorId: "llama-3.2-11b-vision-instruct",
    displayName: "@cf/meta/llama-3.2-11b-vision-instruct",
    family: "llama-3.2-11b-vision-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.049,"outputPerMTokens":0.68},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llama-3.2-11b-vision-instruct"],
    releasedAt: "2024-09-18",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-12-04",
  },
  {
    id: "cloudflare-workers-ai:llama-3.2-1b-instruct",
    provider: "cloudflare-workers-ai",
    vendorId: "llama-3.2-1b-instruct",
    displayName: "@cf/meta/llama-3.2-1b-instruct",
    family: "llama-3.2-1b-instruct",
    status: "stable",
    context: {"combinedMax":60000,"outputMax":60000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.027,"outputPerMTokens":0.2},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llama-3.2-1b-instruct"],
    releasedAt: "2024-09-18",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-10-24",
  },
  {
    id: "cloudflare-workers-ai:llama-3.2-3b-instruct",
    provider: "cloudflare-workers-ai",
    vendorId: "llama-3.2-3b-instruct",
    displayName: "@cf/meta/llama-3.2-3b-instruct",
    family: "llama-3.2-3b-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.051,"outputPerMTokens":0.34},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llama-3.2-3b-instruct"],
    releasedAt: "2024-09-18",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-10-24",
  },
  {
    id: "cloudflare-workers-ai:llama-3.3-70b-instruct-fp8-fast",
    provider: "cloudflare-workers-ai",
    vendorId: "llama-3.3-70b-instruct-fp8-fast",
    displayName: "@cf/meta/llama-3.3-70b-instruct-fp8-fast",
    family: "llama-3.3-70b-instruct-fp8-fast",
    status: "stable",
    context: {"combinedMax":24000,"outputMax":24000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.29,"outputPerMTokens":2.25},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llama-3.3-70b-instruct-fp8-fast"],
    releasedAt: "2024-12-06",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-12-06",
  },
  {
    id: "cloudflare-workers-ai:llama-4-scout-17b-16e-instruct",
    provider: "cloudflare-workers-ai",
    vendorId: "llama-4-scout-17b-16e-instruct",
    displayName: "@cf/meta/llama-4-scout-17b-16e-instruct",
    family: "llama-4-scout-17b-16e-instruct",
    status: "stable",
    context: {"combinedMax":131000,"outputMax":131000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.27,"outputPerMTokens":0.85},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llama-4-scout-17b-16e-instruct"],
    releasedAt: "2025-04-02",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2025-05-23",
  },
  {
    id: "cloudflare-workers-ai:llama-guard-3-8b",
    provider: "cloudflare-workers-ai",
    vendorId: "llama-guard-3-8b",
    displayName: "@cf/meta/llama-guard-3-8b",
    family: "llama-guard-3-8b",
    status: "stable",
    context: {"combinedMax":0,"outputMax":0},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.48,"outputPerMTokens":0.03},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llama-guard-3-8b"],
    releasedAt: "2024-07-22",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-10-11",
  },
  {
    id: "cloudflare-workers-ai:llamaguard-7b-awq",
    provider: "cloudflare-workers-ai",
    vendorId: "llamaguard-7b-awq",
    displayName: "@hf/thebloke/llamaguard-7b-awq",
    family: "llamaguard-7b-awq",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llamaguard-7b-awq"],
    releasedAt: "2023-12-11",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2023-12-11",
  },
  {
    id: "cloudflare-workers-ai:llava-1.5-7b-hf",
    provider: "cloudflare-workers-ai",
    vendorId: "llava-1.5-7b-hf",
    displayName: "@cf/llava-hf/llava-1.5-7b-hf",
    family: "llava-1.5-7b-hf",
    status: "stable",
    context: {"combinedMax":0,"outputMax":0},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/llava-1.5-7b-hf"],
    releasedAt: "2023-12-05",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2025-06-06",
  },
  {
    id: "cloudflare-workers-ai:m2m100-1.2b",
    provider: "cloudflare-workers-ai",
    vendorId: "m2m100-1.2b",
    displayName: "@cf/meta/m2m100-1.2b",
    family: "m2m100-1.2b",
    status: "stable",
    context: {"combinedMax":0,"outputMax":0},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.34,"outputPerMTokens":0.34},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/m2m100-1.2b"],
    releasedAt: "2022-03-02",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2023-11-16",
  },
  {
    id: "cloudflare-workers-ai:melotts",
    provider: "cloudflare-workers-ai",
    vendorId: "melotts",
    displayName: "@cf/myshell-ai/melotts",
    family: "melotts",
    status: "stable",
    context: {"combinedMax":0,"outputMax":0},
    modalities: {"textIn":true},
    pricing: {"inputPerMTokens":0.0002,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/melotts"],
    releasedAt: "2024-07-19",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-07-19",
  },
  {
    id: "cloudflare-workers-ai:mistral-7b-instruct-v0.1",
    provider: "cloudflare-workers-ai",
    vendorId: "mistral-7b-instruct-v0.1",
    displayName: "@cf/mistral/mistral-7b-instruct-v0.1",
    family: "mistral-7b-instruct-v0.1",
    status: "stable",
    context: {"combinedMax":2824,"outputMax":2824},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.11,"outputPerMTokens":0.19},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/mistral-7b-instruct-v0.1"],
    releasedAt: "2023-09-27",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2025-07-24",
  },
  {
    id: "cloudflare-workers-ai:mistral-7b-instruct-v0.1-awq",
    provider: "cloudflare-workers-ai",
    vendorId: "mistral-7b-instruct-v0.1-awq",
    displayName: "@hf/thebloke/mistral-7b-instruct-v0.1-awq",
    family: "mistral-7b-instruct-v0.1-awq",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/mistral-7b-instruct-v0.1-awq"],
    releasedAt: "2023-09-27",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2023-11-09",
  },
  {
    id: "cloudflare-workers-ai:mistral-7b-instruct-v0.2",
    provider: "cloudflare-workers-ai",
    vendorId: "mistral-7b-instruct-v0.2",
    displayName: "@hf/mistral/mistral-7b-instruct-v0.2",
    family: "mistral-7b-instruct-v0.2",
    status: "stable",
    context: {"combinedMax":3072,"outputMax":3072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/mistral-7b-instruct-v0.2"],
    releasedAt: "2023-12-11",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2025-07-24",
  },
  {
    id: "cloudflare-workers-ai:mistral-7b-instruct-v0.2-lora",
    provider: "cloudflare-workers-ai",
    vendorId: "mistral-7b-instruct-v0.2-lora",
    displayName: "@cf/mistral/mistral-7b-instruct-v0.2-lora",
    family: "mistral-7b-instruct-v0.2-lora",
    status: "stable",
    context: {"combinedMax":15000,"outputMax":15000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/mistral-7b-instruct-v0.2-lora"],
    releasedAt: "2024-04-01",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-04-01",
  },
  {
    id: "cloudflare-workers-ai:mistral-small-3.1-24b-instruct",
    provider: "cloudflare-workers-ai",
    vendorId: "mistral-small-3.1-24b-instruct",
    displayName: "@cf/mistralai/mistral-small-3.1-24b-instruct",
    family: "mistral-small-3.1-24b-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.35,"outputPerMTokens":0.56},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/mistral-small-3.1-24b-instruct"],
    releasedAt: "2025-03-11",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2025-07-28",
  },
  {
    id: "cloudflare-workers-ai:neural-chat-7b-v3-1-awq",
    provider: "cloudflare-workers-ai",
    vendorId: "neural-chat-7b-v3-1-awq",
    displayName: "@hf/thebloke/neural-chat-7b-v3-1-awq",
    family: "neural-chat-7b-v3-1-awq",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/neural-chat-7b-v3-1-awq"],
    releasedAt: "2023-11-15",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2023-11-17",
  },
  {
    id: "cloudflare-workers-ai:openchat-3.5-0106",
    provider: "cloudflare-workers-ai",
    vendorId: "openchat-3.5-0106",
    displayName: "@cf/openchat/openchat-3.5-0106",
    family: "openchat-3.5-0106",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/openchat-3.5-0106"],
    releasedAt: "2024-01-07",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-05-18",
  },
  {
    id: "cloudflare-workers-ai:openhermes-2.5-mistral-7b-awq",
    provider: "cloudflare-workers-ai",
    vendorId: "openhermes-2.5-mistral-7b-awq",
    displayName: "@hf/thebloke/openhermes-2.5-mistral-7b-awq",
    family: "openhermes-2.5-mistral-7b-awq",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/openhermes-2.5-mistral-7b-awq"],
    releasedAt: "2023-11-02",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2023-11-09",
  },
  {
    id: "cloudflare-workers-ai:phi-2",
    provider: "cloudflare-workers-ai",
    vendorId: "phi-2",
    displayName: "@cf/microsoft/phi-2",
    family: "phi-2",
    status: "stable",
    context: {"combinedMax":2048,"outputMax":2048},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/phi-2"],
    releasedAt: "2023-12-13",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-04-29",
  },
  {
    id: "cloudflare-workers-ai:qwen1.5-0.5b-chat",
    provider: "cloudflare-workers-ai",
    vendorId: "qwen1.5-0.5b-chat",
    displayName: "@cf/qwen/qwen1.5-0.5b-chat",
    family: "qwen1.5-0.5b-chat",
    status: "stable",
    context: {"combinedMax":32000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/qwen1.5-0.5b-chat"],
    releasedAt: "2024-01-31",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-04-30",
  },
  {
    id: "cloudflare-workers-ai:qwen1.5-1.8b-chat",
    provider: "cloudflare-workers-ai",
    vendorId: "qwen1.5-1.8b-chat",
    displayName: "@cf/qwen/qwen1.5-1.8b-chat",
    family: "qwen1.5-1.8b-chat",
    status: "stable",
    context: {"combinedMax":32000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/qwen1.5-1.8b-chat"],
    releasedAt: "2024-01-30",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-04-30",
  },
  {
    id: "cloudflare-workers-ai:qwen1.5-14b-chat-awq",
    provider: "cloudflare-workers-ai",
    vendorId: "qwen1.5-14b-chat-awq",
    displayName: "@cf/qwen/qwen1.5-14b-chat-awq",
    family: "qwen1.5-14b-chat-awq",
    status: "stable",
    context: {"combinedMax":7500,"outputMax":7500},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/qwen1.5-14b-chat-awq"],
    releasedAt: "2024-02-03",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-04-30",
  },
  {
    id: "cloudflare-workers-ai:qwen1.5-7b-chat-awq",
    provider: "cloudflare-workers-ai",
    vendorId: "qwen1.5-7b-chat-awq",
    displayName: "@cf/qwen/qwen1.5-7b-chat-awq",
    family: "qwen1.5-7b-chat-awq",
    status: "stable",
    context: {"combinedMax":20000,"outputMax":20000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/qwen1.5-7b-chat-awq"],
    releasedAt: "2024-02-03",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-04-30",
  },
  {
    id: "cloudflare-workers-ai:qwen2.5-coder-32b-instruct",
    provider: "cloudflare-workers-ai",
    vendorId: "qwen2.5-coder-32b-instruct",
    displayName: "@cf/qwen/qwen2.5-coder-32b-instruct",
    family: "qwen2.5-coder-32b-instruct",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.66,"outputPerMTokens":1},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/qwen2.5-coder-32b-instruct"],
    releasedAt: "2024-11-06",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2025-01-12",
  },
  {
    id: "cloudflare-workers-ai:qwq-32b",
    provider: "cloudflare-workers-ai",
    vendorId: "qwq-32b",
    displayName: "@cf/qwen/qwq-32b",
    family: "qwq-32b",
    status: "stable",
    context: {"combinedMax":24000,"outputMax":24000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.66,"outputPerMTokens":1},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/qwq-32b"],
    releasedAt: "2025-03-05",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2025-03-11",
  },
  {
    id: "cloudflare-workers-ai:resnet-50",
    provider: "cloudflare-workers-ai",
    vendorId: "resnet-50",
    displayName: "@cf/microsoft/resnet-50",
    family: "resnet-50",
    status: "stable",
    context: {"combinedMax":0,"outputMax":0},
    modalities: {"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.0000025,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/resnet-50"],
    releasedAt: "2022-03-16",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-02-13",
  },
  {
    id: "cloudflare-workers-ai:sqlcoder-7b-2",
    provider: "cloudflare-workers-ai",
    vendorId: "sqlcoder-7b-2",
    displayName: "@cf/defog/sqlcoder-7b-2",
    family: "sqlcoder-7b-2",
    status: "stable",
    context: {"combinedMax":10000,"outputMax":10000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/sqlcoder-7b-2"],
    releasedAt: "2024-02-05",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-02-12",
  },
  {
    id: "cloudflare-workers-ai:stable-diffusion-v1-5-img2img",
    provider: "cloudflare-workers-ai",
    vendorId: "stable-diffusion-v1-5-img2img",
    displayName: "@cf/runwayml/stable-diffusion-v1-5-img2img",
    family: "stable-diffusion-v1-5-img2img",
    status: "stable",
    context: {"combinedMax":0,"outputMax":0},
    modalities: {"textIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/stable-diffusion-v1-5-img2img"],
    releasedAt: "2024-02-27",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-02-27",
  },
  {
    id: "cloudflare-workers-ai:stable-diffusion-v1-5-inpainting",
    provider: "cloudflare-workers-ai",
    vendorId: "stable-diffusion-v1-5-inpainting",
    displayName: "@cf/runwayml/stable-diffusion-v1-5-inpainting",
    family: "stable-diffusion-v1-5-inpainting",
    status: "stable",
    context: {"combinedMax":0,"outputMax":0},
    modalities: {"textIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/stable-diffusion-v1-5-inpainting"],
    releasedAt: "2024-02-27",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-02-27",
  },
  {
    id: "cloudflare-workers-ai:stable-diffusion-xl-base-1.0",
    provider: "cloudflare-workers-ai",
    vendorId: "stable-diffusion-xl-base-1.0",
    displayName: "@cf/stabilityai/stable-diffusion-xl-base-1.0",
    family: "stable-diffusion-xl-base-1.0",
    status: "stable",
    context: {"combinedMax":0,"outputMax":0},
    modalities: {"textIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/stable-diffusion-xl-base-1.0"],
    releasedAt: "2023-07-25",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2023-10-30",
  },
  {
    id: "cloudflare-workers-ai:stable-diffusion-xl-lightning",
    provider: "cloudflare-workers-ai",
    vendorId: "stable-diffusion-xl-lightning",
    displayName: "@cf/bytedance/stable-diffusion-xl-lightning",
    family: "stable-diffusion-xl-lightning",
    status: "stable",
    context: {"combinedMax":0,"outputMax":0},
    modalities: {"textIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/stable-diffusion-xl-lightning"],
    releasedAt: "2024-02-20",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-04-03",
  },
  {
    id: "cloudflare-workers-ai:starling-lm-7b-beta",
    provider: "cloudflare-workers-ai",
    vendorId: "starling-lm-7b-beta",
    displayName: "@hf/nexusflow/starling-lm-7b-beta",
    family: "starling-lm-7b-beta",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/starling-lm-7b-beta"],
    releasedAt: "2024-03-19",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-04-03",
  },
  {
    id: "cloudflare-workers-ai:tinyllama-1.1b-chat-v1.0",
    provider: "cloudflare-workers-ai",
    vendorId: "tinyllama-1.1b-chat-v1.0",
    displayName: "@cf/tinyllama/tinyllama-1.1b-chat-v1.0",
    family: "tinyllama-1.1b-chat-v1.0",
    status: "stable",
    context: {"combinedMax":2048,"outputMax":2048},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/tinyllama-1.1b-chat-v1.0"],
    releasedAt: "2023-12-30",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-03-17",
  },
  {
    id: "cloudflare-workers-ai:uform-gen2-qwen-500m",
    provider: "cloudflare-workers-ai",
    vendorId: "uform-gen2-qwen-500m",
    displayName: "@cf/unum/uform-gen2-qwen-500m",
    family: "uform-gen2-qwen-500m",
    status: "stable",
    context: {"combinedMax":0,"outputMax":0},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/uform-gen2-qwen-500m"],
    releasedAt: "2024-02-15",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-04-24",
  },
  {
    id: "cloudflare-workers-ai:una-cybertron-7b-v2-bf16",
    provider: "cloudflare-workers-ai",
    vendorId: "una-cybertron-7b-v2-bf16",
    displayName: "@cf/fblgit/una-cybertron-7b-v2-bf16",
    family: "una-cybertron-7b-v2-bf16",
    status: "stable",
    context: {"combinedMax":15000,"outputMax":15000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/una-cybertron-7b-v2-bf16"],
    releasedAt: "2023-12-02",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-03-08",
  },
  {
    id: "cloudflare-workers-ai:whisper",
    provider: "cloudflare-workers-ai",
    vendorId: "whisper",
    displayName: "@cf/openai/whisper",
    family: "whisper",
    status: "stable",
    context: {"combinedMax":0,"outputMax":0},
    modalities: {"textOut":true},
    pricing: {"inputPerMTokens":0.00045,"outputPerMTokens":0.00045},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/whisper"],
    releasedAt: "2023-11-07",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-08-12",
  },
  {
    id: "cloudflare-workers-ai:whisper-large-v3-turbo",
    provider: "cloudflare-workers-ai",
    vendorId: "whisper-large-v3-turbo",
    displayName: "@cf/openai/whisper-large-v3-turbo",
    family: "whisper-large-v3-turbo",
    status: "stable",
    context: {"combinedMax":0,"outputMax":0},
    modalities: {"textOut":true},
    pricing: {"inputPerMTokens":0.00051,"outputPerMTokens":0.00051},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/whisper-large-v3-turbo"],
    releasedAt: "2024-10-01",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-10-04",
  },
  {
    id: "cloudflare-workers-ai:whisper-tiny-en",
    provider: "cloudflare-workers-ai",
    vendorId: "whisper-tiny-en",
    displayName: "@cf/openai/whisper-tiny-en",
    family: "whisper-tiny-en",
    status: "stable",
    context: {"combinedMax":0,"outputMax":0},
    modalities: {"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/whisper-tiny-en"],
    releasedAt: "2022-09-26",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2024-01-22",
  },
  {
    id: "cloudflare-workers-ai:zephyr-7b-beta-awq",
    provider: "cloudflare-workers-ai",
    vendorId: "zephyr-7b-beta-awq",
    displayName: "@hf/thebloke/zephyr-7b-beta-awq",
    family: "zephyr-7b-beta-awq",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["cloudflare-workers-ai/zephyr-7b-beta-awq"],
    releasedAt: "2023-10-27",
    source: "https://developers.cloudflare.com/workers-ai/models/",
    contextSource: "https://developers.cloudflare.com/workers-ai/models/",
    verifiedAt: "2023-11-09",
  },
  {
    id: "deepinfra:moonshotai/Kimi-K2-Instruct",
    provider: "deepinfra",
    vendorId: "moonshotai/Kimi-K2-Instruct",
    displayName: "Kimi K2",
    family: "moonshotai/Kimi-K2-Instruct",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.5,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["deepinfra/moonshotai/Kimi-K2-Instruct"],
    releasedAt: "2025-07-11",
    source: "https://deepinfra.com/models",
    contextSource: "https://deepinfra.com/models",
    verifiedAt: "2025-07-11",
  },
  {
    id: "deepinfra:Qwen/Qwen3-Coder-480B-A35B-Instruct",
    provider: "deepinfra",
    vendorId: "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    displayName: "Qwen3 Coder 480B A35B Instruct",
    family: "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":66536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.4,"outputPerMTokens":1.6},
    pricingSource: "models.dev",
    aliases: ["deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct"],
    releasedAt: "2025-07-23",
    source: "https://deepinfra.com/models",
    contextSource: "https://deepinfra.com/models",
    verifiedAt: "2025-07-23",
  },
  {
    id: "deepinfra:Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo",
    provider: "deepinfra",
    vendorId: "Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo",
    displayName: "Qwen3 Coder 480B A35B Instruct Turbo",
    family: "Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":66536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":1.2},
    pricingSource: "models.dev",
    aliases: ["deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo"],
    releasedAt: "2025-07-23",
    source: "https://deepinfra.com/models",
    contextSource: "https://deepinfra.com/models",
    verifiedAt: "2025-07-23",
  },
  {
    id: "deepinfra:zai-org/GLM-4.5",
    provider: "deepinfra",
    vendorId: "zai-org/GLM-4.5",
    displayName: "GLM-4.5",
    family: "zai-org/GLM-4.5",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":98304},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":2.2},
    pricingSource: "models.dev",
    aliases: ["deepinfra/zai-org/GLM-4.5"],
    releasedAt: "2025-07-28",
    source: "https://deepinfra.com/models",
    contextSource: "https://deepinfra.com/models",
    verifiedAt: "2025-07-28",
  },
  {
    id: "deepseek:deepseek-chat",
    provider: "deepseek",
    vendorId: "deepseek-chat",
    displayName: "DeepSeek Chat",
    family: "deepseek-chat",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.57,"outputPerMTokens":1.68},
    pricingSource: "models.dev",
    aliases: ["deepseek/deepseek-chat"],
    releasedAt: "2024-12-26",
    source: "https://platform.deepseek.com/api-docs/pricing",
    contextSource: "https://platform.deepseek.com/api-docs/pricing",
    verifiedAt: "2025-08-21",
  },
  {
    id: "deepseek:deepseek-reasoner",
    provider: "deepseek",
    vendorId: "deepseek-reasoner",
    displayName: "DeepSeek Reasoner",
    family: "deepseek-reasoner",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.57,"outputPerMTokens":1.68},
    pricingSource: "models.dev",
    aliases: ["deepseek/deepseek-reasoner"],
    releasedAt: "2025-01-20",
    source: "https://platform.deepseek.com/api-docs/pricing",
    contextSource: "https://platform.deepseek.com/api-docs/pricing",
    verifiedAt: "2025-08-21",
  },
  {
    id: "fastrouter:anthropic/claude-opus-4.1",
    provider: "fastrouter",
    vendorId: "anthropic/claude-opus-4.1",
    displayName: "Claude Opus 4.1",
    family: "anthropic/claude-opus-4.1",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["fastrouter/anthropic/claude-opus-4.1"],
    releasedAt: "2025-08-05",
    source: "https://fastrouter.ai/models",
    contextSource: "https://fastrouter.ai/models",
    verifiedAt: "2025-08-05",
  },
  {
    id: "fastrouter:anthropic/claude-sonnet-4",
    provider: "fastrouter",
    vendorId: "anthropic/claude-sonnet-4",
    displayName: "Claude Sonnet 4",
    family: "anthropic/claude-sonnet-4",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["fastrouter/anthropic/claude-sonnet-4"],
    releasedAt: "2025-05-22",
    source: "https://fastrouter.ai/models",
    contextSource: "https://fastrouter.ai/models",
    verifiedAt: "2025-05-22",
  },
  {
    id: "fastrouter:deepseek-ai/deepseek-r1-distill-llama-70b",
    provider: "fastrouter",
    vendorId: "deepseek-ai/deepseek-r1-distill-llama-70b",
    displayName: "DeepSeek R1 Distill Llama 70B",
    family: "deepseek-ai/deepseek-r1-distill-llama-70b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.03,"outputPerMTokens":0.14},
    pricingSource: "models.dev",
    aliases: ["fastrouter/deepseek-ai/deepseek-r1-distill-llama-70b"],
    releasedAt: "2025-01-23",
    source: "https://fastrouter.ai/models",
    contextSource: "https://fastrouter.ai/models",
    verifiedAt: "2025-01-23",
  },
  {
    id: "fastrouter:google/gemini-2.5-flash",
    provider: "fastrouter",
    vendorId: "google/gemini-2.5-flash",
    displayName: "Gemini 2.5 Flash",
    family: "google/gemini-2.5-flash",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":2.5},
    pricingSource: "models.dev",
    aliases: ["fastrouter/google/gemini-2.5-flash"],
    releasedAt: "2025-06-17",
    source: "https://fastrouter.ai/models",
    contextSource: "https://fastrouter.ai/models",
    verifiedAt: "2025-06-17",
  },
  {
    id: "fastrouter:google/gemini-2.5-pro",
    provider: "fastrouter",
    vendorId: "google/gemini-2.5-pro",
    displayName: "Gemini 2.5 Pro",
    family: "google/gemini-2.5-pro",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["fastrouter/google/gemini-2.5-pro"],
    releasedAt: "2025-06-17",
    source: "https://fastrouter.ai/models",
    contextSource: "https://fastrouter.ai/models",
    verifiedAt: "2025-06-17",
  },
  {
    id: "fastrouter:moonshotai/kimi-k2",
    provider: "fastrouter",
    vendorId: "moonshotai/kimi-k2",
    displayName: "Kimi K2",
    family: "moonshotai/kimi-k2",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.55,"outputPerMTokens":2.2},
    pricingSource: "models.dev",
    aliases: ["fastrouter/moonshotai/kimi-k2"],
    releasedAt: "2025-07-11",
    source: "https://fastrouter.ai/models",
    contextSource: "https://fastrouter.ai/models",
    verifiedAt: "2025-07-11",
  },
  {
    id: "fastrouter:openai/gpt-4.1",
    provider: "fastrouter",
    vendorId: "openai/gpt-4.1",
    displayName: "GPT-4.1",
    family: "openai/gpt-4.1",
    status: "stable",
    context: {"combinedMax":1047576,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":8},
    pricingSource: "models.dev",
    aliases: ["fastrouter/openai/gpt-4.1"],
    releasedAt: "2025-04-14",
    source: "https://fastrouter.ai/models",
    contextSource: "https://fastrouter.ai/models",
    verifiedAt: "2025-04-14",
  },
  {
    id: "fastrouter:openai/gpt-5",
    provider: "fastrouter",
    vendorId: "openai/gpt-5",
    displayName: "GPT-5",
    family: "openai/gpt-5",
    status: "stable",
    context: {"combinedMax":400000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["fastrouter/openai/gpt-5"],
    releasedAt: "2025-08-07",
    source: "https://fastrouter.ai/models",
    contextSource: "https://fastrouter.ai/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "fastrouter:openai/gpt-5-mini",
    provider: "fastrouter",
    vendorId: "openai/gpt-5-mini",
    displayName: "GPT-5 Mini",
    family: "openai/gpt-5-mini",
    status: "stable",
    context: {"combinedMax":400000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.25,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["fastrouter/openai/gpt-5-mini"],
    releasedAt: "2025-08-07",
    source: "https://fastrouter.ai/models",
    contextSource: "https://fastrouter.ai/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "fastrouter:openai/gpt-5-nano",
    provider: "fastrouter",
    vendorId: "openai/gpt-5-nano",
    displayName: "GPT-5 Nano",
    family: "openai/gpt-5-nano",
    status: "stable",
    context: {"combinedMax":400000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.05,"outputPerMTokens":0.4},
    pricingSource: "models.dev",
    aliases: ["fastrouter/openai/gpt-5-nano"],
    releasedAt: "2025-08-07",
    source: "https://fastrouter.ai/models",
    contextSource: "https://fastrouter.ai/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "fastrouter:openai/gpt-oss-120b",
    provider: "fastrouter",
    vendorId: "openai/gpt-oss-120b",
    displayName: "GPT OSS 120B",
    family: "openai/gpt-oss-120b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["fastrouter/openai/gpt-oss-120b"],
    releasedAt: "2025-08-05",
    source: "https://fastrouter.ai/models",
    contextSource: "https://fastrouter.ai/models",
    verifiedAt: "2025-08-05",
  },
  {
    id: "fastrouter:openai/gpt-oss-20b",
    provider: "fastrouter",
    vendorId: "openai/gpt-oss-20b",
    displayName: "GPT OSS 20B",
    family: "openai/gpt-oss-20b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.05,"outputPerMTokens":0.2},
    pricingSource: "models.dev",
    aliases: ["fastrouter/openai/gpt-oss-20b"],
    releasedAt: "2025-08-05",
    source: "https://fastrouter.ai/models",
    contextSource: "https://fastrouter.ai/models",
    verifiedAt: "2025-08-05",
  },
  {
    id: "fastrouter:qwen/qwen3-coder",
    provider: "fastrouter",
    vendorId: "qwen/qwen3-coder",
    displayName: "Qwen3 Coder",
    family: "qwen/qwen3-coder",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":66536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":1.2},
    pricingSource: "models.dev",
    aliases: ["fastrouter/qwen/qwen3-coder"],
    releasedAt: "2025-07-23",
    source: "https://fastrouter.ai/models",
    contextSource: "https://fastrouter.ai/models",
    verifiedAt: "2025-07-23",
  },
  {
    id: "fastrouter:x-ai/grok-4",
    provider: "fastrouter",
    vendorId: "x-ai/grok-4",
    displayName: "Grok 4",
    family: "x-ai/grok-4",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["fastrouter/x-ai/grok-4"],
    releasedAt: "2025-07-09",
    source: "https://fastrouter.ai/models",
    contextSource: "https://fastrouter.ai/models",
    verifiedAt: "2025-07-09",
  },
  {
    id: "fireworks-ai:accounts/fireworks/gpt-oss-120b",
    provider: "fireworks-ai",
    vendorId: "accounts/fireworks/gpt-oss-120b",
    displayName: "GPT OSS 120B",
    family: "accounts/fireworks/gpt-oss-120b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["fireworks-ai/accounts/fireworks/gpt-oss-120b"],
    releasedAt: "2025-08-05",
    source: "https://fireworks.ai/docs/",
    contextSource: "https://fireworks.ai/docs/",
    verifiedAt: "2025-08-05",
  },
  {
    id: "fireworks-ai:accounts/fireworks/gpt-oss-20b",
    provider: "fireworks-ai",
    vendorId: "accounts/fireworks/gpt-oss-20b",
    displayName: "GPT OSS 20B",
    family: "accounts/fireworks/gpt-oss-20b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.05,"outputPerMTokens":0.2},
    pricingSource: "models.dev",
    aliases: ["fireworks-ai/accounts/fireworks/gpt-oss-20b"],
    releasedAt: "2025-08-05",
    source: "https://fireworks.ai/docs/",
    contextSource: "https://fireworks.ai/docs/",
    verifiedAt: "2025-08-05",
  },
  {
    id: "fireworks-ai:accounts/fireworks/models/deepseek-r1-0528",
    provider: "fireworks-ai",
    vendorId: "accounts/fireworks/models/deepseek-r1-0528",
    displayName: "Deepseek R1 05/28",
    family: "accounts/fireworks/models/deepseek-r1-0528",
    status: "stable",
    context: {"combinedMax":160000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":8},
    pricingSource: "models.dev",
    aliases: ["fireworks-ai/accounts/fireworks/models/deepseek-r1-0528"],
    releasedAt: "2025-05-28",
    source: "https://fireworks.ai/docs/",
    contextSource: "https://fireworks.ai/docs/",
    verifiedAt: "2025-05-28",
  },
  {
    id: "fireworks-ai:accounts/fireworks/models/deepseek-v3-0324",
    provider: "fireworks-ai",
    vendorId: "accounts/fireworks/models/deepseek-v3-0324",
    displayName: "Deepseek V3 03-24",
    family: "accounts/fireworks/models/deepseek-v3-0324",
    status: "stable",
    context: {"combinedMax":160000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.9,"outputPerMTokens":0.9},
    pricingSource: "models.dev",
    aliases: ["fireworks-ai/accounts/fireworks/models/deepseek-v3-0324"],
    releasedAt: "2025-03-24",
    source: "https://fireworks.ai/docs/",
    contextSource: "https://fireworks.ai/docs/",
    verifiedAt: "2025-03-24",
  },
  {
    id: "fireworks-ai:accounts/fireworks/models/deepseek-v3p1",
    provider: "fireworks-ai",
    vendorId: "accounts/fireworks/models/deepseek-v3p1",
    displayName: "DeepSeek V3.1",
    family: "accounts/fireworks/models/deepseek-v3p1",
    status: "stable",
    context: {"combinedMax":163840,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.56,"outputPerMTokens":1.68},
    pricingSource: "models.dev",
    aliases: ["fireworks-ai/accounts/fireworks/models/deepseek-v3p1"],
    releasedAt: "2025-08-21",
    source: "https://fireworks.ai/docs/",
    contextSource: "https://fireworks.ai/docs/",
    verifiedAt: "2025-08-21",
  },
  {
    id: "fireworks-ai:accounts/fireworks/models/glm-4p5",
    provider: "fireworks-ai",
    vendorId: "accounts/fireworks/models/glm-4p5",
    displayName: "GLM 4.5",
    family: "accounts/fireworks/models/glm-4p5",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.55,"outputPerMTokens":2.19},
    pricingSource: "models.dev",
    aliases: ["fireworks-ai/accounts/fireworks/models/glm-4p5"],
    releasedAt: "2025-07-29",
    source: "https://fireworks.ai/docs/",
    contextSource: "https://fireworks.ai/docs/",
    verifiedAt: "2025-07-29",
  },
  {
    id: "fireworks-ai:accounts/fireworks/models/glm-4p5-air",
    provider: "fireworks-ai",
    vendorId: "accounts/fireworks/models/glm-4p5-air",
    displayName: "GLM 4.5 Air",
    family: "accounts/fireworks/models/glm-4p5-air",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.22,"outputPerMTokens":0.88},
    pricingSource: "models.dev",
    aliases: ["fireworks-ai/accounts/fireworks/models/glm-4p5-air"],
    releasedAt: "2025-08-01",
    source: "https://fireworks.ai/docs/",
    contextSource: "https://fireworks.ai/docs/",
    verifiedAt: "2025-08-01",
  },
  {
    id: "fireworks-ai:accounts/fireworks/models/kimi-k2-instruct",
    provider: "fireworks-ai",
    vendorId: "accounts/fireworks/models/kimi-k2-instruct",
    displayName: "Kimi K2 Instruct",
    family: "accounts/fireworks/models/kimi-k2-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1,"outputPerMTokens":3},
    pricingSource: "models.dev",
    aliases: ["fireworks-ai/accounts/fireworks/models/kimi-k2-instruct"],
    releasedAt: "2025-07-11",
    source: "https://fireworks.ai/docs/",
    contextSource: "https://fireworks.ai/docs/",
    verifiedAt: "2025-07-11",
  },
  {
    id: "fireworks-ai:accounts/fireworks/models/qwen3-235b-a22b",
    provider: "fireworks-ai",
    vendorId: "accounts/fireworks/models/qwen3-235b-a22b",
    displayName: "Qwen3 235B-A22B",
    family: "accounts/fireworks/models/qwen3-235b-a22b",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.22,"outputPerMTokens":0.88},
    pricingSource: "models.dev",
    aliases: ["fireworks-ai/accounts/fireworks/models/qwen3-235b-a22b"],
    releasedAt: "2025-04-29",
    source: "https://fireworks.ai/docs/",
    contextSource: "https://fireworks.ai/docs/",
    verifiedAt: "2025-04-29",
  },
  {
    id: "fireworks-ai:accounts/fireworks/models/qwen3-coder-480b-a35b-instruct",
    provider: "fireworks-ai",
    vendorId: "accounts/fireworks/models/qwen3-coder-480b-a35b-instruct",
    displayName: "Qwen3 Coder 480B A35B Instruct",
    family: "accounts/fireworks/models/qwen3-coder-480b-a35b-instruct",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.45,"outputPerMTokens":1.8},
    pricingSource: "models.dev",
    aliases: ["fireworks-ai/accounts/fireworks/models/qwen3-coder-480b-a35b-instruct"],
    releasedAt: "2025-07-22",
    source: "https://fireworks.ai/docs/",
    contextSource: "https://fireworks.ai/docs/",
    verifiedAt: "2025-07-22",
  },
  {
    id: "github-copilot:claude-3.5-sonnet",
    provider: "github-copilot",
    vendorId: "claude-3.5-sonnet",
    displayName: "Claude Sonnet 3.5",
    family: "claude-3.5-sonnet",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricingSource: "models.dev",
    aliases: ["github-copilot/claude-3.5-sonnet"],
    releasedAt: "2024-10-22",
    source: "https://docs.github.com/en/copilot",
    contextSource: "https://docs.github.com/en/copilot",
    verifiedAt: "2024-10-22",
  },
  {
    id: "github-copilot:claude-3.7-sonnet",
    provider: "github-copilot",
    vendorId: "claude-3.7-sonnet",
    displayName: "Claude Sonnet 3.7",
    family: "claude-3.7-sonnet",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricingSource: "models.dev",
    aliases: ["github-copilot/claude-3.7-sonnet"],
    releasedAt: "2025-02-19",
    source: "https://docs.github.com/en/copilot",
    contextSource: "https://docs.github.com/en/copilot",
    verifiedAt: "2025-02-19",
  },
  {
    id: "github-copilot:claude-3.7-sonnet-thought",
    provider: "github-copilot",
    vendorId: "claude-3.7-sonnet-thought",
    displayName: "Claude Sonnet 3.7 Thinking",
    family: "claude-3.7-sonnet-thought",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricingSource: "models.dev",
    aliases: ["github-copilot/claude-3.7-sonnet-thought"],
    releasedAt: "2025-02-19",
    source: "https://docs.github.com/en/copilot",
    contextSource: "https://docs.github.com/en/copilot",
    verifiedAt: "2025-02-19",
  },
  {
    id: "github-copilot:claude-opus-4",
    provider: "github-copilot",
    vendorId: "claude-opus-4",
    displayName: "Claude Opus 4",
    family: "claude-opus-4",
    status: "stable",
    context: {"combinedMax":80000,"outputMax":16000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricingSource: "models.dev",
    aliases: ["github-copilot/claude-opus-4"],
    releasedAt: "2025-05-22",
    source: "https://docs.github.com/en/copilot",
    contextSource: "https://docs.github.com/en/copilot",
    verifiedAt: "2025-05-22",
  },
  {
    id: "github-copilot:claude-opus-41",
    provider: "github-copilot",
    vendorId: "claude-opus-41",
    displayName: "Claude Opus 4.1",
    family: "claude-opus-41",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricingSource: "models.dev",
    aliases: ["github-copilot/claude-opus-41"],
    releasedAt: "2025-08-05",
    source: "https://docs.github.com/en/copilot",
    contextSource: "https://docs.github.com/en/copilot",
    verifiedAt: "2025-08-05",
  },
  {
    id: "github-copilot:claude-sonnet-4",
    provider: "github-copilot",
    vendorId: "claude-sonnet-4",
    displayName: "Claude Sonnet 4",
    family: "claude-sonnet-4",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricingSource: "models.dev",
    aliases: ["github-copilot/claude-sonnet-4"],
    releasedAt: "2025-05-22",
    source: "https://docs.github.com/en/copilot",
    contextSource: "https://docs.github.com/en/copilot",
    verifiedAt: "2025-05-22",
  },
  {
    id: "github-copilot:gemini-2.0-flash-001",
    provider: "github-copilot",
    vendorId: "gemini-2.0-flash-001",
    displayName: "Gemini 2.0 Flash",
    family: "gemini-2.0-flash-001",
    status: "stable",
    context: {"combinedMax":1000000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricingSource: "models.dev",
    aliases: ["github-copilot/gemini-2.0-flash-001"],
    releasedAt: "2024-12-11",
    source: "https://docs.github.com/en/copilot",
    contextSource: "https://docs.github.com/en/copilot",
    verifiedAt: "2024-12-11",
  },
  {
    id: "github-copilot:gemini-2.5-pro",
    provider: "github-copilot",
    vendorId: "gemini-2.5-pro",
    displayName: "Gemini 2.5 Pro",
    family: "gemini-2.5-pro",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricingSource: "models.dev",
    aliases: ["github-copilot/gemini-2.5-pro"],
    releasedAt: "2025-03-20",
    source: "https://docs.github.com/en/copilot",
    contextSource: "https://docs.github.com/en/copilot",
    verifiedAt: "2025-06-05",
  },
  {
    id: "github-copilot:gpt-4.1",
    provider: "github-copilot",
    vendorId: "gpt-4.1",
    displayName: "GPT-4.1",
    family: "gpt-4.1",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricingSource: "models.dev",
    aliases: ["github-copilot/gpt-4.1"],
    releasedAt: "2025-04-14",
    source: "https://docs.github.com/en/copilot",
    contextSource: "https://docs.github.com/en/copilot",
    verifiedAt: "2025-04-14",
  },
  {
    id: "github-copilot:gpt-4o",
    provider: "github-copilot",
    vendorId: "gpt-4o",
    displayName: "GPT-4o",
    family: "gpt-4o",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricingSource: "models.dev",
    aliases: ["github-copilot/gpt-4o"],
    releasedAt: "2024-05-13",
    source: "https://docs.github.com/en/copilot",
    contextSource: "https://docs.github.com/en/copilot",
    verifiedAt: "2024-05-13",
  },
  {
    id: "github-copilot:gpt-5",
    provider: "github-copilot",
    vendorId: "gpt-5",
    displayName: "GPT-5",
    family: "gpt-5",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricingSource: "models.dev",
    aliases: ["github-copilot/gpt-5"],
    releasedAt: "2025-08-07",
    source: "https://docs.github.com/en/copilot",
    contextSource: "https://docs.github.com/en/copilot",
    verifiedAt: "2025-08-07",
  },
  {
    id: "github-copilot:gpt-5-mini",
    provider: "github-copilot",
    vendorId: "gpt-5-mini",
    displayName: "GPT-5-mini",
    family: "gpt-5-mini",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricingSource: "models.dev",
    aliases: ["github-copilot/gpt-5-mini"],
    releasedAt: "2025-08-13",
    source: "https://docs.github.com/en/copilot",
    contextSource: "https://docs.github.com/en/copilot",
    verifiedAt: "2025-08-13",
  },
  {
    id: "github-copilot:grok-code-fast-1",
    provider: "github-copilot",
    vendorId: "grok-code-fast-1",
    displayName: "Grok Code Fast 1",
    family: "grok-code-fast-1",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":10000},
    modalities: {"textIn":true,"textOut":true},
    pricingSource: "models.dev",
    aliases: ["github-copilot/grok-code-fast-1"],
    releasedAt: "2025-08-27",
    source: "https://docs.github.com/en/copilot",
    contextSource: "https://docs.github.com/en/copilot",
    verifiedAt: "2025-08-27",
  },
  {
    id: "github-copilot:o3",
    provider: "github-copilot",
    vendorId: "o3",
    displayName: "o3 (Preview)",
    family: "o3",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricingSource: "models.dev",
    aliases: ["github-copilot/o3"],
    releasedAt: "2025-04-16",
    source: "https://docs.github.com/en/copilot",
    contextSource: "https://docs.github.com/en/copilot",
    verifiedAt: "2025-04-16",
  },
  {
    id: "github-copilot:o3-mini",
    provider: "github-copilot",
    vendorId: "o3-mini",
    displayName: "o3-mini",
    family: "o3-mini",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true},
    pricingSource: "models.dev",
    aliases: ["github-copilot/o3-mini"],
    releasedAt: "2024-12-20",
    source: "https://docs.github.com/en/copilot",
    contextSource: "https://docs.github.com/en/copilot",
    verifiedAt: "2025-01-29",
  },
  {
    id: "github-copilot:o4-mini",
    provider: "github-copilot",
    vendorId: "o4-mini",
    displayName: "o4-mini (Preview)",
    family: "o4-mini",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true},
    pricingSource: "models.dev",
    aliases: ["github-copilot/o4-mini"],
    releasedAt: "2025-04-16",
    source: "https://docs.github.com/en/copilot",
    contextSource: "https://docs.github.com/en/copilot",
    verifiedAt: "2025-04-16",
  },
  {
    id: "github-models:ai21-labs/ai21-jamba-1.5-large",
    provider: "github-models",
    vendorId: "ai21-labs/ai21-jamba-1.5-large",
    displayName: "AI21 Jamba 1.5 Large",
    family: "ai21-labs/ai21-jamba-1.5-large",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/ai21-labs/ai21-jamba-1.5-large"],
    releasedAt: "2024-08-29",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-08-29",
  },
  {
    id: "github-models:ai21-labs/ai21-jamba-1.5-mini",
    provider: "github-models",
    vendorId: "ai21-labs/ai21-jamba-1.5-mini",
    displayName: "AI21 Jamba 1.5 Mini",
    family: "ai21-labs/ai21-jamba-1.5-mini",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/ai21-labs/ai21-jamba-1.5-mini"],
    releasedAt: "2024-08-29",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-08-29",
  },
  {
    id: "github-models:cohere/cohere-command-a",
    provider: "github-models",
    vendorId: "cohere/cohere-command-a",
    displayName: "Cohere Command A",
    family: "cohere/cohere-command-a",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/cohere/cohere-command-a"],
    releasedAt: "2024-11-01",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-11-01",
  },
  {
    id: "github-models:cohere/cohere-command-r",
    provider: "github-models",
    vendorId: "cohere/cohere-command-r",
    displayName: "Cohere Command R",
    family: "cohere/cohere-command-r",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/cohere/cohere-command-r"],
    releasedAt: "2024-03-11",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-08-01",
  },
  {
    id: "github-models:cohere/cohere-command-r-08-2024",
    provider: "github-models",
    vendorId: "cohere/cohere-command-r-08-2024",
    displayName: "Cohere Command R 08-2024",
    family: "cohere/cohere-command-r-08-2024",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/cohere/cohere-command-r-08-2024"],
    releasedAt: "2024-08-01",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-08-01",
  },
  {
    id: "github-models:cohere/cohere-command-r-plus",
    provider: "github-models",
    vendorId: "cohere/cohere-command-r-plus",
    displayName: "Cohere Command R+",
    family: "cohere/cohere-command-r-plus",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/cohere/cohere-command-r-plus"],
    releasedAt: "2024-04-04",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-08-01",
  },
  {
    id: "github-models:cohere/cohere-command-r-plus-08-2024",
    provider: "github-models",
    vendorId: "cohere/cohere-command-r-plus-08-2024",
    displayName: "Cohere Command R+ 08-2024",
    family: "cohere/cohere-command-r-plus-08-2024",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/cohere/cohere-command-r-plus-08-2024"],
    releasedAt: "2024-08-01",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-08-01",
  },
  {
    id: "github-models:core42/jais-30b-chat",
    provider: "github-models",
    vendorId: "core42/jais-30b-chat",
    displayName: "JAIS 30b Chat",
    family: "core42/jais-30b-chat",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":2048},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/core42/jais-30b-chat"],
    releasedAt: "2023-08-30",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2023-08-30",
  },
  {
    id: "github-models:deepseek/deepseek-r1",
    provider: "github-models",
    vendorId: "deepseek/deepseek-r1",
    displayName: "DeepSeek-R1",
    family: "deepseek/deepseek-r1",
    status: "stable",
    context: {"combinedMax":65536,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/deepseek/deepseek-r1"],
    releasedAt: "2025-01-20",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2025-01-20",
  },
  {
    id: "github-models:deepseek/deepseek-r1-0528",
    provider: "github-models",
    vendorId: "deepseek/deepseek-r1-0528",
    displayName: "DeepSeek-R1-0528",
    family: "deepseek/deepseek-r1-0528",
    status: "stable",
    context: {"combinedMax":65536,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/deepseek/deepseek-r1-0528"],
    releasedAt: "2025-05-28",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2025-05-28",
  },
  {
    id: "github-models:deepseek/deepseek-v3-0324",
    provider: "github-models",
    vendorId: "deepseek/deepseek-v3-0324",
    displayName: "DeepSeek-V3-0324",
    family: "deepseek/deepseek-v3-0324",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/deepseek/deepseek-v3-0324"],
    releasedAt: "2025-03-24",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2025-03-24",
  },
  {
    id: "github-models:meta/llama-3.2-11b-vision-instruct",
    provider: "github-models",
    vendorId: "meta/llama-3.2-11b-vision-instruct",
    displayName: "Llama-3.2-11B-Vision-Instruct",
    family: "meta/llama-3.2-11b-vision-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/meta/llama-3.2-11b-vision-instruct"],
    releasedAt: "2024-09-25",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-09-25",
  },
  {
    id: "github-models:meta/llama-3.2-90b-vision-instruct",
    provider: "github-models",
    vendorId: "meta/llama-3.2-90b-vision-instruct",
    displayName: "Llama-3.2-90B-Vision-Instruct",
    family: "meta/llama-3.2-90b-vision-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/meta/llama-3.2-90b-vision-instruct"],
    releasedAt: "2024-09-25",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-09-25",
  },
  {
    id: "github-models:meta/llama-3.3-70b-instruct",
    provider: "github-models",
    vendorId: "meta/llama-3.3-70b-instruct",
    displayName: "Llama-3.3-70B-Instruct",
    family: "meta/llama-3.3-70b-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/meta/llama-3.3-70b-instruct"],
    releasedAt: "2024-12-06",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-12-06",
  },
  {
    id: "github-models:meta/llama-4-maverick-17b-128e-instruct-fp8",
    provider: "github-models",
    vendorId: "meta/llama-4-maverick-17b-128e-instruct-fp8",
    displayName: "Llama 4 Maverick 17B 128E Instruct FP8",
    family: "meta/llama-4-maverick-17b-128e-instruct-fp8",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/meta/llama-4-maverick-17b-128e-instruct-fp8"],
    releasedAt: "2025-01-31",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2025-01-31",
  },
  {
    id: "github-models:meta/llama-4-scout-17b-16e-instruct",
    provider: "github-models",
    vendorId: "meta/llama-4-scout-17b-16e-instruct",
    displayName: "Llama 4 Scout 17B 16E Instruct",
    family: "meta/llama-4-scout-17b-16e-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/meta/llama-4-scout-17b-16e-instruct"],
    releasedAt: "2025-01-31",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2025-01-31",
  },
  {
    id: "github-models:meta/meta-llama-3-70b-instruct",
    provider: "github-models",
    vendorId: "meta/meta-llama-3-70b-instruct",
    displayName: "Meta-Llama-3-70B-Instruct",
    family: "meta/meta-llama-3-70b-instruct",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":2048},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/meta/meta-llama-3-70b-instruct"],
    releasedAt: "2024-04-18",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-04-18",
  },
  {
    id: "github-models:meta/meta-llama-3-8b-instruct",
    provider: "github-models",
    vendorId: "meta/meta-llama-3-8b-instruct",
    displayName: "Meta-Llama-3-8B-Instruct",
    family: "meta/meta-llama-3-8b-instruct",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":2048},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/meta/meta-llama-3-8b-instruct"],
    releasedAt: "2024-04-18",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-04-18",
  },
  {
    id: "github-models:meta/meta-llama-3.1-405b-instruct",
    provider: "github-models",
    vendorId: "meta/meta-llama-3.1-405b-instruct",
    displayName: "Meta-Llama-3.1-405B-Instruct",
    family: "meta/meta-llama-3.1-405b-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/meta/meta-llama-3.1-405b-instruct"],
    releasedAt: "2024-07-23",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-07-23",
  },
  {
    id: "github-models:meta/meta-llama-3.1-70b-instruct",
    provider: "github-models",
    vendorId: "meta/meta-llama-3.1-70b-instruct",
    displayName: "Meta-Llama-3.1-70B-Instruct",
    family: "meta/meta-llama-3.1-70b-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/meta/meta-llama-3.1-70b-instruct"],
    releasedAt: "2024-07-23",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-07-23",
  },
  {
    id: "github-models:meta/meta-llama-3.1-8b-instruct",
    provider: "github-models",
    vendorId: "meta/meta-llama-3.1-8b-instruct",
    displayName: "Meta-Llama-3.1-8B-Instruct",
    family: "meta/meta-llama-3.1-8b-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/meta/meta-llama-3.1-8b-instruct"],
    releasedAt: "2024-07-23",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-07-23",
  },
  {
    id: "github-models:microsoft/mai-ds-r1",
    provider: "github-models",
    vendorId: "microsoft/mai-ds-r1",
    displayName: "MAI-DS-R1",
    family: "microsoft/mai-ds-r1",
    status: "stable",
    context: {"combinedMax":65536,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/microsoft/mai-ds-r1"],
    releasedAt: "2025-01-20",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2025-01-20",
  },
  {
    id: "github-models:microsoft/phi-3-medium-128k-instruct",
    provider: "github-models",
    vendorId: "microsoft/phi-3-medium-128k-instruct",
    displayName: "Phi-3-medium instruct (128k)",
    family: "microsoft/phi-3-medium-128k-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/microsoft/phi-3-medium-128k-instruct"],
    releasedAt: "2024-04-23",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-04-23",
  },
  {
    id: "github-models:microsoft/phi-3-medium-4k-instruct",
    provider: "github-models",
    vendorId: "microsoft/phi-3-medium-4k-instruct",
    displayName: "Phi-3-medium instruct (4k)",
    family: "microsoft/phi-3-medium-4k-instruct",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":1024},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/microsoft/phi-3-medium-4k-instruct"],
    releasedAt: "2024-04-23",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-04-23",
  },
  {
    id: "github-models:microsoft/phi-3-mini-128k-instruct",
    provider: "github-models",
    vendorId: "microsoft/phi-3-mini-128k-instruct",
    displayName: "Phi-3-mini instruct (128k)",
    family: "microsoft/phi-3-mini-128k-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/microsoft/phi-3-mini-128k-instruct"],
    releasedAt: "2024-04-23",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-04-23",
  },
  {
    id: "github-models:microsoft/phi-3-mini-4k-instruct",
    provider: "github-models",
    vendorId: "microsoft/phi-3-mini-4k-instruct",
    displayName: "Phi-3-mini instruct (4k)",
    family: "microsoft/phi-3-mini-4k-instruct",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":1024},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/microsoft/phi-3-mini-4k-instruct"],
    releasedAt: "2024-04-23",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-04-23",
  },
  {
    id: "github-models:microsoft/phi-3-small-128k-instruct",
    provider: "github-models",
    vendorId: "microsoft/phi-3-small-128k-instruct",
    displayName: "Phi-3-small instruct (128k)",
    family: "microsoft/phi-3-small-128k-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/microsoft/phi-3-small-128k-instruct"],
    releasedAt: "2024-04-23",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-04-23",
  },
  {
    id: "github-models:microsoft/phi-3-small-8k-instruct",
    provider: "github-models",
    vendorId: "microsoft/phi-3-small-8k-instruct",
    displayName: "Phi-3-small instruct (8k)",
    family: "microsoft/phi-3-small-8k-instruct",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":2048},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/microsoft/phi-3-small-8k-instruct"],
    releasedAt: "2024-04-23",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-04-23",
  },
  {
    id: "github-models:microsoft/phi-3.5-mini-instruct",
    provider: "github-models",
    vendorId: "microsoft/phi-3.5-mini-instruct",
    displayName: "Phi-3.5-mini instruct (128k)",
    family: "microsoft/phi-3.5-mini-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/microsoft/phi-3.5-mini-instruct"],
    releasedAt: "2024-08-20",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-08-20",
  },
  {
    id: "github-models:microsoft/phi-3.5-moe-instruct",
    provider: "github-models",
    vendorId: "microsoft/phi-3.5-moe-instruct",
    displayName: "Phi-3.5-MoE instruct (128k)",
    family: "microsoft/phi-3.5-moe-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/microsoft/phi-3.5-moe-instruct"],
    releasedAt: "2024-08-20",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-08-20",
  },
  {
    id: "github-models:microsoft/phi-3.5-vision-instruct",
    provider: "github-models",
    vendorId: "microsoft/phi-3.5-vision-instruct",
    displayName: "Phi-3.5-vision instruct (128k)",
    family: "microsoft/phi-3.5-vision-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/microsoft/phi-3.5-vision-instruct"],
    releasedAt: "2024-08-20",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-08-20",
  },
  {
    id: "github-models:microsoft/phi-4",
    provider: "github-models",
    vendorId: "microsoft/phi-4",
    displayName: "Phi-4",
    family: "microsoft/phi-4",
    status: "stable",
    context: {"combinedMax":16000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/microsoft/phi-4"],
    releasedAt: "2024-12-11",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-12-11",
  },
  {
    id: "github-models:microsoft/phi-4-mini-instruct",
    provider: "github-models",
    vendorId: "microsoft/phi-4-mini-instruct",
    displayName: "Phi-4-mini-instruct",
    family: "microsoft/phi-4-mini-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/microsoft/phi-4-mini-instruct"],
    releasedAt: "2024-12-11",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-12-11",
  },
  {
    id: "github-models:microsoft/phi-4-mini-reasoning",
    provider: "github-models",
    vendorId: "microsoft/phi-4-mini-reasoning",
    displayName: "Phi-4-mini-reasoning",
    family: "microsoft/phi-4-mini-reasoning",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/microsoft/phi-4-mini-reasoning"],
    releasedAt: "2024-12-11",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-12-11",
  },
  {
    id: "github-models:microsoft/phi-4-multimodal-instruct",
    provider: "github-models",
    vendorId: "microsoft/phi-4-multimodal-instruct",
    displayName: "Phi-4-multimodal-instruct",
    family: "microsoft/phi-4-multimodal-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/microsoft/phi-4-multimodal-instruct"],
    releasedAt: "2024-12-11",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-12-11",
  },
  {
    id: "github-models:microsoft/phi-4-reasoning",
    provider: "github-models",
    vendorId: "microsoft/phi-4-reasoning",
    displayName: "Phi-4-Reasoning",
    family: "microsoft/phi-4-reasoning",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/microsoft/phi-4-reasoning"],
    releasedAt: "2024-12-11",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-12-11",
  },
  {
    id: "github-models:mistral-ai/codestral-2501",
    provider: "github-models",
    vendorId: "mistral-ai/codestral-2501",
    displayName: "Codestral 25.01",
    family: "mistral-ai/codestral-2501",
    status: "stable",
    context: {"combinedMax":32000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/mistral-ai/codestral-2501"],
    releasedAt: "2025-01-01",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2025-01-01",
  },
  {
    id: "github-models:mistral-ai/ministral-3b",
    provider: "github-models",
    vendorId: "mistral-ai/ministral-3b",
    displayName: "Ministral 3B",
    family: "mistral-ai/ministral-3b",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/mistral-ai/ministral-3b"],
    releasedAt: "2024-10-22",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-10-22",
  },
  {
    id: "github-models:mistral-ai/mistral-large-2411",
    provider: "github-models",
    vendorId: "mistral-ai/mistral-large-2411",
    displayName: "Mistral Large 24.11",
    family: "mistral-ai/mistral-large-2411",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/mistral-ai/mistral-large-2411"],
    releasedAt: "2024-11-01",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-11-01",
  },
  {
    id: "github-models:mistral-ai/mistral-medium-2505",
    provider: "github-models",
    vendorId: "mistral-ai/mistral-medium-2505",
    displayName: "Mistral Medium 3 (25.05)",
    family: "mistral-ai/mistral-medium-2505",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/mistral-ai/mistral-medium-2505"],
    releasedAt: "2025-05-01",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2025-05-01",
  },
  {
    id: "github-models:mistral-ai/mistral-nemo",
    provider: "github-models",
    vendorId: "mistral-ai/mistral-nemo",
    displayName: "Mistral Nemo",
    family: "mistral-ai/mistral-nemo",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/mistral-ai/mistral-nemo"],
    releasedAt: "2024-07-18",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-07-18",
  },
  {
    id: "github-models:mistral-ai/mistral-small-2503",
    provider: "github-models",
    vendorId: "mistral-ai/mistral-small-2503",
    displayName: "Mistral Small 3.1",
    family: "mistral-ai/mistral-small-2503",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/mistral-ai/mistral-small-2503"],
    releasedAt: "2025-03-01",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2025-03-01",
  },
  {
    id: "github-models:openai/gpt-4.1",
    provider: "github-models",
    vendorId: "openai/gpt-4.1",
    displayName: "GPT-4.1",
    family: "openai/gpt-4.1",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/openai/gpt-4.1"],
    releasedAt: "2025-04-14",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2025-04-14",
  },
  {
    id: "github-models:openai/gpt-4.1-mini",
    provider: "github-models",
    vendorId: "openai/gpt-4.1-mini",
    displayName: "GPT-4.1-mini",
    family: "openai/gpt-4.1-mini",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/openai/gpt-4.1-mini"],
    releasedAt: "2025-04-14",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2025-04-14",
  },
  {
    id: "github-models:openai/gpt-4.1-nano",
    provider: "github-models",
    vendorId: "openai/gpt-4.1-nano",
    displayName: "GPT-4.1-nano",
    family: "openai/gpt-4.1-nano",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/openai/gpt-4.1-nano"],
    releasedAt: "2025-04-14",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2025-04-14",
  },
  {
    id: "github-models:openai/gpt-4o",
    provider: "github-models",
    vendorId: "openai/gpt-4o",
    displayName: "GPT-4o",
    family: "openai/gpt-4o",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/openai/gpt-4o"],
    releasedAt: "2024-05-13",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-05-13",
  },
  {
    id: "github-models:openai/gpt-4o-mini",
    provider: "github-models",
    vendorId: "openai/gpt-4o-mini",
    displayName: "GPT-4o mini",
    family: "openai/gpt-4o-mini",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/openai/gpt-4o-mini"],
    releasedAt: "2024-07-18",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-07-18",
  },
  {
    id: "github-models:openai/o1",
    provider: "github-models",
    vendorId: "openai/o1",
    displayName: "OpenAI o1",
    family: "openai/o1",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/openai/o1"],
    releasedAt: "2024-09-12",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-12-17",
  },
  {
    id: "github-models:openai/o1-mini",
    provider: "github-models",
    vendorId: "openai/o1-mini",
    displayName: "OpenAI o1-mini",
    family: "openai/o1-mini",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/openai/o1-mini"],
    releasedAt: "2024-09-12",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-12-17",
  },
  {
    id: "github-models:openai/o1-preview",
    provider: "github-models",
    vendorId: "openai/o1-preview",
    displayName: "OpenAI o1-preview",
    family: "openai/o1-preview",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/openai/o1-preview"],
    releasedAt: "2024-09-12",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-09-12",
  },
  {
    id: "github-models:openai/o3",
    provider: "github-models",
    vendorId: "openai/o3",
    displayName: "OpenAI o3",
    family: "openai/o3",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/openai/o3"],
    releasedAt: "2025-01-31",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2025-01-31",
  },
  {
    id: "github-models:openai/o3-mini",
    provider: "github-models",
    vendorId: "openai/o3-mini",
    displayName: "OpenAI o3-mini",
    family: "openai/o3-mini",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/openai/o3-mini"],
    releasedAt: "2025-01-31",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2025-01-31",
  },
  {
    id: "github-models:openai/o4-mini",
    provider: "github-models",
    vendorId: "openai/o4-mini",
    displayName: "OpenAI o4-mini",
    family: "openai/o4-mini",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/openai/o4-mini"],
    releasedAt: "2025-01-31",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2025-01-31",
  },
  {
    id: "github-models:xai/grok-3",
    provider: "github-models",
    vendorId: "xai/grok-3",
    displayName: "Grok 3",
    family: "xai/grok-3",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/xai/grok-3"],
    releasedAt: "2024-12-09",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-12-09",
  },
  {
    id: "github-models:xai/grok-3-mini",
    provider: "github-models",
    vendorId: "xai/grok-3-mini",
    displayName: "Grok 3 Mini",
    family: "xai/grok-3-mini",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["github-models/xai/grok-3-mini"],
    releasedAt: "2024-12-09",
    source: "https://docs.github.com/en/github-models",
    contextSource: "https://docs.github.com/en/github-models",
    verifiedAt: "2024-12-09",
  },
  {
    id: "google:gemini-1.5-flash",
    provider: "google",
    vendorId: "gemini-1.5-flash",
    displayName: "Gemini 1.5 Flash",
    family: "gemini-1.5-flash",
    status: "stable",
    context: {"combinedMax":1000000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.075,"outputPerMTokens":0.3},
    pricingSource: "models.dev",
    aliases: ["google/gemini-1.5-flash"],
    releasedAt: "2024-05-14",
    source: "https://ai.google.dev/gemini-api/docs/pricing",
    contextSource: "https://ai.google.dev/gemini-api/docs/pricing",
    verifiedAt: "2024-05-14",
  },
  {
    id: "google:gemini-1.5-flash-8b",
    provider: "google",
    vendorId: "gemini-1.5-flash-8b",
    displayName: "Gemini 1.5 Flash-8B",
    family: "gemini-1.5-flash-8b",
    status: "stable",
    context: {"combinedMax":1000000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.0375,"outputPerMTokens":0.15},
    pricingSource: "models.dev",
    aliases: ["google/gemini-1.5-flash-8b"],
    releasedAt: "2024-10-03",
    source: "https://ai.google.dev/gemini-api/docs/pricing",
    contextSource: "https://ai.google.dev/gemini-api/docs/pricing",
    verifiedAt: "2024-10-03",
  },
  {
    id: "google:gemini-1.5-pro",
    provider: "google",
    vendorId: "gemini-1.5-pro",
    displayName: "Gemini 1.5 Pro",
    family: "gemini-1.5-pro",
    status: "stable",
    context: {"combinedMax":1000000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":5},
    pricingSource: "models.dev",
    aliases: ["google/gemini-1.5-pro"],
    releasedAt: "2024-02-15",
    source: "https://ai.google.dev/gemini-api/docs/pricing",
    contextSource: "https://ai.google.dev/gemini-api/docs/pricing",
    verifiedAt: "2024-02-15",
  },
  {
    id: "google:gemini-2.0-flash",
    provider: "google",
    vendorId: "gemini-2.0-flash",
    displayName: "Gemini 2.0 Flash",
    family: "gemini-2.0-flash",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.4},
    pricingSource: "models.dev",
    aliases: ["google/gemini-2.0-flash"],
    releasedAt: "2024-12-11",
    source: "https://ai.google.dev/gemini-api/docs/pricing",
    contextSource: "https://ai.google.dev/gemini-api/docs/pricing",
    verifiedAt: "2024-12-11",
  },
  {
    id: "google:gemini-2.0-flash-lite",
    provider: "google",
    vendorId: "gemini-2.0-flash-lite",
    displayName: "Gemini 2.0 Flash Lite",
    family: "gemini-2.0-flash-lite",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.075,"outputPerMTokens":0.3},
    pricingSource: "models.dev",
    aliases: ["google/gemini-2.0-flash-lite"],
    releasedAt: "2024-12-11",
    source: "https://ai.google.dev/gemini-api/docs/pricing",
    contextSource: "https://ai.google.dev/gemini-api/docs/pricing",
    verifiedAt: "2024-12-11",
  },
  {
    id: "google:gemini-2.5-flash",
    provider: "google",
    vendorId: "gemini-2.5-flash",
    displayName: "Gemini 2.5 Flash",
    family: "gemini-2.5-flash",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":2.5},
    pricingSource: "models.dev",
    aliases: ["google/gemini-2.5-flash"],
    releasedAt: "2025-03-20",
    source: "https://ai.google.dev/gemini-api/docs/pricing",
    contextSource: "https://ai.google.dev/gemini-api/docs/pricing",
    verifiedAt: "2025-06-05",
  },
  {
    id: "google:gemini-2.5-flash-lite-preview-06-17",
    provider: "google",
    vendorId: "gemini-2.5-flash-lite-preview-06-17",
    displayName: "Gemini 2.5 Flash Lite Preview 06-17",
    family: "gemini-2.5-flash-lite-preview-06-17",
    status: "stable",
    context: {"combinedMax":65536,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.4},
    pricingSource: "models.dev",
    aliases: ["google/gemini-2.5-flash-lite-preview-06-17"],
    releasedAt: "2025-06-17",
    source: "https://ai.google.dev/gemini-api/docs/pricing",
    contextSource: "https://ai.google.dev/gemini-api/docs/pricing",
    verifiedAt: "2025-06-17",
  },
  {
    id: "google:gemini-2.5-flash-preview-04-17",
    provider: "google",
    vendorId: "gemini-2.5-flash-preview-04-17",
    displayName: "Gemini 2.5 Flash Preview 04-17",
    family: "gemini-2.5-flash-preview-04-17",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["google/gemini-2.5-flash-preview-04-17"],
    releasedAt: "2025-04-17",
    source: "https://ai.google.dev/gemini-api/docs/pricing",
    contextSource: "https://ai.google.dev/gemini-api/docs/pricing",
    verifiedAt: "2025-04-17",
  },
  {
    id: "google:gemini-2.5-flash-preview-05-20",
    provider: "google",
    vendorId: "gemini-2.5-flash-preview-05-20",
    displayName: "Gemini 2.5 Flash Preview 05-20",
    family: "gemini-2.5-flash-preview-05-20",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["google/gemini-2.5-flash-preview-05-20"],
    releasedAt: "2025-05-20",
    source: "https://ai.google.dev/gemini-api/docs/pricing",
    contextSource: "https://ai.google.dev/gemini-api/docs/pricing",
    verifiedAt: "2025-05-20",
  },
  {
    id: "google:gemini-2.5-pro",
    provider: "google",
    vendorId: "gemini-2.5-pro",
    displayName: "Gemini 2.5 Pro",
    family: "gemini-2.5-pro",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["google/gemini-2.5-pro"],
    releasedAt: "2025-03-20",
    source: "https://ai.google.dev/gemini-api/docs/pricing",
    contextSource: "https://ai.google.dev/gemini-api/docs/pricing",
    verifiedAt: "2025-06-05",
  },
  {
    id: "google:gemini-2.5-pro-preview-05-06",
    provider: "google",
    vendorId: "gemini-2.5-pro-preview-05-06",
    displayName: "Gemini 2.5 Pro Preview 05-06",
    family: "gemini-2.5-pro-preview-05-06",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["google/gemini-2.5-pro-preview-05-06"],
    releasedAt: "2025-05-06",
    source: "https://ai.google.dev/gemini-api/docs/pricing",
    contextSource: "https://ai.google.dev/gemini-api/docs/pricing",
    verifiedAt: "2025-05-06",
  },
  {
    id: "google:gemini-2.5-pro-preview-06-05",
    provider: "google",
    vendorId: "gemini-2.5-pro-preview-06-05",
    displayName: "Gemini 2.5 Pro Preview 06-05",
    family: "gemini-2.5-pro-preview-06-05",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["google/gemini-2.5-pro-preview-06-05"],
    releasedAt: "2025-06-05",
    source: "https://ai.google.dev/gemini-api/docs/pricing",
    contextSource: "https://ai.google.dev/gemini-api/docs/pricing",
    verifiedAt: "2025-06-05",
  },
  {
    id: "google-vertex:gemini-2.0-flash",
    provider: "google-vertex",
    vendorId: "gemini-2.0-flash",
    displayName: "Gemini 2.0 Flash",
    family: "gemini-2.0-flash",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.4},
    pricingSource: "models.dev",
    aliases: ["google-vertex/gemini-2.0-flash"],
    releasedAt: "2024-12-11",
    source: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    contextSource: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    verifiedAt: "2024-12-11",
  },
  {
    id: "google-vertex:gemini-2.0-flash-lite",
    provider: "google-vertex",
    vendorId: "gemini-2.0-flash-lite",
    displayName: "Gemini 2.0 Flash Lite",
    family: "gemini-2.0-flash-lite",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.075,"outputPerMTokens":0.3},
    pricingSource: "models.dev",
    aliases: ["google-vertex/gemini-2.0-flash-lite"],
    releasedAt: "2024-12-11",
    source: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    contextSource: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    verifiedAt: "2024-12-11",
  },
  {
    id: "google-vertex:gemini-2.5-flash",
    provider: "google-vertex",
    vendorId: "gemini-2.5-flash",
    displayName: "Gemini 2.5 Flash",
    family: "gemini-2.5-flash",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":2.5},
    pricingSource: "models.dev",
    aliases: ["google-vertex/gemini-2.5-flash"],
    releasedAt: "2025-06-17",
    source: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    contextSource: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    verifiedAt: "2025-06-17",
  },
  {
    id: "google-vertex:gemini-2.5-flash-lite-preview-06-17",
    provider: "google-vertex",
    vendorId: "gemini-2.5-flash-lite-preview-06-17",
    displayName: "Gemini 2.5 Flash Lite Preview 06-17",
    family: "gemini-2.5-flash-lite-preview-06-17",
    status: "stable",
    context: {"combinedMax":65536,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.4},
    pricingSource: "models.dev",
    aliases: ["google-vertex/gemini-2.5-flash-lite-preview-06-17"],
    releasedAt: "2025-06-17",
    source: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    contextSource: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    verifiedAt: "2025-06-17",
  },
  {
    id: "google-vertex:gemini-2.5-flash-preview-04-17",
    provider: "google-vertex",
    vendorId: "gemini-2.5-flash-preview-04-17",
    displayName: "Gemini 2.5 Flash Preview 04-17",
    family: "gemini-2.5-flash-preview-04-17",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["google-vertex/gemini-2.5-flash-preview-04-17"],
    releasedAt: "2025-04-17",
    source: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    contextSource: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    verifiedAt: "2025-04-17",
  },
  {
    id: "google-vertex:gemini-2.5-flash-preview-05-20",
    provider: "google-vertex",
    vendorId: "gemini-2.5-flash-preview-05-20",
    displayName: "Gemini 2.5 Flash Preview 05-20",
    family: "gemini-2.5-flash-preview-05-20",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["google-vertex/gemini-2.5-flash-preview-05-20"],
    releasedAt: "2025-05-20",
    source: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    contextSource: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    verifiedAt: "2025-05-20",
  },
  {
    id: "google-vertex:gemini-2.5-pro",
    provider: "google-vertex",
    vendorId: "gemini-2.5-pro",
    displayName: "Gemini 2.5 Pro",
    family: "gemini-2.5-pro",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["google-vertex/gemini-2.5-pro"],
    releasedAt: "2025-03-20",
    source: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    contextSource: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    verifiedAt: "2025-06-05",
  },
  {
    id: "google-vertex:gemini-2.5-pro-preview-05-06",
    provider: "google-vertex",
    vendorId: "gemini-2.5-pro-preview-05-06",
    displayName: "Gemini 2.5 Pro Preview 05-06",
    family: "gemini-2.5-pro-preview-05-06",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["google-vertex/gemini-2.5-pro-preview-05-06"],
    releasedAt: "2025-05-06",
    source: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    contextSource: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    verifiedAt: "2025-05-06",
  },
  {
    id: "google-vertex:gemini-2.5-pro-preview-06-05",
    provider: "google-vertex",
    vendorId: "gemini-2.5-pro-preview-06-05",
    displayName: "Gemini 2.5 Pro Preview 06-05",
    family: "gemini-2.5-pro-preview-06-05",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["google-vertex/gemini-2.5-pro-preview-06-05"],
    releasedAt: "2025-06-05",
    source: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    contextSource: "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
    verifiedAt: "2025-06-05",
  },
  {
    id: "google-vertex-anthropic:claude-3-5-haiku@20241022",
    provider: "google-vertex-anthropic",
    vendorId: "claude-3-5-haiku@20241022",
    displayName: "Claude Haiku 3.5",
    family: "claude-3-5-haiku@20241022",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.8,"outputPerMTokens":4},
    pricingSource: "models.dev",
    aliases: ["google-vertex-anthropic/claude-3-5-haiku@20241022"],
    releasedAt: "2024-10-22",
    source: "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude",
    contextSource: "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude",
    verifiedAt: "2024-10-22",
  },
  {
    id: "google-vertex-anthropic:claude-3-5-sonnet@20241022",
    provider: "google-vertex-anthropic",
    vendorId: "claude-3-5-sonnet@20241022",
    displayName: "Claude Sonnet 3.5 v2",
    family: "claude-3-5-sonnet@20241022",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["google-vertex-anthropic/claude-3-5-sonnet@20241022"],
    releasedAt: "2024-10-22",
    source: "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude",
    contextSource: "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude",
    verifiedAt: "2024-10-22",
  },
  {
    id: "google-vertex-anthropic:claude-3-7-sonnet@20250219",
    provider: "google-vertex-anthropic",
    vendorId: "claude-3-7-sonnet@20250219",
    displayName: "Claude Sonnet 3.7",
    family: "claude-3-7-sonnet@20250219",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["google-vertex-anthropic/claude-3-7-sonnet@20250219"],
    releasedAt: "2025-02-19",
    source: "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude",
    contextSource: "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude",
    verifiedAt: "2025-02-19",
  },
  {
    id: "google-vertex-anthropic:claude-opus-4-1@20250805",
    provider: "google-vertex-anthropic",
    vendorId: "claude-opus-4-1@20250805",
    displayName: "Claude Opus 4.1",
    family: "claude-opus-4-1@20250805",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["google-vertex-anthropic/claude-opus-4-1@20250805"],
    releasedAt: "2025-08-05",
    source: "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude",
    contextSource: "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude",
    verifiedAt: "2025-08-05",
  },
  {
    id: "google-vertex-anthropic:claude-opus-4@20250514",
    provider: "google-vertex-anthropic",
    vendorId: "claude-opus-4@20250514",
    displayName: "Claude Opus 4",
    family: "claude-opus-4@20250514",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["google-vertex-anthropic/claude-opus-4@20250514"],
    releasedAt: "2025-05-22",
    source: "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude",
    contextSource: "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude",
    verifiedAt: "2025-05-22",
  },
  {
    id: "google-vertex-anthropic:claude-sonnet-4@20250514",
    provider: "google-vertex-anthropic",
    vendorId: "claude-sonnet-4@20250514",
    displayName: "Claude Sonnet 4",
    family: "claude-sonnet-4@20250514",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["google-vertex-anthropic/claude-sonnet-4@20250514"],
    releasedAt: "2025-05-22",
    source: "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude",
    contextSource: "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude",
    verifiedAt: "2025-05-22",
  },
  {
    id: "groq:deepseek-r1-distill-llama-70b",
    provider: "groq",
    vendorId: "deepseek-r1-distill-llama-70b",
    displayName: "DeepSeek R1 Distill Llama 70B",
    family: "deepseek-r1-distill-llama-70b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.75,"outputPerMTokens":0.99},
    pricingSource: "models.dev",
    aliases: ["groq/deepseek-r1-distill-llama-70b"],
    releasedAt: "2025-01-20",
    source: "https://console.groq.com/docs/models",
    contextSource: "https://console.groq.com/docs/models",
    verifiedAt: "2025-01-20",
  },
  {
    id: "groq:gemma2-9b-it",
    provider: "groq",
    vendorId: "gemma2-9b-it",
    displayName: "Gemma 2 9B",
    family: "gemma2-9b-it",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.2},
    pricingSource: "models.dev",
    aliases: ["groq/gemma2-9b-it"],
    releasedAt: "2024-06-27",
    source: "https://console.groq.com/docs/models",
    contextSource: "https://console.groq.com/docs/models",
    verifiedAt: "2024-06-27",
  },
  {
    id: "groq:llama-3.1-8b-instant",
    provider: "groq",
    vendorId: "llama-3.1-8b-instant",
    displayName: "Llama 3.1 8B Instant",
    family: "llama-3.1-8b-instant",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.05,"outputPerMTokens":0.08},
    pricingSource: "models.dev",
    aliases: ["groq/llama-3.1-8b-instant"],
    releasedAt: "2024-07-23",
    source: "https://console.groq.com/docs/models",
    contextSource: "https://console.groq.com/docs/models",
    verifiedAt: "2024-07-23",
  },
  {
    id: "groq:llama-3.3-70b-versatile",
    provider: "groq",
    vendorId: "llama-3.3-70b-versatile",
    displayName: "Llama 3.3 70B Versatile",
    family: "llama-3.3-70b-versatile",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.59,"outputPerMTokens":0.79},
    pricingSource: "models.dev",
    aliases: ["groq/llama-3.3-70b-versatile"],
    releasedAt: "2024-12-06",
    source: "https://console.groq.com/docs/models",
    contextSource: "https://console.groq.com/docs/models",
    verifiedAt: "2024-12-06",
  },
  {
    id: "groq:llama-guard-3-8b",
    provider: "groq",
    vendorId: "llama-guard-3-8b",
    displayName: "Llama Guard 3 8B",
    family: "llama-guard-3-8b",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.2},
    pricingSource: "models.dev",
    aliases: ["groq/llama-guard-3-8b"],
    releasedAt: "2024-07-23",
    source: "https://console.groq.com/docs/models",
    contextSource: "https://console.groq.com/docs/models",
    verifiedAt: "2024-07-23",
  },
  {
    id: "groq:llama3-70b-8192",
    provider: "groq",
    vendorId: "llama3-70b-8192",
    displayName: "Llama 3 70B",
    family: "llama3-70b-8192",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.59,"outputPerMTokens":0.79},
    pricingSource: "models.dev",
    aliases: ["groq/llama3-70b-8192"],
    releasedAt: "2024-04-18",
    source: "https://console.groq.com/docs/models",
    contextSource: "https://console.groq.com/docs/models",
    verifiedAt: "2024-04-18",
  },
  {
    id: "groq:llama3-8b-8192",
    provider: "groq",
    vendorId: "llama3-8b-8192",
    displayName: "Llama 3 8B",
    family: "llama3-8b-8192",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.05,"outputPerMTokens":0.08},
    pricingSource: "models.dev",
    aliases: ["groq/llama3-8b-8192"],
    releasedAt: "2024-04-18",
    source: "https://console.groq.com/docs/models",
    contextSource: "https://console.groq.com/docs/models",
    verifiedAt: "2024-04-18",
  },
  {
    id: "groq:meta-llama/llama-4-maverick-17b-128e-instruct",
    provider: "groq",
    vendorId: "meta-llama/llama-4-maverick-17b-128e-instruct",
    displayName: "Llama 4 Maverick 17B",
    family: "meta-llama/llama-4-maverick-17b-128e-instruct",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["groq/meta-llama/llama-4-maverick-17b-128e-instruct"],
    releasedAt: "2025-04-05",
    source: "https://console.groq.com/docs/models",
    contextSource: "https://console.groq.com/docs/models",
    verifiedAt: "2025-04-05",
  },
  {
    id: "groq:meta-llama/llama-4-scout-17b-16e-instruct",
    provider: "groq",
    vendorId: "meta-llama/llama-4-scout-17b-16e-instruct",
    displayName: "Llama 4 Scout 17B",
    family: "meta-llama/llama-4-scout-17b-16e-instruct",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.11,"outputPerMTokens":0.34},
    pricingSource: "models.dev",
    aliases: ["groq/meta-llama/llama-4-scout-17b-16e-instruct"],
    releasedAt: "2025-04-05",
    source: "https://console.groq.com/docs/models",
    contextSource: "https://console.groq.com/docs/models",
    verifiedAt: "2025-04-05",
  },
  {
    id: "groq:meta-llama/llama-guard-4-12b",
    provider: "groq",
    vendorId: "meta-llama/llama-guard-4-12b",
    displayName: "Llama Guard 4 12B",
    family: "meta-llama/llama-guard-4-12b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":128},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.2},
    pricingSource: "models.dev",
    aliases: ["groq/meta-llama/llama-guard-4-12b"],
    releasedAt: "2025-04-05",
    source: "https://console.groq.com/docs/models",
    contextSource: "https://console.groq.com/docs/models",
    verifiedAt: "2025-04-05",
  },
  {
    id: "groq:mistral-saba-24b",
    provider: "groq",
    vendorId: "mistral-saba-24b",
    displayName: "Mistral Saba 24B",
    family: "mistral-saba-24b",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.79,"outputPerMTokens":0.79},
    pricingSource: "models.dev",
    aliases: ["groq/mistral-saba-24b"],
    releasedAt: "2025-02-06",
    source: "https://console.groq.com/docs/models",
    contextSource: "https://console.groq.com/docs/models",
    verifiedAt: "2025-02-06",
  },
  {
    id: "groq:moonshotai/kimi-k2-instruct",
    provider: "groq",
    vendorId: "moonshotai/kimi-k2-instruct",
    displayName: "Kimi K2 Instruct",
    family: "moonshotai/kimi-k2-instruct",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1,"outputPerMTokens":3},
    pricingSource: "models.dev",
    aliases: ["groq/moonshotai/kimi-k2-instruct"],
    releasedAt: "2025-07-14",
    source: "https://console.groq.com/docs/models",
    contextSource: "https://console.groq.com/docs/models",
    verifiedAt: "2025-07-14",
  },
  {
    id: "groq:moonshotai/kimi-k2-instruct-0905",
    provider: "groq",
    vendorId: "moonshotai/kimi-k2-instruct-0905",
    displayName: "Kimi K2 Instruct 0905",
    family: "moonshotai/kimi-k2-instruct-0905",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1,"outputPerMTokens":3},
    pricingSource: "models.dev",
    aliases: ["groq/moonshotai/kimi-k2-instruct-0905"],
    releasedAt: "2025-09-05",
    source: "https://console.groq.com/docs/models",
    contextSource: "https://console.groq.com/docs/models",
    verifiedAt: "2025-09-05",
  },
  {
    id: "groq:openai/gpt-oss-120b",
    provider: "groq",
    vendorId: "openai/gpt-oss-120b",
    displayName: "GPT OSS 120B",
    family: "openai/gpt-oss-120b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.75},
    pricingSource: "models.dev",
    aliases: ["groq/openai/gpt-oss-120b"],
    releasedAt: "2025-08-05",
    source: "https://console.groq.com/docs/models",
    contextSource: "https://console.groq.com/docs/models",
    verifiedAt: "2025-08-05",
  },
  {
    id: "groq:openai/gpt-oss-20b",
    provider: "groq",
    vendorId: "openai/gpt-oss-20b",
    displayName: "GPT OSS 20B",
    family: "openai/gpt-oss-20b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.5},
    pricingSource: "models.dev",
    aliases: ["groq/openai/gpt-oss-20b"],
    releasedAt: "2025-08-05",
    source: "https://console.groq.com/docs/models",
    contextSource: "https://console.groq.com/docs/models",
    verifiedAt: "2025-08-05",
  },
  {
    id: "groq:qwen-qwq-32b",
    provider: "groq",
    vendorId: "qwen-qwq-32b",
    displayName: "Qwen QwQ 32B",
    family: "qwen-qwq-32b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.29,"outputPerMTokens":0.39},
    pricingSource: "models.dev",
    aliases: ["groq/qwen-qwq-32b"],
    releasedAt: "2024-11-27",
    source: "https://console.groq.com/docs/models",
    contextSource: "https://console.groq.com/docs/models",
    verifiedAt: "2024-11-27",
  },
  {
    id: "groq:qwen/qwen3-32b",
    provider: "groq",
    vendorId: "qwen/qwen3-32b",
    displayName: "Qwen3 32B",
    family: "qwen/qwen3-32b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.29,"outputPerMTokens":0.59},
    pricingSource: "models.dev",
    aliases: ["groq/qwen/qwen3-32b"],
    releasedAt: "2024-12-23",
    source: "https://console.groq.com/docs/models",
    contextSource: "https://console.groq.com/docs/models",
    verifiedAt: "2024-12-23",
  },
  {
    id: "huggingface:deepseek-ai/DeepSeek-R1-0528",
    provider: "huggingface",
    vendorId: "deepseek-ai/DeepSeek-R1-0528",
    displayName: "DeepSeek-R1-0528",
    family: "deepseek-ai/DeepSeek-R1-0528",
    status: "stable",
    context: {"combinedMax":163840,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":5},
    pricingSource: "models.dev",
    aliases: ["huggingface/deepseek-ai/DeepSeek-R1-0528"],
    releasedAt: "2025-05-28",
    source: "https://huggingface.co/docs/inference-providers",
    contextSource: "https://huggingface.co/docs/inference-providers",
    verifiedAt: "2025-05-28",
  },
  {
    id: "huggingface:deepseek-ai/Deepseek-V3-0324",
    provider: "huggingface",
    vendorId: "deepseek-ai/Deepseek-V3-0324",
    displayName: "DeepSeek-V3-0324",
    family: "deepseek-ai/Deepseek-V3-0324",
    status: "stable",
    context: {"combinedMax":16384,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":1.25},
    pricingSource: "models.dev",
    aliases: ["huggingface/deepseek-ai/Deepseek-V3-0324"],
    releasedAt: "2025-03-24",
    source: "https://huggingface.co/docs/inference-providers",
    contextSource: "https://huggingface.co/docs/inference-providers",
    verifiedAt: "2025-03-24",
  },
  {
    id: "huggingface:moonshotai/Kimi-K2-Instruct",
    provider: "huggingface",
    vendorId: "moonshotai/Kimi-K2-Instruct",
    displayName: "Kimi-K2-Instruct",
    family: "moonshotai/Kimi-K2-Instruct",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1,"outputPerMTokens":3},
    pricingSource: "models.dev",
    aliases: ["huggingface/moonshotai/Kimi-K2-Instruct"],
    releasedAt: "2025-07-14",
    source: "https://huggingface.co/docs/inference-providers",
    contextSource: "https://huggingface.co/docs/inference-providers",
    verifiedAt: "2025-07-14",
  },
  {
    id: "huggingface:Qwen/Qwen3-235B-A22B-Thinking-2507",
    provider: "huggingface",
    vendorId: "Qwen/Qwen3-235B-A22B-Thinking-2507",
    displayName: "Qwen3-235B-A22B-Thinking-2507",
    family: "Qwen/Qwen3-235B-A22B-Thinking-2507",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":3},
    pricingSource: "models.dev",
    aliases: ["huggingface/Qwen/Qwen3-235B-A22B-Thinking-2507"],
    releasedAt: "2025-07-25",
    source: "https://huggingface.co/docs/inference-providers",
    contextSource: "https://huggingface.co/docs/inference-providers",
    verifiedAt: "2025-07-25",
  },
  {
    id: "huggingface:Qwen/Qwen3-Coder-480B-A35B-Instruct",
    provider: "huggingface",
    vendorId: "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    displayName: "Qwen3-Coder-480B-A35B-Instruct",
    family: "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":66536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["huggingface/Qwen/Qwen3-Coder-480B-A35B-Instruct"],
    releasedAt: "2025-07-23",
    source: "https://huggingface.co/docs/inference-providers",
    contextSource: "https://huggingface.co/docs/inference-providers",
    verifiedAt: "2025-07-23",
  },
  {
    id: "huggingface:zai-org/GLM-4.5",
    provider: "huggingface",
    vendorId: "zai-org/GLM-4.5",
    displayName: "GLM-4.5",
    family: "zai-org/GLM-4.5",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":98304},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":2.2},
    pricingSource: "models.dev",
    aliases: ["huggingface/zai-org/GLM-4.5"],
    releasedAt: "2025-07-28",
    source: "https://huggingface.co/docs/inference-providers",
    contextSource: "https://huggingface.co/docs/inference-providers",
    verifiedAt: "2025-07-28",
  },
  {
    id: "huggingface:zai-org/GLM-4.5-Air",
    provider: "huggingface",
    vendorId: "zai-org/GLM-4.5-Air",
    displayName: "GLM-4.5-Air",
    family: "zai-org/GLM-4.5-Air",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":96000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":1.1},
    pricingSource: "models.dev",
    aliases: ["huggingface/zai-org/GLM-4.5-Air"],
    releasedAt: "2025-07-28",
    source: "https://huggingface.co/docs/inference-providers",
    contextSource: "https://huggingface.co/docs/inference-providers",
    verifiedAt: "2025-07-28",
  },
  {
    id: "inception:mercury",
    provider: "inception",
    vendorId: "mercury",
    displayName: "Mercury",
    family: "mercury",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.25,"outputPerMTokens":1},
    pricingSource: "models.dev",
    aliases: ["inception/mercury"],
    releasedAt: "2025-06-26",
    source: "https://platform.inceptionlabs.ai/docs",
    contextSource: "https://platform.inceptionlabs.ai/docs",
    verifiedAt: "2025-07-31",
  },
  {
    id: "inception:mercury-coder",
    provider: "inception",
    vendorId: "mercury-coder",
    displayName: "Mercury Coder",
    family: "mercury-coder",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.25,"outputPerMTokens":1},
    pricingSource: "models.dev",
    aliases: ["inception/mercury-coder"],
    releasedAt: "2025-02-26",
    source: "https://platform.inceptionlabs.ai/docs",
    contextSource: "https://platform.inceptionlabs.ai/docs",
    verifiedAt: "2025-07-31",
  },
  {
    id: "inference:google/gemma-3",
    provider: "inference",
    vendorId: "google/gemma-3",
    displayName: "Google Gemma 3",
    family: "google/gemma-3",
    status: "stable",
    context: {"combinedMax":125000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.3},
    pricingSource: "models.dev",
    aliases: ["inference/google/gemma-3"],
    releasedAt: "2025-01-01",
    source: "https://inference.net/models",
    contextSource: "https://inference.net/models",
    verifiedAt: "2025-01-01",
  },
  {
    id: "inference:meta/llama-3.1-8b-instruct",
    provider: "inference",
    vendorId: "meta/llama-3.1-8b-instruct",
    displayName: "Llama 3.1 8B Instruct",
    family: "meta/llama-3.1-8b-instruct",
    status: "stable",
    context: {"combinedMax":16000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.025,"outputPerMTokens":0.025},
    pricingSource: "models.dev",
    aliases: ["inference/meta/llama-3.1-8b-instruct"],
    releasedAt: "2025-01-01",
    source: "https://inference.net/models",
    contextSource: "https://inference.net/models",
    verifiedAt: "2025-01-01",
  },
  {
    id: "inference:meta/llama-3.2-11b-vision-instruct",
    provider: "inference",
    vendorId: "meta/llama-3.2-11b-vision-instruct",
    displayName: "Llama 3.2 11B Vision Instruct",
    family: "meta/llama-3.2-11b-vision-instruct",
    status: "stable",
    context: {"combinedMax":16000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.055,"outputPerMTokens":0.055},
    pricingSource: "models.dev",
    aliases: ["inference/meta/llama-3.2-11b-vision-instruct"],
    releasedAt: "2025-01-01",
    source: "https://inference.net/models",
    contextSource: "https://inference.net/models",
    verifiedAt: "2025-01-01",
  },
  {
    id: "inference:meta/llama-3.2-1b-instruct",
    provider: "inference",
    vendorId: "meta/llama-3.2-1b-instruct",
    displayName: "Llama 3.2 1B Instruct",
    family: "meta/llama-3.2-1b-instruct",
    status: "stable",
    context: {"combinedMax":16000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.01,"outputPerMTokens":0.01},
    pricingSource: "models.dev",
    aliases: ["inference/meta/llama-3.2-1b-instruct"],
    releasedAt: "2025-01-01",
    source: "https://inference.net/models",
    contextSource: "https://inference.net/models",
    verifiedAt: "2025-01-01",
  },
  {
    id: "inference:meta/llama-3.2-3b-instruct",
    provider: "inference",
    vendorId: "meta/llama-3.2-3b-instruct",
    displayName: "Llama 3.2 3B Instruct",
    family: "meta/llama-3.2-3b-instruct",
    status: "stable",
    context: {"combinedMax":16000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.02,"outputPerMTokens":0.02},
    pricingSource: "models.dev",
    aliases: ["inference/meta/llama-3.2-3b-instruct"],
    releasedAt: "2025-01-01",
    source: "https://inference.net/models",
    contextSource: "https://inference.net/models",
    verifiedAt: "2025-01-01",
  },
  {
    id: "inference:mistral/mistral-nemo-12b-instruct",
    provider: "inference",
    vendorId: "mistral/mistral-nemo-12b-instruct",
    displayName: "Mistral Nemo 12B Instruct",
    family: "mistral/mistral-nemo-12b-instruct",
    status: "stable",
    context: {"combinedMax":16000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.038,"outputPerMTokens":0.1},
    pricingSource: "models.dev",
    aliases: ["inference/mistral/mistral-nemo-12b-instruct"],
    releasedAt: "2025-01-01",
    source: "https://inference.net/models",
    contextSource: "https://inference.net/models",
    verifiedAt: "2025-01-01",
  },
  {
    id: "inference:osmosis/osmosis-structure-0.6b",
    provider: "inference",
    vendorId: "osmosis/osmosis-structure-0.6b",
    displayName: "Osmosis Structure 0.6B",
    family: "osmosis/osmosis-structure-0.6b",
    status: "stable",
    context: {"combinedMax":4000,"outputMax":2048},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.5},
    pricingSource: "models.dev",
    aliases: ["inference/osmosis/osmosis-structure-0.6b"],
    releasedAt: "2025-01-01",
    source: "https://inference.net/models",
    contextSource: "https://inference.net/models",
    verifiedAt: "2025-01-01",
  },
  {
    id: "inference:qwen/qwen-2.5-7b-vision-instruct",
    provider: "inference",
    vendorId: "qwen/qwen-2.5-7b-vision-instruct",
    displayName: "Qwen 2.5 7B Vision Instruct",
    family: "qwen/qwen-2.5-7b-vision-instruct",
    status: "stable",
    context: {"combinedMax":125000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.2},
    pricingSource: "models.dev",
    aliases: ["inference/qwen/qwen-2.5-7b-vision-instruct"],
    releasedAt: "2025-01-01",
    source: "https://inference.net/models",
    contextSource: "https://inference.net/models",
    verifiedAt: "2025-01-01",
  },
  {
    id: "inference:qwen/qwen3-embedding-4b",
    provider: "inference",
    vendorId: "qwen/qwen3-embedding-4b",
    displayName: "Qwen 3 Embedding 4B",
    family: "qwen/qwen3-embedding-4b",
    status: "stable",
    context: {"combinedMax":32000,"outputMax":2048},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.01,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["inference/qwen/qwen3-embedding-4b"],
    releasedAt: "2025-01-01",
    source: "https://inference.net/models",
    contextSource: "https://inference.net/models",
    verifiedAt: "2025-01-01",
  },
  {
    id: "llama:cerebras-llama-4-maverick-17b-128e-instruct",
    provider: "llama",
    vendorId: "cerebras-llama-4-maverick-17b-128e-instruct",
    displayName: "Cerebras-Llama-4-Maverick-17B-128E-Instruct",
    family: "cerebras-llama-4-maverick-17b-128e-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["llama/cerebras-llama-4-maverick-17b-128e-instruct"],
    releasedAt: "2025-04-05",
    source: "https://llama.developer.meta.com/docs/models",
    contextSource: "https://llama.developer.meta.com/docs/models",
    verifiedAt: "2025-04-05",
  },
  {
    id: "llama:cerebras-llama-4-scout-17b-16e-instruct",
    provider: "llama",
    vendorId: "cerebras-llama-4-scout-17b-16e-instruct",
    displayName: "Cerebras-Llama-4-Scout-17B-16E-Instruct",
    family: "cerebras-llama-4-scout-17b-16e-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["llama/cerebras-llama-4-scout-17b-16e-instruct"],
    releasedAt: "2025-04-05",
    source: "https://llama.developer.meta.com/docs/models",
    contextSource: "https://llama.developer.meta.com/docs/models",
    verifiedAt: "2025-04-05",
  },
  {
    id: "llama:groq-llama-4-maverick-17b-128e-instruct",
    provider: "llama",
    vendorId: "groq-llama-4-maverick-17b-128e-instruct",
    displayName: "Groq-Llama-4-Maverick-17B-128E-Instruct",
    family: "groq-llama-4-maverick-17b-128e-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["llama/groq-llama-4-maverick-17b-128e-instruct"],
    releasedAt: "2025-04-05",
    source: "https://llama.developer.meta.com/docs/models",
    contextSource: "https://llama.developer.meta.com/docs/models",
    verifiedAt: "2025-04-05",
  },
  {
    id: "llama:llama-3.3-70b-instruct",
    provider: "llama",
    vendorId: "llama-3.3-70b-instruct",
    displayName: "Llama-3.3-70B-Instruct",
    family: "llama-3.3-70b-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["llama/llama-3.3-70b-instruct"],
    releasedAt: "2024-12-06",
    source: "https://llama.developer.meta.com/docs/models",
    contextSource: "https://llama.developer.meta.com/docs/models",
    verifiedAt: "2024-12-06",
  },
  {
    id: "llama:llama-3.3-8b-instruct",
    provider: "llama",
    vendorId: "llama-3.3-8b-instruct",
    displayName: "Llama-3.3-8B-Instruct",
    family: "llama-3.3-8b-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["llama/llama-3.3-8b-instruct"],
    releasedAt: "2024-12-06",
    source: "https://llama.developer.meta.com/docs/models",
    contextSource: "https://llama.developer.meta.com/docs/models",
    verifiedAt: "2024-12-06",
  },
  {
    id: "llama:llama-4-maverick-17b-128e-instruct-fp8",
    provider: "llama",
    vendorId: "llama-4-maverick-17b-128e-instruct-fp8",
    displayName: "Llama-4-Maverick-17B-128E-Instruct-FP8",
    family: "llama-4-maverick-17b-128e-instruct-fp8",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["llama/llama-4-maverick-17b-128e-instruct-fp8"],
    releasedAt: "2025-04-05",
    source: "https://llama.developer.meta.com/docs/models",
    contextSource: "https://llama.developer.meta.com/docs/models",
    verifiedAt: "2025-04-05",
  },
  {
    id: "llama:llama-4-scout-17b-16e-instruct-fp8",
    provider: "llama",
    vendorId: "llama-4-scout-17b-16e-instruct-fp8",
    displayName: "Llama-4-Scout-17B-16E-Instruct-FP8",
    family: "llama-4-scout-17b-16e-instruct-fp8",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["llama/llama-4-scout-17b-16e-instruct-fp8"],
    releasedAt: "2025-04-05",
    source: "https://llama.developer.meta.com/docs/models",
    contextSource: "https://llama.developer.meta.com/docs/models",
    verifiedAt: "2025-04-05",
  },
  {
    id: "lmstudio:openai/gpt-oss-20b",
    provider: "lmstudio",
    vendorId: "openai/gpt-oss-20b",
    displayName: "GPT OSS 20B",
    family: "openai/gpt-oss-20b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["lmstudio/openai/gpt-oss-20b"],
    releasedAt: "2025-08-05",
    source: "https://lmstudio.ai/models",
    contextSource: "https://lmstudio.ai/models",
    verifiedAt: "2025-08-05",
  },
  {
    id: "lmstudio:qwen/qwen3-30b-a3b-2507",
    provider: "lmstudio",
    vendorId: "qwen/qwen3-30b-a3b-2507",
    displayName: "Qwen3 30B A3B 2507",
    family: "qwen/qwen3-30b-a3b-2507",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["lmstudio/qwen/qwen3-30b-a3b-2507"],
    releasedAt: "2025-07-30",
    source: "https://lmstudio.ai/models",
    contextSource: "https://lmstudio.ai/models",
    verifiedAt: "2025-07-30",
  },
  {
    id: "lmstudio:qwen/qwen3-coder-30b",
    provider: "lmstudio",
    vendorId: "qwen/qwen3-coder-30b",
    displayName: "Qwen3 Coder 30B",
    family: "qwen/qwen3-coder-30b",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["lmstudio/qwen/qwen3-coder-30b"],
    releasedAt: "2025-07-23",
    source: "https://lmstudio.ai/models",
    contextSource: "https://lmstudio.ai/models",
    verifiedAt: "2025-07-23",
  },
  {
    id: "mistral:codestral-latest",
    provider: "mistral",
    vendorId: "codestral-latest",
    displayName: "Codestral",
    family: "codestral-latest",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":0.9},
    pricingSource: "models.dev",
    aliases: ["mistral/codestral-latest"],
    releasedAt: "2024-05-29",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2025-01-04",
  },
  {
    id: "mistral:devstral-medium-2507",
    provider: "mistral",
    vendorId: "devstral-medium-2507",
    displayName: "Devstral Medium",
    family: "devstral-medium-2507",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.4,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["mistral/devstral-medium-2507"],
    releasedAt: "2025-07-10",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2025-07-10",
  },
  {
    id: "mistral:devstral-small-2505",
    provider: "mistral",
    vendorId: "devstral-small-2505",
    displayName: "Devstral Small 2505",
    family: "devstral-small-2505",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.3},
    pricingSource: "models.dev",
    aliases: ["mistral/devstral-small-2505"],
    releasedAt: "2025-05-07",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2025-05-07",
  },
  {
    id: "mistral:devstral-small-2507",
    provider: "mistral",
    vendorId: "devstral-small-2507",
    displayName: "Devstral Small",
    family: "devstral-small-2507",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.3},
    pricingSource: "models.dev",
    aliases: ["mistral/devstral-small-2507"],
    releasedAt: "2025-07-10",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2025-07-10",
  },
  {
    id: "mistral:magistral-medium-latest",
    provider: "mistral",
    vendorId: "magistral-medium-latest",
    displayName: "Magistral Medium",
    family: "magistral-medium-latest",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":5},
    pricingSource: "models.dev",
    aliases: ["mistral/magistral-medium-latest"],
    releasedAt: "2025-03-17",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2025-03-20",
  },
  {
    id: "mistral:magistral-small",
    provider: "mistral",
    vendorId: "magistral-small",
    displayName: "Magistral Small",
    family: "magistral-small",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.5,"outputPerMTokens":1.5},
    pricingSource: "models.dev",
    aliases: ["mistral/magistral-small"],
    releasedAt: "2025-03-17",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2025-03-17",
  },
  {
    id: "mistral:ministral-3b-latest",
    provider: "mistral",
    vendorId: "ministral-3b-latest",
    displayName: "Ministral 3B",
    family: "ministral-3b-latest",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.04,"outputPerMTokens":0.04},
    pricingSource: "models.dev",
    aliases: ["mistral/ministral-3b-latest"],
    releasedAt: "2024-10-01",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2024-10-04",
  },
  {
    id: "mistral:ministral-8b-latest",
    provider: "mistral",
    vendorId: "ministral-8b-latest",
    displayName: "Ministral 8B",
    family: "ministral-8b-latest",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.1},
    pricingSource: "models.dev",
    aliases: ["mistral/ministral-8b-latest"],
    releasedAt: "2024-10-01",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2024-10-04",
  },
  {
    id: "mistral:mistral-large-latest",
    provider: "mistral",
    vendorId: "mistral-large-latest",
    displayName: "Mistral Large",
    family: "mistral-large-latest",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":6},
    pricingSource: "models.dev",
    aliases: ["mistral/mistral-large-latest"],
    releasedAt: "2024-11-01",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2024-11-04",
  },
  {
    id: "mistral:mistral-medium-2505",
    provider: "mistral",
    vendorId: "mistral-medium-2505",
    displayName: "Mistral Medium 3",
    family: "mistral-medium-2505",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.4,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["mistral/mistral-medium-2505"],
    releasedAt: "2025-05-07",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2025-05-07",
  },
  {
    id: "mistral:mistral-medium-2508",
    provider: "mistral",
    vendorId: "mistral-medium-2508",
    displayName: "Mistral Medium 3.1",
    family: "mistral-medium-2508",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":262144},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.4,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["mistral/mistral-medium-2508"],
    releasedAt: "2025-08-12",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2025-08-12",
  },
  {
    id: "mistral:mistral-medium-latest",
    provider: "mistral",
    vendorId: "mistral-medium-latest",
    displayName: "Mistral Medium",
    family: "mistral-medium-latest",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.4,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["mistral/mistral-medium-latest"],
    releasedAt: "2025-05-07",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2025-05-10",
  },
  {
    id: "mistral:mistral-nemo",
    provider: "mistral",
    vendorId: "mistral-nemo",
    displayName: "Mistral Nemo",
    family: "mistral-nemo",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.15},
    pricingSource: "models.dev",
    aliases: ["mistral/mistral-nemo"],
    releasedAt: "2024-07-01",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2024-07-01",
  },
  {
    id: "mistral:mistral-small-latest",
    provider: "mistral",
    vendorId: "mistral-small-latest",
    displayName: "Mistral Small",
    family: "mistral-small-latest",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.3},
    pricingSource: "models.dev",
    aliases: ["mistral/mistral-small-latest"],
    releasedAt: "2024-09-01",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2024-09-04",
  },
  {
    id: "mistral:open-mistral-7b",
    provider: "mistral",
    vendorId: "open-mistral-7b",
    displayName: "Mistral 7B",
    family: "open-mistral-7b",
    status: "stable",
    context: {"combinedMax":8000,"outputMax":8000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.25,"outputPerMTokens":0.25},
    pricingSource: "models.dev",
    aliases: ["mistral/open-mistral-7b"],
    releasedAt: "2023-09-27",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2023-09-27",
  },
  {
    id: "mistral:open-mixtral-8x22b",
    provider: "mistral",
    vendorId: "open-mixtral-8x22b",
    displayName: "Mixtral 8x22B",
    family: "open-mixtral-8x22b",
    status: "stable",
    context: {"combinedMax":64000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":6},
    pricingSource: "models.dev",
    aliases: ["mistral/open-mixtral-8x22b"],
    releasedAt: "2024-04-17",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2024-04-17",
  },
  {
    id: "mistral:open-mixtral-8x7b",
    provider: "mistral",
    vendorId: "open-mixtral-8x7b",
    displayName: "Mixtral 8x7B",
    family: "open-mixtral-8x7b",
    status: "stable",
    context: {"combinedMax":32000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.7,"outputPerMTokens":0.7},
    pricingSource: "models.dev",
    aliases: ["mistral/open-mixtral-8x7b"],
    releasedAt: "2023-12-11",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2023-12-11",
  },
  {
    id: "mistral:pixtral-12b",
    provider: "mistral",
    vendorId: "pixtral-12b",
    displayName: "Pixtral 12B",
    family: "pixtral-12b",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.15},
    pricingSource: "models.dev",
    aliases: ["mistral/pixtral-12b"],
    releasedAt: "2024-09-01",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2024-09-01",
  },
  {
    id: "mistral:pixtral-large-latest",
    provider: "mistral",
    vendorId: "pixtral-large-latest",
    displayName: "Pixtral Large",
    family: "pixtral-large-latest",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":6},
    pricingSource: "models.dev",
    aliases: ["mistral/pixtral-large-latest"],
    releasedAt: "2024-11-01",
    source: "https://docs.mistral.ai/getting-started/models/",
    contextSource: "https://docs.mistral.ai/getting-started/models/",
    verifiedAt: "2024-11-04",
  },
  {
    id: "modelscope:moonshotai/Kimi-K2-Instruct",
    provider: "modelscope",
    vendorId: "moonshotai/Kimi-K2-Instruct",
    displayName: "Kimi-K2-Instruct",
    family: "moonshotai/Kimi-K2-Instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["modelscope/moonshotai/Kimi-K2-Instruct"],
    releasedAt: "2025-07-14",
    source: "https://modelscope.cn/docs/model-service/API-Inference/intro",
    contextSource: "https://modelscope.cn/docs/model-service/API-Inference/intro",
    verifiedAt: "2025-07-14",
  },
  {
    id: "modelscope:Qwen/Qwen3-235B-A22B-Instruct-2507",
    provider: "modelscope",
    vendorId: "Qwen/Qwen3-235B-A22B-Instruct-2507",
    displayName: "Qwen3 235B A22B Instruct 2507",
    family: "Qwen/Qwen3-235B-A22B-Instruct-2507",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["modelscope/Qwen/Qwen3-235B-A22B-Instruct-2507"],
    releasedAt: "2025-04-28",
    source: "https://modelscope.cn/docs/model-service/API-Inference/intro",
    contextSource: "https://modelscope.cn/docs/model-service/API-Inference/intro",
    verifiedAt: "2025-07-21",
  },
  {
    id: "modelscope:Qwen/Qwen3-235B-A22B-Thinking-2507",
    provider: "modelscope",
    vendorId: "Qwen/Qwen3-235B-A22B-Thinking-2507",
    displayName: "Qwen3-235B-A22B-Thinking-2507",
    family: "Qwen/Qwen3-235B-A22B-Thinking-2507",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["modelscope/Qwen/Qwen3-235B-A22B-Thinking-2507"],
    releasedAt: "2025-07-25",
    source: "https://modelscope.cn/docs/model-service/API-Inference/intro",
    contextSource: "https://modelscope.cn/docs/model-service/API-Inference/intro",
    verifiedAt: "2025-07-25",
  },
  {
    id: "modelscope:Qwen/Qwen3-30B-A3B-Instruct-2507",
    provider: "modelscope",
    vendorId: "Qwen/Qwen3-30B-A3B-Instruct-2507",
    displayName: "Qwen3 30B A3B Instruct 2507",
    family: "Qwen/Qwen3-30B-A3B-Instruct-2507",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["modelscope/Qwen/Qwen3-30B-A3B-Instruct-2507"],
    releasedAt: "2025-07-30",
    source: "https://modelscope.cn/docs/model-service/API-Inference/intro",
    contextSource: "https://modelscope.cn/docs/model-service/API-Inference/intro",
    verifiedAt: "2025-07-30",
  },
  {
    id: "modelscope:Qwen/Qwen3-30B-A3B-Thinking-2507",
    provider: "modelscope",
    vendorId: "Qwen/Qwen3-30B-A3B-Thinking-2507",
    displayName: "Qwen3 30B A3B Thinking 2507",
    family: "Qwen/Qwen3-30B-A3B-Thinking-2507",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["modelscope/Qwen/Qwen3-30B-A3B-Thinking-2507"],
    releasedAt: "2025-07-30",
    source: "https://modelscope.cn/docs/model-service/API-Inference/intro",
    contextSource: "https://modelscope.cn/docs/model-service/API-Inference/intro",
    verifiedAt: "2025-07-30",
  },
  {
    id: "modelscope:Qwen/Qwen3-Coder-30B-A3B-Instruct",
    provider: "modelscope",
    vendorId: "Qwen/Qwen3-Coder-30B-A3B-Instruct",
    displayName: "Qwen3 Coder 30B A3B Instruct",
    family: "Qwen/Qwen3-Coder-30B-A3B-Instruct",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["modelscope/Qwen/Qwen3-Coder-30B-A3B-Instruct"],
    releasedAt: "2025-07-31",
    source: "https://modelscope.cn/docs/model-service/API-Inference/intro",
    contextSource: "https://modelscope.cn/docs/model-service/API-Inference/intro",
    verifiedAt: "2025-07-31",
  },
  {
    id: "modelscope:Qwen/Qwen3-Coder-480B-A35B-Instruct",
    provider: "modelscope",
    vendorId: "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    displayName: "Qwen3-Coder-480B-A35B-Instruct",
    family: "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":66536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["modelscope/Qwen/Qwen3-Coder-480B-A35B-Instruct"],
    releasedAt: "2025-07-23",
    source: "https://modelscope.cn/docs/model-service/API-Inference/intro",
    contextSource: "https://modelscope.cn/docs/model-service/API-Inference/intro",
    verifiedAt: "2025-07-23",
  },
  {
    id: "modelscope:ZhipuAI/GLM-4.5",
    provider: "modelscope",
    vendorId: "ZhipuAI/GLM-4.5",
    displayName: "GLM-4.5",
    family: "ZhipuAI/GLM-4.5",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":98304},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["modelscope/ZhipuAI/GLM-4.5"],
    releasedAt: "2025-07-28",
    source: "https://modelscope.cn/docs/model-service/API-Inference/intro",
    contextSource: "https://modelscope.cn/docs/model-service/API-Inference/intro",
    verifiedAt: "2025-07-28",
  },
  {
    id: "moonshotai:kimi-k2-0711-preview",
    provider: "moonshotai",
    vendorId: "kimi-k2-0711-preview",
    displayName: "Kimi K2 0711",
    family: "kimi-k2-0711-preview",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":2.5},
    pricingSource: "models.dev",
    aliases: ["moonshotai/kimi-k2-0711-preview"],
    releasedAt: "2025-07-14",
    source: "https://platform.moonshot.ai/docs/api/chat",
    contextSource: "https://platform.moonshot.ai/docs/api/chat",
    verifiedAt: "2025-07-14",
  },
  {
    id: "moonshotai:kimi-k2-0905-preview",
    provider: "moonshotai",
    vendorId: "kimi-k2-0905-preview",
    displayName: "Kimi K2 0905",
    family: "kimi-k2-0905-preview",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":262144},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":2.5},
    pricingSource: "models.dev",
    aliases: ["moonshotai/kimi-k2-0905-preview"],
    releasedAt: "2025-09-05",
    source: "https://platform.moonshot.ai/docs/api/chat",
    contextSource: "https://platform.moonshot.ai/docs/api/chat",
    verifiedAt: "2025-09-05",
  },
  {
    id: "moonshotai:kimi-k2-turbo-preview",
    provider: "moonshotai",
    vendorId: "kimi-k2-turbo-preview",
    displayName: "Kimi K2 Turbo",
    family: "kimi-k2-turbo-preview",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2.4,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["moonshotai/kimi-k2-turbo-preview"],
    releasedAt: "2025-07-14",
    source: "https://platform.moonshot.ai/docs/api/chat",
    contextSource: "https://platform.moonshot.ai/docs/api/chat",
    verifiedAt: "2025-07-14",
  },
  {
    id: "moonshotai-cn:kimi-k2-0711-preview",
    provider: "moonshotai-cn",
    vendorId: "kimi-k2-0711-preview",
    displayName: "Kimi K2 0711",
    family: "kimi-k2-0711-preview",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":2.5},
    pricingSource: "models.dev",
    aliases: ["moonshotai-cn/kimi-k2-0711-preview"],
    releasedAt: "2025-07-14",
    source: "https://platform.moonshot.cn/docs/api/chat",
    contextSource: "https://platform.moonshot.cn/docs/api/chat",
    verifiedAt: "2025-07-14",
  },
  {
    id: "moonshotai-cn:kimi-k2-0905-preview",
    provider: "moonshotai-cn",
    vendorId: "kimi-k2-0905-preview",
    displayName: "Kimi K2 0905",
    family: "kimi-k2-0905-preview",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":262144},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":2.5},
    pricingSource: "models.dev",
    aliases: ["moonshotai-cn/kimi-k2-0905-preview"],
    releasedAt: "2025-09-05",
    source: "https://platform.moonshot.cn/docs/api/chat",
    contextSource: "https://platform.moonshot.cn/docs/api/chat",
    verifiedAt: "2025-09-05",
  },
  {
    id: "moonshotai-cn:kimi-k2-turbo-preview",
    provider: "moonshotai-cn",
    vendorId: "kimi-k2-turbo-preview",
    displayName: "Kimi K2 Turbo",
    family: "kimi-k2-turbo-preview",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2.4,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["moonshotai-cn/kimi-k2-turbo-preview"],
    releasedAt: "2025-07-14",
    source: "https://platform.moonshot.cn/docs/api/chat",
    contextSource: "https://platform.moonshot.cn/docs/api/chat",
    verifiedAt: "2025-07-14",
  },
  {
    id: "morph:auto",
    provider: "morph",
    vendorId: "auto",
    displayName: "Auto",
    family: "auto",
    status: "stable",
    context: {"combinedMax":32000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.85,"outputPerMTokens":1.55},
    pricingSource: "models.dev",
    aliases: ["morph/auto"],
    releasedAt: "2024-06-01",
    source: "https://docs.morphllm.com/api-reference/introduction",
    contextSource: "https://docs.morphllm.com/api-reference/introduction",
    verifiedAt: "2024-06-01",
  },
  {
    id: "morph:morph-v3-fast",
    provider: "morph",
    vendorId: "morph-v3-fast",
    displayName: "Morph v3 Fast",
    family: "morph-v3-fast",
    status: "stable",
    context: {"combinedMax":16000,"outputMax":16000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.8,"outputPerMTokens":1.2},
    pricingSource: "models.dev",
    aliases: ["morph/morph-v3-fast"],
    releasedAt: "2024-08-15",
    source: "https://docs.morphllm.com/api-reference/introduction",
    contextSource: "https://docs.morphllm.com/api-reference/introduction",
    verifiedAt: "2024-08-15",
  },
  {
    id: "morph:morph-v3-large",
    provider: "morph",
    vendorId: "morph-v3-large",
    displayName: "Morph v3 Large",
    family: "morph-v3-large",
    status: "stable",
    context: {"combinedMax":32000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.9,"outputPerMTokens":1.9},
    pricingSource: "models.dev",
    aliases: ["morph/morph-v3-large"],
    releasedAt: "2024-08-15",
    source: "https://docs.morphllm.com/api-reference/introduction",
    contextSource: "https://docs.morphllm.com/api-reference/introduction",
    verifiedAt: "2024-08-15",
  },
  {
    id: "nvidia:cosmos-nemotron-34b",
    provider: "nvidia",
    vendorId: "cosmos-nemotron-34b",
    displayName: "Cosmos Nemotron 34B",
    family: "cosmos-nemotron-34b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["nvidia/cosmos-nemotron-34b"],
    releasedAt: "2024-01-01",
    source: "https://docs.api.nvidia.com/nim/",
    contextSource: "https://docs.api.nvidia.com/nim/",
    verifiedAt: "2025-09-05",
  },
  {
    id: "nvidia:deepseek-r1",
    provider: "nvidia",
    vendorId: "deepseek-r1",
    displayName: "DeepSeek R1",
    family: "deepseek-r1",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["nvidia/deepseek-r1"],
    releasedAt: "2024-11-01",
    source: "https://docs.api.nvidia.com/nim/",
    contextSource: "https://docs.api.nvidia.com/nim/",
    verifiedAt: "2025-09-05",
  },
  {
    id: "nvidia:deepseek-v3.1",
    provider: "nvidia",
    vendorId: "deepseek-v3.1",
    displayName: "DeepSeek V3.1",
    family: "deepseek-v3.1",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["nvidia/deepseek-v3.1"],
    releasedAt: "2025-08-20",
    source: "https://docs.api.nvidia.com/nim/",
    contextSource: "https://docs.api.nvidia.com/nim/",
    verifiedAt: "2025-08-26",
  },
  {
    id: "nvidia:flux_1-dev",
    provider: "nvidia",
    vendorId: "flux_1-dev",
    displayName: "FLUX.1-dev",
    family: "flux_1-dev",
    status: "stable",
    context: {"combinedMax":4096,"outputMax":0},
    modalities: {"textIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["nvidia/flux_1-dev"],
    releasedAt: "2024-08-01",
    source: "https://docs.api.nvidia.com/nim/",
    contextSource: "https://docs.api.nvidia.com/nim/",
    verifiedAt: "2025-09-05",
  },
  {
    id: "nvidia:gemma-3-27b-it",
    provider: "nvidia",
    vendorId: "gemma-3-27b-it",
    displayName: "Gemma-3-27B-IT",
    family: "gemma-3-27b-it",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["nvidia/gemma-3-27b-it"],
    releasedAt: "2024-12-01",
    source: "https://docs.api.nvidia.com/nim/",
    contextSource: "https://docs.api.nvidia.com/nim/",
    verifiedAt: "2025-09-05",
  },
  {
    id: "nvidia:llama-3.1-nemotron-ultra-253b-v1",
    provider: "nvidia",
    vendorId: "llama-3.1-nemotron-ultra-253b-v1",
    displayName: "Llama-3.1-Nemotron-Ultra-253B-v1",
    family: "llama-3.1-nemotron-ultra-253b-v1",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["nvidia/llama-3.1-nemotron-ultra-253b-v1"],
    releasedAt: "2024-07-01",
    source: "https://docs.api.nvidia.com/nim/",
    contextSource: "https://docs.api.nvidia.com/nim/",
    verifiedAt: "2025-09-05",
  },
  {
    id: "nvidia:llama-3.3-nemotron-super-49b-v1.5",
    provider: "nvidia",
    vendorId: "llama-3.3-nemotron-super-49b-v1.5",
    displayName: "Llama-3.3-Nemotron-Super-49B-v1.5",
    family: "llama-3.3-nemotron-super-49b-v1.5",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["nvidia/llama-3.3-nemotron-super-49b-v1.5"],
    releasedAt: "2025-07-25",
    source: "https://docs.api.nvidia.com/nim/",
    contextSource: "https://docs.api.nvidia.com/nim/",
    verifiedAt: "2025-09-05",
  },
  {
    id: "nvidia:mistral-small-3.1-24b-instruct-2503",
    provider: "nvidia",
    vendorId: "mistral-small-3.1-24b-instruct-2503",
    displayName: "Mistral-Small-3.1-24B-Instruct-2503",
    family: "mistral-small-3.1-24b-instruct-2503",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["nvidia/mistral-small-3.1-24b-instruct-2503"],
    releasedAt: "2025-04-01",
    source: "https://docs.api.nvidia.com/nim/",
    contextSource: "https://docs.api.nvidia.com/nim/",
    verifiedAt: "2025-09-05",
  },
  {
    id: "nvidia:nemoretriever-ocr-v1",
    provider: "nvidia",
    vendorId: "nemoretriever-ocr-v1",
    displayName: "NeMo Retriever OCR v1",
    family: "nemoretriever-ocr-v1",
    status: "stable",
    context: {"combinedMax":0,"outputMax":4096},
    modalities: {"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["nvidia/nemoretriever-ocr-v1"],
    releasedAt: "2024-01-01",
    source: "https://docs.api.nvidia.com/nim/",
    contextSource: "https://docs.api.nvidia.com/nim/",
    verifiedAt: "2025-09-05",
  },
  {
    id: "nvidia:parakeet-tdt-0.6b-v2",
    provider: "nvidia",
    vendorId: "parakeet-tdt-0.6b-v2",
    displayName: "Parakeet TDT 0.6B v2",
    family: "parakeet-tdt-0.6b-v2",
    status: "stable",
    context: {"combinedMax":0,"outputMax":4096},
    modalities: {"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["nvidia/parakeet-tdt-0.6b-v2"],
    releasedAt: "2024-01-01",
    source: "https://docs.api.nvidia.com/nim/",
    contextSource: "https://docs.api.nvidia.com/nim/",
    verifiedAt: "2025-09-05",
  },
  {
    id: "nvidia:phi-4-multimodal-instruct",
    provider: "nvidia",
    vendorId: "phi-4-multimodal-instruct",
    displayName: "Phi-4-Multimodal-Instruct",
    family: "phi-4-multimodal-instruct",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["nvidia/phi-4-multimodal-instruct"],
    releasedAt: "2024-12-01",
    source: "https://docs.api.nvidia.com/nim/",
    contextSource: "https://docs.api.nvidia.com/nim/",
    verifiedAt: "2025-09-05",
  },
  {
    id: "nvidia:qwen3-235b-a22b",
    provider: "nvidia",
    vendorId: "qwen3-235b-a22b",
    displayName: "Qwen3-235B-A22B",
    family: "qwen3-235b-a22b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["nvidia/qwen3-235b-a22b"],
    releasedAt: "2024-12-01",
    source: "https://docs.api.nvidia.com/nim/",
    contextSource: "https://docs.api.nvidia.com/nim/",
    verifiedAt: "2025-09-05",
  },
  {
    id: "nvidia:qwen3-coder-480b-a35b-instruct",
    provider: "nvidia",
    vendorId: "qwen3-coder-480b-a35b-instruct",
    displayName: "Qwen3 Coder 480B A35B Instruct",
    family: "qwen3-coder-480b-a35b-instruct",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":66536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["nvidia/qwen3-coder-480b-a35b-instruct"],
    releasedAt: "2025-07-23",
    source: "https://docs.api.nvidia.com/nim/",
    contextSource: "https://docs.api.nvidia.com/nim/",
    verifiedAt: "2025-07-23",
  },
  {
    id: "nvidia:whisper-large-v3",
    provider: "nvidia",
    vendorId: "whisper-large-v3",
    displayName: "Whisper Large v3",
    family: "whisper-large-v3",
    status: "stable",
    context: {"combinedMax":0,"outputMax":4096},
    modalities: {"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["nvidia/whisper-large-v3"],
    releasedAt: "2023-09-01",
    source: "https://docs.api.nvidia.com/nim/",
    contextSource: "https://docs.api.nvidia.com/nim/",
    verifiedAt: "2025-09-05",
  },
  {
    id: "openai:codex-mini-latest",
    provider: "openai",
    vendorId: "codex-mini-latest",
    displayName: "Codex Mini",
    family: "codex-mini-latest",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.5,"outputPerMTokens":6},
    pricingSource: "models.dev",
    aliases: ["openai/codex-mini-latest"],
    releasedAt: "2025-05-16",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2025-05-16",
  },
  {
    id: "openai:gpt-3.5-turbo",
    provider: "openai",
    vendorId: "gpt-3.5-turbo",
    displayName: "GPT-3.5-turbo",
    family: "gpt-3.5-turbo",
    status: "stable",
    context: {"combinedMax":16385,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.5,"outputPerMTokens":1.5},
    pricingSource: "models.dev",
    aliases: ["openai/gpt-3.5-turbo"],
    releasedAt: "2023-03-01",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2023-11-06",
  },
  {
    id: "openai:gpt-4",
    provider: "openai",
    vendorId: "gpt-4",
    displayName: "GPT-4",
    family: "gpt-4",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":30,"outputPerMTokens":60},
    pricingSource: "models.dev",
    aliases: ["openai/gpt-4"],
    releasedAt: "2023-11-06",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2024-04-09",
  },
  {
    id: "openai:gpt-4-turbo",
    provider: "openai",
    vendorId: "gpt-4-turbo",
    displayName: "GPT-4 Turbo",
    family: "gpt-4-turbo",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":10,"outputPerMTokens":30},
    pricingSource: "models.dev",
    aliases: ["openai/gpt-4-turbo"],
    releasedAt: "2023-11-06",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2024-04-09",
  },
  {
    id: "openai:gpt-4.1",
    provider: "openai",
    vendorId: "gpt-4.1",
    displayName: "GPT-4.1",
    family: "gpt-4.1",
    status: "stable",
    context: {"combinedMax":1047576,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":8},
    pricingSource: "models.dev",
    aliases: ["openai/gpt-4.1"],
    releasedAt: "2025-04-14",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2025-04-14",
  },
  {
    id: "openai:gpt-4.1-mini",
    provider: "openai",
    vendorId: "gpt-4.1-mini",
    displayName: "GPT-4.1 mini",
    family: "gpt-4.1-mini",
    status: "stable",
    context: {"combinedMax":1047576,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.4,"outputPerMTokens":1.6},
    pricingSource: "models.dev",
    aliases: ["openai/gpt-4.1-mini"],
    releasedAt: "2025-04-14",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2025-04-14",
  },
  {
    id: "openai:gpt-4.1-nano",
    provider: "openai",
    vendorId: "gpt-4.1-nano",
    displayName: "GPT-4.1 nano",
    family: "gpt-4.1-nano",
    status: "stable",
    context: {"combinedMax":1047576,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.4},
    pricingSource: "models.dev",
    aliases: ["openai/gpt-4.1-nano"],
    releasedAt: "2025-04-14",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2025-04-14",
  },
  {
    id: "openai:gpt-4o",
    provider: "openai",
    vendorId: "gpt-4o",
    displayName: "GPT-4o",
    family: "gpt-4o",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2.5,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["openai/gpt-4o"],
    releasedAt: "2024-05-13",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2024-05-13",
  },
  {
    id: "openai:gpt-4o-mini",
    provider: "openai",
    vendorId: "gpt-4o-mini",
    displayName: "GPT-4o mini",
    family: "gpt-4o-mini",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["openai/gpt-4o-mini"],
    releasedAt: "2024-07-18",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2024-07-18",
  },
  {
    id: "openai:gpt-5",
    provider: "openai",
    vendorId: "gpt-5",
    displayName: "GPT-5",
    family: "gpt-5",
    status: "stable",
    context: {"combinedMax":400000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["openai/gpt-5"],
    releasedAt: "2025-08-07",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "openai:gpt-5-chat-latest",
    provider: "openai",
    vendorId: "gpt-5-chat-latest",
    displayName: "GPT-5 Chat (latest)",
    family: "gpt-5-chat-latest",
    status: "stable",
    context: {"combinedMax":400000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["openai/gpt-5-chat-latest"],
    releasedAt: "2025-08-07",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "openai:gpt-5-mini",
    provider: "openai",
    vendorId: "gpt-5-mini",
    displayName: "GPT-5 Mini",
    family: "gpt-5-mini",
    status: "stable",
    context: {"combinedMax":400000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.25,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["openai/gpt-5-mini"],
    releasedAt: "2025-08-07",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "openai:gpt-5-nano",
    provider: "openai",
    vendorId: "gpt-5-nano",
    displayName: "GPT-5 Nano",
    family: "gpt-5-nano",
    status: "stable",
    context: {"combinedMax":400000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.05,"outputPerMTokens":0.4},
    pricingSource: "models.dev",
    aliases: ["openai/gpt-5-nano"],
    releasedAt: "2025-08-07",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "openai:o1",
    provider: "openai",
    vendorId: "o1",
    displayName: "o1",
    family: "o1",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":60},
    pricingSource: "models.dev",
    aliases: ["openai/o1"],
    releasedAt: "2024-12-05",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2024-12-05",
  },
  {
    id: "openai:o1-mini",
    provider: "openai",
    vendorId: "o1-mini",
    displayName: "o1-mini",
    family: "o1-mini",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.1,"outputPerMTokens":4.4},
    pricingSource: "models.dev",
    aliases: ["openai/o1-mini"],
    releasedAt: "2024-09-12",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2024-09-12",
  },
  {
    id: "openai:o1-preview",
    provider: "openai",
    vendorId: "o1-preview",
    displayName: "o1-preview",
    family: "o1-preview",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":60},
    pricingSource: "models.dev",
    aliases: ["openai/o1-preview"],
    releasedAt: "2024-09-12",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2024-09-12",
  },
  {
    id: "openai:o1-pro",
    provider: "openai",
    vendorId: "o1-pro",
    displayName: "o1-pro",
    family: "o1-pro",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":150,"outputPerMTokens":600},
    pricingSource: "models.dev",
    aliases: ["openai/o1-pro"],
    releasedAt: "2025-03-19",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2025-03-19",
  },
  {
    id: "openai:o3",
    provider: "openai",
    vendorId: "o3",
    displayName: "o3",
    family: "o3",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":8},
    pricingSource: "models.dev",
    aliases: ["openai/o3"],
    releasedAt: "2025-04-16",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2025-04-16",
  },
  {
    id: "openai:o3-deep-research",
    provider: "openai",
    vendorId: "o3-deep-research",
    displayName: "o3-deep-research",
    family: "o3-deep-research",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":10,"outputPerMTokens":40},
    pricingSource: "models.dev",
    aliases: ["openai/o3-deep-research"],
    releasedAt: "2024-06-26",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2024-06-26",
  },
  {
    id: "openai:o3-mini",
    provider: "openai",
    vendorId: "o3-mini",
    displayName: "o3-mini",
    family: "o3-mini",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.1,"outputPerMTokens":4.4},
    pricingSource: "models.dev",
    aliases: ["openai/o3-mini"],
    releasedAt: "2024-12-20",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2025-01-29",
  },
  {
    id: "openai:o3-pro",
    provider: "openai",
    vendorId: "o3-pro",
    displayName: "o3-pro",
    family: "o3-pro",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":20,"outputPerMTokens":80},
    pricingSource: "models.dev",
    aliases: ["openai/o3-pro"],
    releasedAt: "2025-06-10",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2025-06-10",
  },
  {
    id: "openai:o4-mini",
    provider: "openai",
    vendorId: "o4-mini",
    displayName: "o4-mini",
    family: "o4-mini",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.1,"outputPerMTokens":4.4},
    pricingSource: "models.dev",
    aliases: ["openai/o4-mini"],
    releasedAt: "2025-04-16",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2025-04-16",
  },
  {
    id: "openai:o4-mini-deep-research",
    provider: "openai",
    vendorId: "o4-mini-deep-research",
    displayName: "o4-mini-deep-research",
    family: "o4-mini-deep-research",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":8},
    pricingSource: "models.dev",
    aliases: ["openai/o4-mini-deep-research"],
    releasedAt: "2024-06-26",
    source: "https://platform.openai.com/docs/models",
    contextSource: "https://platform.openai.com/docs/models",
    verifiedAt: "2024-06-26",
  },
  {
    id: "opencode:claude-3.5-haiku",
    provider: "opencode",
    vendorId: "claude-3.5-haiku",
    displayName: "Claude Haiku 3.5",
    family: "claude-3.5-haiku",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.8,"outputPerMTokens":4},
    pricingSource: "models.dev",
    aliases: ["opencode/claude-3.5-haiku"],
    releasedAt: "2024-10-22",
    source: "https://opencode.ai/docs",
    contextSource: "https://opencode.ai/docs",
    verifiedAt: "2024-10-22",
  },
  {
    id: "opencode:claude-opus-4.1",
    provider: "opencode",
    vendorId: "claude-opus-4.1",
    displayName: "Claude Opus 4.1",
    family: "claude-opus-4.1",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["opencode/claude-opus-4.1"],
    releasedAt: "2025-08-05",
    source: "https://opencode.ai/docs",
    contextSource: "https://opencode.ai/docs",
    verifiedAt: "2025-08-05",
  },
  {
    id: "opencode:claude-sonnet-4",
    provider: "opencode",
    vendorId: "claude-sonnet-4",
    displayName: "Claude Sonnet 4",
    family: "claude-sonnet-4",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["opencode/claude-sonnet-4"],
    releasedAt: "2025-05-22",
    source: "https://opencode.ai/docs",
    contextSource: "https://opencode.ai/docs",
    verifiedAt: "2025-05-22",
  },
  {
    id: "opencode:gpt-5",
    provider: "opencode",
    vendorId: "gpt-5",
    displayName: "GPT-5",
    family: "gpt-5",
    status: "stable",
    context: {"combinedMax":400000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["opencode/gpt-5"],
    releasedAt: "2025-08-07",
    source: "https://opencode.ai/docs",
    contextSource: "https://opencode.ai/docs",
    verifiedAt: "2025-08-07",
  },
  {
    id: "opencode:grok-code",
    provider: "opencode",
    vendorId: "grok-code",
    displayName: "Grok Code Fast 1",
    family: "grok-code",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["opencode/grok-code"],
    releasedAt: "2025-08-20",
    source: "https://opencode.ai/docs",
    contextSource: "https://opencode.ai/docs",
    verifiedAt: "2025-08-20",
  },
  {
    id: "opencode:kimi-k2",
    provider: "opencode",
    vendorId: "kimi-k2",
    displayName: "Kimi K2",
    family: "kimi-k2",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":262144},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":2.5},
    pricingSource: "models.dev",
    aliases: ["opencode/kimi-k2"],
    releasedAt: "2025-09-05",
    source: "https://opencode.ai/docs",
    contextSource: "https://opencode.ai/docs",
    verifiedAt: "2025-09-05",
  },
  {
    id: "opencode:qwen3-coder",
    provider: "opencode",
    vendorId: "qwen3-coder",
    displayName: "Qwen3 Coder",
    family: "qwen3-coder",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":1.2},
    pricingSource: "models.dev",
    aliases: ["opencode/qwen3-coder"],
    releasedAt: "2025-07-23",
    source: "https://opencode.ai/docs",
    contextSource: "https://opencode.ai/docs",
    verifiedAt: "2025-07-23",
  },
  {
    id: "openrouter:anthropic/claude-3.5-haiku",
    provider: "openrouter",
    vendorId: "anthropic/claude-3.5-haiku",
    displayName: "Claude Haiku 3.5",
    family: "anthropic/claude-3.5-haiku",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.8,"outputPerMTokens":4},
    pricingSource: "models.dev",
    aliases: ["openrouter/anthropic/claude-3.5-haiku"],
    releasedAt: "2024-10-22",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2024-10-22",
  },
  {
    id: "openrouter:anthropic/claude-3.7-sonnet",
    provider: "openrouter",
    vendorId: "anthropic/claude-3.7-sonnet",
    displayName: "Claude Sonnet 3.7",
    family: "anthropic/claude-3.7-sonnet",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["openrouter/anthropic/claude-3.7-sonnet"],
    releasedAt: "2025-02-19",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-02-19",
  },
  {
    id: "openrouter:anthropic/claude-opus-4",
    provider: "openrouter",
    vendorId: "anthropic/claude-opus-4",
    displayName: "Claude Opus 4",
    family: "anthropic/claude-opus-4",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["openrouter/anthropic/claude-opus-4"],
    releasedAt: "2025-05-22",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-05-22",
  },
  {
    id: "openrouter:anthropic/claude-opus-4.1",
    provider: "openrouter",
    vendorId: "anthropic/claude-opus-4.1",
    displayName: "Claude Opus 4.1",
    family: "anthropic/claude-opus-4.1",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["openrouter/anthropic/claude-opus-4.1"],
    releasedAt: "2025-08-05",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-08-05",
  },
  {
    id: "openrouter:anthropic/claude-sonnet-4",
    provider: "openrouter",
    vendorId: "anthropic/claude-sonnet-4",
    displayName: "Claude Sonnet 4",
    family: "anthropic/claude-sonnet-4",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["openrouter/anthropic/claude-sonnet-4"],
    releasedAt: "2025-05-22",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-05-22",
  },
  {
    id: "openrouter:cognitivecomputations/dolphin3.0-mistral-24b",
    provider: "openrouter",
    vendorId: "cognitivecomputations/dolphin3.0-mistral-24b",
    displayName: "Dolphin3.0 Mistral 24B",
    family: "cognitivecomputations/dolphin3.0-mistral-24b",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/cognitivecomputations/dolphin3.0-mistral-24b"],
    releasedAt: "2025-02-13",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-02-13",
  },
  {
    id: "openrouter:cognitivecomputations/dolphin3.0-r1-mistral-24b",
    provider: "openrouter",
    vendorId: "cognitivecomputations/dolphin3.0-r1-mistral-24b",
    displayName: "Dolphin3.0 R1 Mistral 24B",
    family: "cognitivecomputations/dolphin3.0-r1-mistral-24b",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/cognitivecomputations/dolphin3.0-r1-mistral-24b"],
    releasedAt: "2025-02-13",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-02-13",
  },
  {
    id: "openrouter:deepseek/deepseek-chat-v3-0324",
    provider: "openrouter",
    vendorId: "deepseek/deepseek-chat-v3-0324",
    displayName: "DeepSeek V3 0324",
    family: "deepseek/deepseek-chat-v3-0324",
    status: "stable",
    context: {"combinedMax":16384,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/deepseek/deepseek-chat-v3-0324"],
    releasedAt: "2025-03-24",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-03-24",
  },
  {
    id: "openrouter:deepseek/deepseek-chat-v3.1",
    provider: "openrouter",
    vendorId: "deepseek/deepseek-chat-v3.1",
    displayName: "DeepSeek-V3.1",
    family: "deepseek/deepseek-chat-v3.1",
    status: "stable",
    context: {"combinedMax":163840,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.8},
    pricingSource: "models.dev",
    aliases: ["openrouter/deepseek/deepseek-chat-v3.1"],
    releasedAt: "2025-08-21",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-08-21",
  },
  {
    id: "openrouter:deepseek/deepseek-r1-0528-qwen3-8b:free",
    provider: "openrouter",
    vendorId: "deepseek/deepseek-r1-0528-qwen3-8b:free",
    displayName: "Deepseek R1 0528 Qwen3 8B (free)",
    family: "deepseek/deepseek-r1-0528-qwen3-8b:free",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/deepseek/deepseek-r1-0528-qwen3-8b:free"],
    releasedAt: "2025-05-29",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-05-29",
  },
  {
    id: "openrouter:deepseek/deepseek-r1-0528:free",
    provider: "openrouter",
    vendorId: "deepseek/deepseek-r1-0528:free",
    displayName: "R1 0528 (free)",
    family: "deepseek/deepseek-r1-0528:free",
    status: "stable",
    context: {"combinedMax":163840,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/deepseek/deepseek-r1-0528:free"],
    releasedAt: "2025-05-28",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-05-28",
  },
  {
    id: "openrouter:deepseek/deepseek-r1-distill-llama-70b",
    provider: "openrouter",
    vendorId: "deepseek/deepseek-r1-distill-llama-70b",
    displayName: "DeepSeek R1 Distill Llama 70B",
    family: "deepseek/deepseek-r1-distill-llama-70b",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/deepseek/deepseek-r1-distill-llama-70b"],
    releasedAt: "2025-01-23",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-01-23",
  },
  {
    id: "openrouter:deepseek/deepseek-r1-distill-qwen-14b",
    provider: "openrouter",
    vendorId: "deepseek/deepseek-r1-distill-qwen-14b",
    displayName: "DeepSeek R1 Distill Qwen 14B",
    family: "deepseek/deepseek-r1-distill-qwen-14b",
    status: "stable",
    context: {"combinedMax":64000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/deepseek/deepseek-r1-distill-qwen-14b"],
    releasedAt: "2025-01-29",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-01-29",
  },
  {
    id: "openrouter:deepseek/deepseek-r1:free",
    provider: "openrouter",
    vendorId: "deepseek/deepseek-r1:free",
    displayName: "R1 (free)",
    family: "deepseek/deepseek-r1:free",
    status: "stable",
    context: {"combinedMax":163840,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/deepseek/deepseek-r1:free"],
    releasedAt: "2025-01-20",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-01-20",
  },
  {
    id: "openrouter:deepseek/deepseek-v3-base:free",
    provider: "openrouter",
    vendorId: "deepseek/deepseek-v3-base:free",
    displayName: "DeepSeek V3 Base (free)",
    family: "deepseek/deepseek-v3-base:free",
    status: "stable",
    context: {"combinedMax":163840,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/deepseek/deepseek-v3-base:free"],
    releasedAt: "2025-03-29",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-03-29",
  },
  {
    id: "openrouter:featherless/qwerky-72b",
    provider: "openrouter",
    vendorId: "featherless/qwerky-72b",
    displayName: "Qwerky 72B",
    family: "featherless/qwerky-72b",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/featherless/qwerky-72b"],
    releasedAt: "2025-03-20",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-03-20",
  },
  {
    id: "openrouter:google/gemini-2.0-flash-001",
    provider: "openrouter",
    vendorId: "google/gemini-2.0-flash-001",
    displayName: "Gemini 2.0 Flash",
    family: "google/gemini-2.0-flash-001",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.4},
    pricingSource: "models.dev",
    aliases: ["openrouter/google/gemini-2.0-flash-001"],
    releasedAt: "2024-12-11",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2024-12-11",
  },
  {
    id: "openrouter:google/gemini-2.0-flash-exp:free",
    provider: "openrouter",
    vendorId: "google/gemini-2.0-flash-exp:free",
    displayName: "Gemini 2.0 Flash Experimental (free)",
    family: "google/gemini-2.0-flash-exp:free",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":1048576},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/google/gemini-2.0-flash-exp:free"],
    releasedAt: "2024-12-11",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2024-12-11",
  },
  {
    id: "openrouter:google/gemini-2.5-flash",
    provider: "openrouter",
    vendorId: "google/gemini-2.5-flash",
    displayName: "Gemini 2.5 Flash",
    family: "google/gemini-2.5-flash",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":2.5},
    pricingSource: "models.dev",
    aliases: ["openrouter/google/gemini-2.5-flash"],
    releasedAt: "2025-07-17",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-17",
  },
  {
    id: "openrouter:google/gemini-2.5-pro",
    provider: "openrouter",
    vendorId: "google/gemini-2.5-pro",
    displayName: "Gemini 2.5 Pro",
    family: "google/gemini-2.5-pro",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["openrouter/google/gemini-2.5-pro"],
    releasedAt: "2025-03-20",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-06-05",
  },
  {
    id: "openrouter:google/gemini-2.5-pro-preview-05-06",
    provider: "openrouter",
    vendorId: "google/gemini-2.5-pro-preview-05-06",
    displayName: "Gemini 2.5 Pro Preview 05-06",
    family: "google/gemini-2.5-pro-preview-05-06",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["openrouter/google/gemini-2.5-pro-preview-05-06"],
    releasedAt: "2025-05-06",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-05-06",
  },
  {
    id: "openrouter:google/gemini-2.5-pro-preview-06-05",
    provider: "openrouter",
    vendorId: "google/gemini-2.5-pro-preview-06-05",
    displayName: "Gemini 2.5 Pro Preview 06-05",
    family: "google/gemini-2.5-pro-preview-06-05",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["openrouter/google/gemini-2.5-pro-preview-06-05"],
    releasedAt: "2025-06-05",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-06-05",
  },
  {
    id: "openrouter:google/gemma-2-9b-it:free",
    provider: "openrouter",
    vendorId: "google/gemma-2-9b-it:free",
    displayName: "Gemma 2 9B (free)",
    family: "google/gemma-2-9b-it:free",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/google/gemma-2-9b-it:free"],
    releasedAt: "2024-06-28",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2024-06-28",
  },
  {
    id: "openrouter:google/gemma-3-12b-it",
    provider: "openrouter",
    vendorId: "google/gemma-3-12b-it",
    displayName: "Gemma 3 12B IT",
    family: "google/gemma-3-12b-it",
    status: "stable",
    context: {"combinedMax":96000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/google/gemma-3-12b-it"],
    releasedAt: "2025-03-13",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-03-13",
  },
  {
    id: "openrouter:google/gemma-3-27b-it",
    provider: "openrouter",
    vendorId: "google/gemma-3-27b-it",
    displayName: "Gemma 3 27B IT",
    family: "google/gemma-3-27b-it",
    status: "stable",
    context: {"combinedMax":96000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/google/gemma-3-27b-it"],
    releasedAt: "2025-03-12",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-03-12",
  },
  {
    id: "openrouter:google/gemma-3n-e4b-it",
    provider: "openrouter",
    vendorId: "google/gemma-3n-e4b-it",
    displayName: "Gemma 3n E4B IT",
    family: "google/gemma-3n-e4b-it",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/google/gemma-3n-e4b-it"],
    releasedAt: "2025-05-20",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-05-20",
  },
  {
    id: "openrouter:google/gemma-3n-e4b-it:free",
    provider: "openrouter",
    vendorId: "google/gemma-3n-e4b-it:free",
    displayName: "Gemma 3n 4B (free)",
    family: "google/gemma-3n-e4b-it:free",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/google/gemma-3n-e4b-it:free"],
    releasedAt: "2025-05-20",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-05-20",
  },
  {
    id: "openrouter:meta-llama/llama-3.2-11b-vision-instruct",
    provider: "openrouter",
    vendorId: "meta-llama/llama-3.2-11b-vision-instruct",
    displayName: "Llama 3.2 11B Vision Instruct",
    family: "meta-llama/llama-3.2-11b-vision-instruct",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/meta-llama/llama-3.2-11b-vision-instruct"],
    releasedAt: "2024-09-25",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2024-09-25",
  },
  {
    id: "openrouter:meta-llama/llama-3.3-70b-instruct:free",
    provider: "openrouter",
    vendorId: "meta-llama/llama-3.3-70b-instruct:free",
    displayName: "Llama 3.3 70B Instruct (free)",
    family: "meta-llama/llama-3.3-70b-instruct:free",
    status: "stable",
    context: {"combinedMax":65536,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/meta-llama/llama-3.3-70b-instruct:free"],
    releasedAt: "2024-12-06",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2024-12-06",
  },
  {
    id: "openrouter:meta-llama/llama-4-scout:free",
    provider: "openrouter",
    vendorId: "meta-llama/llama-4-scout:free",
    displayName: "Llama 4 Scout (free)",
    family: "meta-llama/llama-4-scout:free",
    status: "stable",
    context: {"combinedMax":64000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/meta-llama/llama-4-scout:free"],
    releasedAt: "2025-04-05",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-04-05",
  },
  {
    id: "openrouter:microsoft/mai-ds-r1:free",
    provider: "openrouter",
    vendorId: "microsoft/mai-ds-r1:free",
    displayName: "MAI DS R1 (free)",
    family: "microsoft/mai-ds-r1:free",
    status: "stable",
    context: {"combinedMax":163840,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/microsoft/mai-ds-r1:free"],
    releasedAt: "2025-04-21",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-04-21",
  },
  {
    id: "openrouter:mistralai/codestral-2508",
    provider: "openrouter",
    vendorId: "mistralai/codestral-2508",
    displayName: "Codestral 2508",
    family: "mistralai/codestral-2508",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":256000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":0.9},
    pricingSource: "models.dev",
    aliases: ["openrouter/mistralai/codestral-2508"],
    releasedAt: "2025-08-01",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-08-01",
  },
  {
    id: "openrouter:mistralai/devstral-medium-2507",
    provider: "openrouter",
    vendorId: "mistralai/devstral-medium-2507",
    displayName: "Devstral Medium",
    family: "mistralai/devstral-medium-2507",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.4,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["openrouter/mistralai/devstral-medium-2507"],
    releasedAt: "2025-07-10",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-10",
  },
  {
    id: "openrouter:mistralai/devstral-small-2505",
    provider: "openrouter",
    vendorId: "mistralai/devstral-small-2505",
    displayName: "Devstral Small",
    family: "mistralai/devstral-small-2505",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.06,"outputPerMTokens":0.12},
    pricingSource: "models.dev",
    aliases: ["openrouter/mistralai/devstral-small-2505"],
    releasedAt: "2025-05-07",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-05-07",
  },
  {
    id: "openrouter:mistralai/devstral-small-2505:free",
    provider: "openrouter",
    vendorId: "mistralai/devstral-small-2505:free",
    displayName: "Devstral Small 2505 (free)",
    family: "mistralai/devstral-small-2505:free",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/mistralai/devstral-small-2505:free"],
    releasedAt: "2025-05-21",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-05-21",
  },
  {
    id: "openrouter:mistralai/devstral-small-2507",
    provider: "openrouter",
    vendorId: "mistralai/devstral-small-2507",
    displayName: "Devstral Small 1.1",
    family: "mistralai/devstral-small-2507",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.3},
    pricingSource: "models.dev",
    aliases: ["openrouter/mistralai/devstral-small-2507"],
    releasedAt: "2025-07-10",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-10",
  },
  {
    id: "openrouter:mistralai/mistral-7b-instruct:free",
    provider: "openrouter",
    vendorId: "mistralai/mistral-7b-instruct:free",
    displayName: "Mistral 7B Instruct (free)",
    family: "mistralai/mistral-7b-instruct:free",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/mistralai/mistral-7b-instruct:free"],
    releasedAt: "2024-05-27",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2024-05-27",
  },
  {
    id: "openrouter:mistralai/mistral-medium-3",
    provider: "openrouter",
    vendorId: "mistralai/mistral-medium-3",
    displayName: "Mistral Medium 3",
    family: "mistralai/mistral-medium-3",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.4,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["openrouter/mistralai/mistral-medium-3"],
    releasedAt: "2025-05-07",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-05-07",
  },
  {
    id: "openrouter:mistralai/mistral-medium-3.1",
    provider: "openrouter",
    vendorId: "mistralai/mistral-medium-3.1",
    displayName: "Mistral Medium 3.1",
    family: "mistralai/mistral-medium-3.1",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":262144},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.4,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["openrouter/mistralai/mistral-medium-3.1"],
    releasedAt: "2025-08-12",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-08-12",
  },
  {
    id: "openrouter:mistralai/mistral-nemo:free",
    provider: "openrouter",
    vendorId: "mistralai/mistral-nemo:free",
    displayName: "Mistral Nemo (free)",
    family: "mistralai/mistral-nemo:free",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/mistralai/mistral-nemo:free"],
    releasedAt: "2024-07-19",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2024-07-19",
  },
  {
    id: "openrouter:mistralai/mistral-small-3.1-24b-instruct",
    provider: "openrouter",
    vendorId: "mistralai/mistral-small-3.1-24b-instruct",
    displayName: "Mistral Small 3.1 24B Instruct",
    family: "mistralai/mistral-small-3.1-24b-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/mistralai/mistral-small-3.1-24b-instruct"],
    releasedAt: "2025-03-17",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-03-17",
  },
  {
    id: "openrouter:mistralai/mistral-small-3.2-24b-instruct",
    provider: "openrouter",
    vendorId: "mistralai/mistral-small-3.2-24b-instruct",
    displayName: "Mistral Small 3.2 24B Instruct",
    family: "mistralai/mistral-small-3.2-24b-instruct",
    status: "stable",
    context: {"combinedMax":96000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/mistralai/mistral-small-3.2-24b-instruct"],
    releasedAt: "2025-06-20",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-06-20",
  },
  {
    id: "openrouter:mistralai/mistral-small-3.2-24b-instruct:free",
    provider: "openrouter",
    vendorId: "mistralai/mistral-small-3.2-24b-instruct:free",
    displayName: "Mistral Small 3.2 24B (free)",
    family: "mistralai/mistral-small-3.2-24b-instruct:free",
    status: "stable",
    context: {"combinedMax":96000,"outputMax":96000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/mistralai/mistral-small-3.2-24b-instruct:free"],
    releasedAt: "2025-06-20",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-06-20",
  },
  {
    id: "openrouter:moonshotai/kimi-dev-72b:free",
    provider: "openrouter",
    vendorId: "moonshotai/kimi-dev-72b:free",
    displayName: "Kimi Dev 72b (free)",
    family: "moonshotai/kimi-dev-72b:free",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/moonshotai/kimi-dev-72b:free"],
    releasedAt: "2025-06-16",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-06-16",
  },
  {
    id: "openrouter:moonshotai/kimi-k2",
    provider: "openrouter",
    vendorId: "moonshotai/kimi-k2",
    displayName: "Kimi K2",
    family: "moonshotai/kimi-k2",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.55,"outputPerMTokens":2.2},
    pricingSource: "models.dev",
    aliases: ["openrouter/moonshotai/kimi-k2"],
    releasedAt: "2025-07-11",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-11",
  },
  {
    id: "openrouter:moonshotai/kimi-k2-0905",
    provider: "openrouter",
    vendorId: "moonshotai/kimi-k2-0905",
    displayName: "Kimi K2 Instruct 0905",
    family: "moonshotai/kimi-k2-0905",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":2.5},
    pricingSource: "models.dev",
    aliases: ["openrouter/moonshotai/kimi-k2-0905"],
    releasedAt: "2025-09-05",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-09-05",
  },
  {
    id: "openrouter:moonshotai/kimi-k2:free",
    provider: "openrouter",
    vendorId: "moonshotai/kimi-k2:free",
    displayName: "Kimi K2 (free)",
    family: "moonshotai/kimi-k2:free",
    status: "stable",
    context: {"combinedMax":32800,"outputMax":32800},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/moonshotai/kimi-k2:free"],
    releasedAt: "2025-07-11",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-11",
  },
  {
    id: "openrouter:nousresearch/deephermes-3-llama-3-8b-preview",
    provider: "openrouter",
    vendorId: "nousresearch/deephermes-3-llama-3-8b-preview",
    displayName: "DeepHermes 3 Llama 3 8B Preview",
    family: "nousresearch/deephermes-3-llama-3-8b-preview",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/nousresearch/deephermes-3-llama-3-8b-preview"],
    releasedAt: "2025-02-28",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-02-28",
  },
  {
    id: "openrouter:nousresearch/hermes-4-405b",
    provider: "openrouter",
    vendorId: "nousresearch/hermes-4-405b",
    displayName: "Hermes 4 405B",
    family: "nousresearch/hermes-4-405b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1,"outputPerMTokens":3},
    pricingSource: "models.dev",
    aliases: ["openrouter/nousresearch/hermes-4-405b"],
    releasedAt: "2025-08-25",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-08-25",
  },
  {
    id: "openrouter:nousresearch/hermes-4-70b",
    provider: "openrouter",
    vendorId: "nousresearch/hermes-4-70b",
    displayName: "Hermes 4 70B",
    family: "nousresearch/hermes-4-70b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.13,"outputPerMTokens":0.4},
    pricingSource: "models.dev",
    aliases: ["openrouter/nousresearch/hermes-4-70b"],
    releasedAt: "2025-08-25",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-08-25",
  },
  {
    id: "openrouter:openai/gpt-4.1",
    provider: "openrouter",
    vendorId: "openai/gpt-4.1",
    displayName: "GPT-4.1",
    family: "openai/gpt-4.1",
    status: "stable",
    context: {"combinedMax":1047576,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":8},
    pricingSource: "models.dev",
    aliases: ["openrouter/openai/gpt-4.1"],
    releasedAt: "2025-04-14",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-04-14",
  },
  {
    id: "openrouter:openai/gpt-4.1-mini",
    provider: "openrouter",
    vendorId: "openai/gpt-4.1-mini",
    displayName: "GPT-4.1 Mini",
    family: "openai/gpt-4.1-mini",
    status: "stable",
    context: {"combinedMax":1047576,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.4,"outputPerMTokens":1.6},
    pricingSource: "models.dev",
    aliases: ["openrouter/openai/gpt-4.1-mini"],
    releasedAt: "2025-04-14",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-04-14",
  },
  {
    id: "openrouter:openai/gpt-4o-mini",
    provider: "openrouter",
    vendorId: "openai/gpt-4o-mini",
    displayName: "GPT-4o-mini",
    family: "openai/gpt-4o-mini",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["openrouter/openai/gpt-4o-mini"],
    releasedAt: "2024-07-18",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2024-07-18",
  },
  {
    id: "openrouter:openai/gpt-5",
    provider: "openrouter",
    vendorId: "openai/gpt-5",
    displayName: "GPT-5",
    family: "openai/gpt-5",
    status: "stable",
    context: {"combinedMax":400000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["openrouter/openai/gpt-5"],
    releasedAt: "2025-08-07",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "openrouter:openai/gpt-5-chat",
    provider: "openrouter",
    vendorId: "openai/gpt-5-chat",
    displayName: "GPT-5 Chat (latest)",
    family: "openai/gpt-5-chat",
    status: "stable",
    context: {"combinedMax":400000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["openrouter/openai/gpt-5-chat"],
    releasedAt: "2025-08-07",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "openrouter:openai/gpt-5-mini",
    provider: "openrouter",
    vendorId: "openai/gpt-5-mini",
    displayName: "GPT-5 Mini",
    family: "openai/gpt-5-mini",
    status: "stable",
    context: {"combinedMax":400000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.25,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["openrouter/openai/gpt-5-mini"],
    releasedAt: "2025-08-07",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "openrouter:openai/gpt-5-nano",
    provider: "openrouter",
    vendorId: "openai/gpt-5-nano",
    displayName: "GPT-5 Nano",
    family: "openai/gpt-5-nano",
    status: "stable",
    context: {"combinedMax":400000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.05,"outputPerMTokens":0.4},
    pricingSource: "models.dev",
    aliases: ["openrouter/openai/gpt-5-nano"],
    releasedAt: "2025-08-07",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "openrouter:openai/gpt-oss-120b",
    provider: "openrouter",
    vendorId: "openai/gpt-oss-120b",
    displayName: "GPT OSS 120B",
    family: "openai/gpt-oss-120b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["openrouter/openai/gpt-oss-120b"],
    releasedAt: "2025-08-05",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-08-05",
  },
  {
    id: "openrouter:openai/gpt-oss-20b",
    provider: "openrouter",
    vendorId: "openai/gpt-oss-20b",
    displayName: "GPT OSS 20B",
    family: "openai/gpt-oss-20b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.05,"outputPerMTokens":0.2},
    pricingSource: "models.dev",
    aliases: ["openrouter/openai/gpt-oss-20b"],
    releasedAt: "2025-08-05",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-08-05",
  },
  {
    id: "openrouter:openai/o4-mini",
    provider: "openrouter",
    vendorId: "openai/o4-mini",
    displayName: "o4 Mini",
    family: "openai/o4-mini",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.1,"outputPerMTokens":4.4},
    pricingSource: "models.dev",
    aliases: ["openrouter/openai/o4-mini"],
    releasedAt: "2025-04-16",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-04-16",
  },
  {
    id: "openrouter:openrouter/cypher-alpha:free",
    provider: "openrouter",
    vendorId: "openrouter/cypher-alpha:free",
    displayName: "Cypher Alpha (free)",
    family: "openrouter/cypher-alpha:free",
    status: "stable",
    context: {"combinedMax":1000000,"outputMax":1000000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/openrouter/cypher-alpha:free"],
    releasedAt: "2025-07-01",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-01",
  },
  {
    id: "openrouter:openrouter/horizon-alpha",
    provider: "openrouter",
    vendorId: "openrouter/horizon-alpha",
    displayName: "Horizon Alpha",
    family: "openrouter/horizon-alpha",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/openrouter/horizon-alpha"],
    releasedAt: "2025-07-30",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-30",
  },
  {
    id: "openrouter:openrouter/horizon-beta",
    provider: "openrouter",
    vendorId: "openrouter/horizon-beta",
    displayName: "Horizon Beta",
    family: "openrouter/horizon-beta",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/openrouter/horizon-beta"],
    releasedAt: "2025-08-01",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-08-01",
  },
  {
    id: "openrouter:openrouter/sonoma-dusk-alpha",
    provider: "openrouter",
    vendorId: "openrouter/sonoma-dusk-alpha",
    displayName: "Sonoma Dusk Alpha",
    family: "openrouter/sonoma-dusk-alpha",
    status: "stable",
    context: {"combinedMax":2000000,"outputMax":2000000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/openrouter/sonoma-dusk-alpha"],
    releasedAt: "2024-09-05",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2024-09-05",
  },
  {
    id: "openrouter:openrouter/sonoma-sky-alpha",
    provider: "openrouter",
    vendorId: "openrouter/sonoma-sky-alpha",
    displayName: "Sonoma Sky Alpha",
    family: "openrouter/sonoma-sky-alpha",
    status: "stable",
    context: {"combinedMax":2000000,"outputMax":2000000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/openrouter/sonoma-sky-alpha"],
    releasedAt: "2024-09-05",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2024-09-05",
  },
  {
    id: "openrouter:qwen/qwen-2.5-coder-32b-instruct",
    provider: "openrouter",
    vendorId: "qwen/qwen-2.5-coder-32b-instruct",
    displayName: "Qwen2.5 Coder 32B Instruct",
    family: "qwen/qwen-2.5-coder-32b-instruct",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/qwen/qwen-2.5-coder-32b-instruct"],
    releasedAt: "2024-11-11",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2024-11-11",
  },
  {
    id: "openrouter:qwen/qwen2.5-vl-32b-instruct:free",
    provider: "openrouter",
    vendorId: "qwen/qwen2.5-vl-32b-instruct:free",
    displayName: "Qwen2.5 VL 32B Instruct (free)",
    family: "qwen/qwen2.5-vl-32b-instruct:free",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/qwen/qwen2.5-vl-32b-instruct:free"],
    releasedAt: "2025-03-24",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-03-24",
  },
  {
    id: "openrouter:qwen/qwen2.5-vl-72b-instruct",
    provider: "openrouter",
    vendorId: "qwen/qwen2.5-vl-72b-instruct",
    displayName: "Qwen2.5 VL 72B Instruct",
    family: "qwen/qwen2.5-vl-72b-instruct",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/qwen/qwen2.5-vl-72b-instruct"],
    releasedAt: "2025-02-01",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-02-01",
  },
  {
    id: "openrouter:qwen/qwen2.5-vl-72b-instruct:free",
    provider: "openrouter",
    vendorId: "qwen/qwen2.5-vl-72b-instruct:free",
    displayName: "Qwen2.5 VL 72B Instruct (free)",
    family: "qwen/qwen2.5-vl-72b-instruct:free",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/qwen/qwen2.5-vl-72b-instruct:free"],
    releasedAt: "2025-02-01",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-02-01",
  },
  {
    id: "openrouter:qwen/qwen3-14b:free",
    provider: "openrouter",
    vendorId: "qwen/qwen3-14b:free",
    displayName: "Qwen3 14B (free)",
    family: "qwen/qwen3-14b:free",
    status: "stable",
    context: {"combinedMax":40960,"outputMax":40960},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/qwen/qwen3-14b:free"],
    releasedAt: "2025-04-28",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-04-28",
  },
  {
    id: "openrouter:qwen/qwen3-235b-a22b-07-25",
    provider: "openrouter",
    vendorId: "qwen/qwen3-235b-a22b-07-25",
    displayName: "Qwen3 235B A22B Instruct 2507",
    family: "qwen/qwen3-235b-a22b-07-25",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.85},
    pricingSource: "models.dev",
    aliases: ["openrouter/qwen/qwen3-235b-a22b-07-25"],
    releasedAt: "2025-04-28",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-21",
  },
  {
    id: "openrouter:qwen/qwen3-235b-a22b-07-25:free",
    provider: "openrouter",
    vendorId: "qwen/qwen3-235b-a22b-07-25:free",
    displayName: "Qwen3 235B A22B Instruct 2507 (free)",
    family: "qwen/qwen3-235b-a22b-07-25:free",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/qwen/qwen3-235b-a22b-07-25:free"],
    releasedAt: "2025-04-28",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-21",
  },
  {
    id: "openrouter:qwen/qwen3-235b-a22b-thinking-2507",
    provider: "openrouter",
    vendorId: "qwen/qwen3-235b-a22b-thinking-2507",
    displayName: "Qwen3 235B A22B Thinking 2507",
    family: "qwen/qwen3-235b-a22b-thinking-2507",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":81920},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.078,"outputPerMTokens":0.312},
    pricingSource: "models.dev",
    aliases: ["openrouter/qwen/qwen3-235b-a22b-thinking-2507"],
    releasedAt: "2025-07-25",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-25",
  },
  {
    id: "openrouter:qwen/qwen3-235b-a22b:free",
    provider: "openrouter",
    vendorId: "qwen/qwen3-235b-a22b:free",
    displayName: "Qwen3 235B A22B (free)",
    family: "qwen/qwen3-235b-a22b:free",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/qwen/qwen3-235b-a22b:free"],
    releasedAt: "2025-04-28",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-04-28",
  },
  {
    id: "openrouter:qwen/qwen3-30b-a3b-instruct-2507",
    provider: "openrouter",
    vendorId: "qwen/qwen3-30b-a3b-instruct-2507",
    displayName: "Qwen3 30B A3B Instruct 2507",
    family: "qwen/qwen3-30b-a3b-instruct-2507",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":33000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.8},
    pricingSource: "models.dev",
    aliases: ["openrouter/qwen/qwen3-30b-a3b-instruct-2507"],
    releasedAt: "2025-07-29",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-29",
  },
  {
    id: "openrouter:qwen/qwen3-30b-a3b:free",
    provider: "openrouter",
    vendorId: "qwen/qwen3-30b-a3b:free",
    displayName: "Qwen3 30B A3B (free)",
    family: "qwen/qwen3-30b-a3b:free",
    status: "stable",
    context: {"combinedMax":40960,"outputMax":40960},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/qwen/qwen3-30b-a3b:free"],
    releasedAt: "2025-04-28",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-04-28",
  },
  {
    id: "openrouter:qwen/qwen3-32b:free",
    provider: "openrouter",
    vendorId: "qwen/qwen3-32b:free",
    displayName: "Qwen3 32B (free)",
    family: "qwen/qwen3-32b:free",
    status: "stable",
    context: {"combinedMax":40960,"outputMax":40960},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/qwen/qwen3-32b:free"],
    releasedAt: "2025-04-28",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-04-28",
  },
  {
    id: "openrouter:qwen/qwen3-8b:free",
    provider: "openrouter",
    vendorId: "qwen/qwen3-8b:free",
    displayName: "Qwen3 8B (free)",
    family: "qwen/qwen3-8b:free",
    status: "stable",
    context: {"combinedMax":40960,"outputMax":40960},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/qwen/qwen3-8b:free"],
    releasedAt: "2025-04-28",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-04-28",
  },
  {
    id: "openrouter:qwen/qwen3-coder",
    provider: "openrouter",
    vendorId: "qwen/qwen3-coder",
    displayName: "Qwen3 Coder",
    family: "qwen/qwen3-coder",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":66536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":1.2},
    pricingSource: "models.dev",
    aliases: ["openrouter/qwen/qwen3-coder"],
    releasedAt: "2025-07-23",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-23",
  },
  {
    id: "openrouter:qwen/qwen3-coder:free",
    provider: "openrouter",
    vendorId: "qwen/qwen3-coder:free",
    displayName: "Qwen3 Coder 480B A35B Instruct (free)",
    family: "qwen/qwen3-coder:free",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":66536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/qwen/qwen3-coder:free"],
    releasedAt: "2025-07-23",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-23",
  },
  {
    id: "openrouter:qwen/qwen3-max",
    provider: "openrouter",
    vendorId: "qwen/qwen3-max",
    displayName: "Qwen3 Max",
    family: "qwen/qwen3-max",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.2,"outputPerMTokens":6},
    pricingSource: "models.dev",
    aliases: ["openrouter/qwen/qwen3-max"],
    releasedAt: "2025-09-05",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-09-05",
  },
  {
    id: "openrouter:qwen/qwq-32b:free",
    provider: "openrouter",
    vendorId: "qwen/qwq-32b:free",
    displayName: "QwQ 32B (free)",
    family: "qwen/qwq-32b:free",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/qwen/qwq-32b:free"],
    releasedAt: "2025-03-05",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-03-05",
  },
  {
    id: "openrouter:rekaai/reka-flash-3",
    provider: "openrouter",
    vendorId: "rekaai/reka-flash-3",
    displayName: "Reka Flash 3",
    family: "rekaai/reka-flash-3",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/rekaai/reka-flash-3"],
    releasedAt: "2025-03-12",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-03-12",
  },
  {
    id: "openrouter:sarvamai/sarvam-m:free",
    provider: "openrouter",
    vendorId: "sarvamai/sarvam-m:free",
    displayName: "Sarvam-M (free)",
    family: "sarvamai/sarvam-m:free",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/sarvamai/sarvam-m:free"],
    releasedAt: "2025-05-25",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-05-25",
  },
  {
    id: "openrouter:thudm/glm-z1-32b:free",
    provider: "openrouter",
    vendorId: "thudm/glm-z1-32b:free",
    displayName: "GLM Z1 32B (free)",
    family: "thudm/glm-z1-32b:free",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/thudm/glm-z1-32b:free"],
    releasedAt: "2025-04-17",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-04-17",
  },
  {
    id: "openrouter:tngtech/deepseek-r1t2-chimera:free",
    provider: "openrouter",
    vendorId: "tngtech/deepseek-r1t2-chimera:free",
    displayName: "DeepSeek R1T2 Chimera (free)",
    family: "tngtech/deepseek-r1t2-chimera:free",
    status: "stable",
    context: {"combinedMax":163840,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/tngtech/deepseek-r1t2-chimera:free"],
    releasedAt: "2025-07-08",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-08",
  },
  {
    id: "openrouter:x-ai/grok-3",
    provider: "openrouter",
    vendorId: "x-ai/grok-3",
    displayName: "Grok 3",
    family: "x-ai/grok-3",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["openrouter/x-ai/grok-3"],
    releasedAt: "2025-02-17",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-02-17",
  },
  {
    id: "openrouter:x-ai/grok-3-beta",
    provider: "openrouter",
    vendorId: "x-ai/grok-3-beta",
    displayName: "Grok 3 Beta",
    family: "x-ai/grok-3-beta",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["openrouter/x-ai/grok-3-beta"],
    releasedAt: "2025-02-17",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-02-17",
  },
  {
    id: "openrouter:x-ai/grok-3-mini",
    provider: "openrouter",
    vendorId: "x-ai/grok-3-mini",
    displayName: "Grok 3 Mini",
    family: "x-ai/grok-3-mini",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":0.5},
    pricingSource: "models.dev",
    aliases: ["openrouter/x-ai/grok-3-mini"],
    releasedAt: "2025-02-17",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-02-17",
  },
  {
    id: "openrouter:x-ai/grok-3-mini-beta",
    provider: "openrouter",
    vendorId: "x-ai/grok-3-mini-beta",
    displayName: "Grok 3 Mini Beta",
    family: "x-ai/grok-3-mini-beta",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":0.5},
    pricingSource: "models.dev",
    aliases: ["openrouter/x-ai/grok-3-mini-beta"],
    releasedAt: "2025-02-17",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-02-17",
  },
  {
    id: "openrouter:x-ai/grok-4",
    provider: "openrouter",
    vendorId: "x-ai/grok-4",
    displayName: "Grok 4",
    family: "x-ai/grok-4",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["openrouter/x-ai/grok-4"],
    releasedAt: "2025-07-09",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-09",
  },
  {
    id: "openrouter:x-ai/grok-code-fast-1",
    provider: "openrouter",
    vendorId: "x-ai/grok-code-fast-1",
    displayName: "Grok Code Fast 1",
    family: "x-ai/grok-code-fast-1",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":10000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":1.5},
    pricingSource: "models.dev",
    aliases: ["openrouter/x-ai/grok-code-fast-1"],
    releasedAt: "2025-08-26",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-08-26",
  },
  {
    id: "openrouter:z-ai/glm-4.5",
    provider: "openrouter",
    vendorId: "z-ai/glm-4.5",
    displayName: "GLM 4.5",
    family: "z-ai/glm-4.5",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":96000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":2.2},
    pricingSource: "models.dev",
    aliases: ["openrouter/z-ai/glm-4.5"],
    releasedAt: "2025-07-28",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-28",
  },
  {
    id: "openrouter:z-ai/glm-4.5-air",
    provider: "openrouter",
    vendorId: "z-ai/glm-4.5-air",
    displayName: "GLM 4.5 Air",
    family: "z-ai/glm-4.5-air",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":96000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":1.1},
    pricingSource: "models.dev",
    aliases: ["openrouter/z-ai/glm-4.5-air"],
    releasedAt: "2025-07-28",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-28",
  },
  {
    id: "openrouter:z-ai/glm-4.5-air:free",
    provider: "openrouter",
    vendorId: "z-ai/glm-4.5-air:free",
    displayName: "GLM 4.5 Air (free)",
    family: "z-ai/glm-4.5-air:free",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":96000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["openrouter/z-ai/glm-4.5-air:free"],
    releasedAt: "2025-07-28",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-07-28",
  },
  {
    id: "openrouter:z-ai/glm-4.5v",
    provider: "openrouter",
    vendorId: "z-ai/glm-4.5v",
    displayName: "GLM 4.5V",
    family: "z-ai/glm-4.5v",
    status: "stable",
    context: {"combinedMax":64000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":1.8},
    pricingSource: "models.dev",
    aliases: ["openrouter/z-ai/glm-4.5v"],
    releasedAt: "2025-08-11",
    source: "https://openrouter.ai/models",
    contextSource: "https://openrouter.ai/models",
    verifiedAt: "2025-08-11",
  },
  {
    id: "requesty:anthropic/claude-3-7-sonnet",
    provider: "requesty",
    vendorId: "anthropic/claude-3-7-sonnet",
    displayName: "Claude Sonnet 3.7",
    family: "anthropic/claude-3-7-sonnet",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["requesty/anthropic/claude-3-7-sonnet"],
    releasedAt: "2025-02-19",
    source: "https://requesty.ai/solution/llm-routing/models",
    contextSource: "https://requesty.ai/solution/llm-routing/models",
    verifiedAt: "2025-02-19",
  },
  {
    id: "requesty:anthropic/claude-4-sonnet-20250522",
    provider: "requesty",
    vendorId: "anthropic/claude-4-sonnet-20250522",
    displayName: "Claude Sonnet 4",
    family: "anthropic/claude-4-sonnet-20250522",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["requesty/anthropic/claude-4-sonnet-20250522"],
    releasedAt: "2025-05-22",
    source: "https://requesty.ai/solution/llm-routing/models",
    contextSource: "https://requesty.ai/solution/llm-routing/models",
    verifiedAt: "2025-05-22",
  },
  {
    id: "requesty:anthropic/claude-opus-4",
    provider: "requesty",
    vendorId: "anthropic/claude-opus-4",
    displayName: "Claude Opus 4",
    family: "anthropic/claude-opus-4",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["requesty/anthropic/claude-opus-4"],
    releasedAt: "2025-05-22",
    source: "https://requesty.ai/solution/llm-routing/models",
    contextSource: "https://requesty.ai/solution/llm-routing/models",
    verifiedAt: "2025-05-22",
  },
  {
    id: "requesty:anthropic/claude-opus-4-1-20250805",
    provider: "requesty",
    vendorId: "anthropic/claude-opus-4-1-20250805",
    displayName: "Claude Opus 4.1",
    family: "anthropic/claude-opus-4-1-20250805",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["requesty/anthropic/claude-opus-4-1-20250805"],
    releasedAt: "2025-08-05",
    source: "https://requesty.ai/solution/llm-routing/models",
    contextSource: "https://requesty.ai/solution/llm-routing/models",
    verifiedAt: "2025-08-05",
  },
  {
    id: "requesty:google/gemini-2.5-flash",
    provider: "requesty",
    vendorId: "google/gemini-2.5-flash",
    displayName: "Gemini 2.5 Flash",
    family: "google/gemini-2.5-flash",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":2.5},
    pricingSource: "models.dev",
    aliases: ["requesty/google/gemini-2.5-flash"],
    releasedAt: "2025-06-17",
    source: "https://requesty.ai/solution/llm-routing/models",
    contextSource: "https://requesty.ai/solution/llm-routing/models",
    verifiedAt: "2025-06-17",
  },
  {
    id: "requesty:google/gemini-2.5-pro",
    provider: "requesty",
    vendorId: "google/gemini-2.5-pro",
    displayName: "Gemini 2.5 Pro",
    family: "google/gemini-2.5-pro",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["requesty/google/gemini-2.5-pro"],
    releasedAt: "2025-06-17",
    source: "https://requesty.ai/solution/llm-routing/models",
    contextSource: "https://requesty.ai/solution/llm-routing/models",
    verifiedAt: "2025-06-17",
  },
  {
    id: "requesty:openai/gpt-4.1",
    provider: "requesty",
    vendorId: "openai/gpt-4.1",
    displayName: "GPT-4.1",
    family: "openai/gpt-4.1",
    status: "stable",
    context: {"combinedMax":1047576,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":8},
    pricingSource: "models.dev",
    aliases: ["requesty/openai/gpt-4.1"],
    releasedAt: "2025-04-14",
    source: "https://requesty.ai/solution/llm-routing/models",
    contextSource: "https://requesty.ai/solution/llm-routing/models",
    verifiedAt: "2025-04-14",
  },
  {
    id: "requesty:openai/gpt-4.1-mini",
    provider: "requesty",
    vendorId: "openai/gpt-4.1-mini",
    displayName: "GPT-4.1 Mini",
    family: "openai/gpt-4.1-mini",
    status: "stable",
    context: {"combinedMax":1047576,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.4,"outputPerMTokens":1.6},
    pricingSource: "models.dev",
    aliases: ["requesty/openai/gpt-4.1-mini"],
    releasedAt: "2025-04-14",
    source: "https://requesty.ai/solution/llm-routing/models",
    contextSource: "https://requesty.ai/solution/llm-routing/models",
    verifiedAt: "2025-04-14",
  },
  {
    id: "requesty:openai/gpt-4o-mini",
    provider: "requesty",
    vendorId: "openai/gpt-4o-mini",
    displayName: "GPT-4o Mini",
    family: "openai/gpt-4o-mini",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["requesty/openai/gpt-4o-mini"],
    releasedAt: "2024-07-18",
    source: "https://requesty.ai/solution/llm-routing/models",
    contextSource: "https://requesty.ai/solution/llm-routing/models",
    verifiedAt: "2024-07-18",
  },
  {
    id: "requesty:openai/gpt-5",
    provider: "requesty",
    vendorId: "openai/gpt-5",
    displayName: "GPT-5",
    family: "openai/gpt-5",
    status: "stable",
    context: {"combinedMax":400000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["requesty/openai/gpt-5"],
    releasedAt: "2025-08-07",
    source: "https://requesty.ai/solution/llm-routing/models",
    contextSource: "https://requesty.ai/solution/llm-routing/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "requesty:openai/gpt-5-mini",
    provider: "requesty",
    vendorId: "openai/gpt-5-mini",
    displayName: "GPT-5 Mini",
    family: "openai/gpt-5-mini",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.25,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["requesty/openai/gpt-5-mini"],
    releasedAt: "2025-08-07",
    source: "https://requesty.ai/solution/llm-routing/models",
    contextSource: "https://requesty.ai/solution/llm-routing/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "requesty:openai/gpt-5-nano",
    provider: "requesty",
    vendorId: "openai/gpt-5-nano",
    displayName: "GPT-5 Nano",
    family: "openai/gpt-5-nano",
    status: "stable",
    context: {"combinedMax":16000,"outputMax":4000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.05,"outputPerMTokens":0.4},
    pricingSource: "models.dev",
    aliases: ["requesty/openai/gpt-5-nano"],
    releasedAt: "2025-08-07",
    source: "https://requesty.ai/solution/llm-routing/models",
    contextSource: "https://requesty.ai/solution/llm-routing/models",
    verifiedAt: "2025-08-07",
  },
  {
    id: "requesty:openai/o4-mini",
    provider: "requesty",
    vendorId: "openai/o4-mini",
    displayName: "o4 Mini",
    family: "openai/o4-mini",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.1,"outputPerMTokens":4.4},
    pricingSource: "models.dev",
    aliases: ["requesty/openai/o4-mini"],
    releasedAt: "2025-04-16",
    source: "https://requesty.ai/solution/llm-routing/models",
    contextSource: "https://requesty.ai/solution/llm-routing/models",
    verifiedAt: "2025-04-16",
  },
  {
    id: "submodel:deepseek-ai/DeepSeek-R1-0528",
    provider: "submodel",
    vendorId: "deepseek-ai/DeepSeek-R1-0528",
    displayName: "DeepSeek R1 0528",
    family: "deepseek-ai/DeepSeek-R1-0528",
    status: "stable",
    context: {"combinedMax":75000,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.5,"outputPerMTokens":2.15},
    pricingSource: "models.dev",
    aliases: ["submodel/deepseek-ai/DeepSeek-R1-0528"],
    releasedAt: "2025-08-23",
    source: "https://submodel.gitbook.io",
    contextSource: "https://submodel.gitbook.io",
    verifiedAt: "2025-08-23",
  },
  {
    id: "submodel:deepseek-ai/DeepSeek-V3-0324",
    provider: "submodel",
    vendorId: "deepseek-ai/DeepSeek-V3-0324",
    displayName: "DeepSeek V3 0324",
    family: "deepseek-ai/DeepSeek-V3-0324",
    status: "stable",
    context: {"combinedMax":75000,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.8},
    pricingSource: "models.dev",
    aliases: ["submodel/deepseek-ai/DeepSeek-V3-0324"],
    releasedAt: "2025-08-23",
    source: "https://submodel.gitbook.io",
    contextSource: "https://submodel.gitbook.io",
    verifiedAt: "2025-08-23",
  },
  {
    id: "submodel:deepseek-ai/DeepSeek-V3.1",
    provider: "submodel",
    vendorId: "deepseek-ai/DeepSeek-V3.1",
    displayName: "DeepSeek V3.1",
    family: "deepseek-ai/DeepSeek-V3.1",
    status: "stable",
    context: {"combinedMax":75000,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.8},
    pricingSource: "models.dev",
    aliases: ["submodel/deepseek-ai/DeepSeek-V3.1"],
    releasedAt: "2025-08-23",
    source: "https://submodel.gitbook.io",
    contextSource: "https://submodel.gitbook.io",
    verifiedAt: "2025-08-23",
  },
  {
    id: "submodel:openai/gpt-oss-120b",
    provider: "submodel",
    vendorId: "openai/gpt-oss-120b",
    displayName: "GPT OSS 120B",
    family: "openai/gpt-oss-120b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.5},
    pricingSource: "models.dev",
    aliases: ["submodel/openai/gpt-oss-120b"],
    releasedAt: "2025-08-23",
    source: "https://submodel.gitbook.io",
    contextSource: "https://submodel.gitbook.io",
    verifiedAt: "2025-08-23",
  },
  {
    id: "submodel:Qwen/Qwen3-235B-A22B-Instruct-2507",
    provider: "submodel",
    vendorId: "Qwen/Qwen3-235B-A22B-Instruct-2507",
    displayName: "Qwen3 235B A22B Instruct 2507",
    family: "Qwen/Qwen3-235B-A22B-Instruct-2507",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.3},
    pricingSource: "models.dev",
    aliases: ["submodel/Qwen/Qwen3-235B-A22B-Instruct-2507"],
    releasedAt: "2025-08-23",
    source: "https://submodel.gitbook.io",
    contextSource: "https://submodel.gitbook.io",
    verifiedAt: "2025-08-23",
  },
  {
    id: "submodel:Qwen/Qwen3-235B-A22B-Thinking-2507",
    provider: "submodel",
    vendorId: "Qwen/Qwen3-235B-A22B-Thinking-2507",
    displayName: "Qwen3 235B A22B Thinking 2507",
    family: "Qwen/Qwen3-235B-A22B-Thinking-2507",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["submodel/Qwen/Qwen3-235B-A22B-Thinking-2507"],
    releasedAt: "2025-08-23",
    source: "https://submodel.gitbook.io",
    contextSource: "https://submodel.gitbook.io",
    verifiedAt: "2025-08-23",
  },
  {
    id: "submodel:Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    provider: "submodel",
    vendorId: "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    displayName: "Qwen3 Coder 480B A35B Instruct",
    family: "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":262144},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.8},
    pricingSource: "models.dev",
    aliases: ["submodel/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8"],
    releasedAt: "2025-08-23",
    source: "https://submodel.gitbook.io",
    contextSource: "https://submodel.gitbook.io",
    verifiedAt: "2025-08-23",
  },
  {
    id: "submodel:zai-org/GLM-4.5-Air",
    provider: "submodel",
    vendorId: "zai-org/GLM-4.5-Air",
    displayName: "GLM 4.5 Air",
    family: "zai-org/GLM-4.5-Air",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.5},
    pricingSource: "models.dev",
    aliases: ["submodel/zai-org/GLM-4.5-Air"],
    releasedAt: "2025-07-28",
    source: "https://submodel.gitbook.io",
    contextSource: "https://submodel.gitbook.io",
    verifiedAt: "2025-07-28",
  },
  {
    id: "submodel:zai-org/GLM-4.5-FP8",
    provider: "submodel",
    vendorId: "zai-org/GLM-4.5-FP8",
    displayName: "GLM 4.5 FP8",
    family: "zai-org/GLM-4.5-FP8",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.8},
    pricingSource: "models.dev",
    aliases: ["submodel/zai-org/GLM-4.5-FP8"],
    releasedAt: "2025-07-28",
    source: "https://submodel.gitbook.io",
    contextSource: "https://submodel.gitbook.io",
    verifiedAt: "2025-07-28",
  },
  {
    id: "synthetic:hf:deepseek-ai/DeepSeek-R1",
    provider: "synthetic",
    vendorId: "hf:deepseek-ai/DeepSeek-R1",
    displayName: "DeepSeek R1",
    family: "hf:deepseek-ai/DeepSeek-R1",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.55,"outputPerMTokens":2.19},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:deepseek-ai/DeepSeek-R1"],
    releasedAt: "2025-01-20",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2025-01-20",
  },
  {
    id: "synthetic:hf:deepseek-ai/DeepSeek-R1-0528",
    provider: "synthetic",
    vendorId: "hf:deepseek-ai/DeepSeek-R1-0528",
    displayName: "DeepSeek R1 (0528)",
    family: "hf:deepseek-ai/DeepSeek-R1-0528",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":8},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:deepseek-ai/DeepSeek-R1-0528"],
    releasedAt: "2025-08-01",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2025-08-01",
  },
  {
    id: "synthetic:hf:deepseek-ai/DeepSeek-V3",
    provider: "synthetic",
    vendorId: "hf:deepseek-ai/DeepSeek-V3",
    displayName: "DeepSeek V3",
    family: "hf:deepseek-ai/DeepSeek-V3",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":1.25},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:deepseek-ai/DeepSeek-V3"],
    releasedAt: "2025-01-20",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2025-05-29",
  },
  {
    id: "synthetic:hf:deepseek-ai/DeepSeek-V3-0324",
    provider: "synthetic",
    vendorId: "hf:deepseek-ai/DeepSeek-V3-0324",
    displayName: "DeepSeek V3 (0324)",
    family: "hf:deepseek-ai/DeepSeek-V3-0324",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.2,"outputPerMTokens":1.2},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:deepseek-ai/DeepSeek-V3-0324"],
    releasedAt: "2025-08-01",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2025-08-01",
  },
  {
    id: "synthetic:hf:deepseek-ai/DeepSeek-V3.1",
    provider: "synthetic",
    vendorId: "hf:deepseek-ai/DeepSeek-V3.1",
    displayName: "DeepSeek V3.1",
    family: "hf:deepseek-ai/DeepSeek-V3.1",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.56,"outputPerMTokens":1.68},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:deepseek-ai/DeepSeek-V3.1"],
    releasedAt: "2025-08-21",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2025-08-21",
  },
  {
    id: "synthetic:hf:meta-llama/Llama-3.1-405B-Instruct",
    provider: "synthetic",
    vendorId: "hf:meta-llama/Llama-3.1-405B-Instruct",
    displayName: "Llama-3.1-405B-Instruct",
    family: "hf:meta-llama/Llama-3.1-405B-Instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":3},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:meta-llama/Llama-3.1-405B-Instruct"],
    releasedAt: "2024-07-23",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2024-07-23",
  },
  {
    id: "synthetic:hf:meta-llama/Llama-3.1-70B-Instruct",
    provider: "synthetic",
    vendorId: "hf:meta-llama/Llama-3.1-70B-Instruct",
    displayName: "Llama-3.1-70B-Instruct",
    family: "hf:meta-llama/Llama-3.1-70B-Instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.9,"outputPerMTokens":0.9},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:meta-llama/Llama-3.1-70B-Instruct"],
    releasedAt: "2024-07-23",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2024-07-23",
  },
  {
    id: "synthetic:hf:meta-llama/Llama-3.1-8B-Instruct",
    provider: "synthetic",
    vendorId: "hf:meta-llama/Llama-3.1-8B-Instruct",
    displayName: "Llama-3.1-8B-Instruct",
    family: "hf:meta-llama/Llama-3.1-8B-Instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.2},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:meta-llama/Llama-3.1-8B-Instruct"],
    releasedAt: "2024-07-23",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2024-07-23",
  },
  {
    id: "synthetic:hf:meta-llama/Llama-3.3-70B-Instruct",
    provider: "synthetic",
    vendorId: "hf:meta-llama/Llama-3.3-70B-Instruct",
    displayName: "Llama-3.3-70B-Instruct",
    family: "hf:meta-llama/Llama-3.3-70B-Instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.9,"outputPerMTokens":0.9},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:meta-llama/Llama-3.3-70B-Instruct"],
    releasedAt: "2024-12-06",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2024-12-06",
  },
  {
    id: "synthetic:hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
    provider: "synthetic",
    vendorId: "hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
    displayName: "Llama-4-Maverick-17B-128E-Instruct-FP8",
    family: "hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
    status: "stable",
    context: {"combinedMax":524000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.22,"outputPerMTokens":0.88},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8"],
    releasedAt: "2025-04-05",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2025-04-05",
  },
  {
    id: "synthetic:hf:meta-llama/Llama-4-Scout-17B-16E-Instruct",
    provider: "synthetic",
    vendorId: "hf:meta-llama/Llama-4-Scout-17B-16E-Instruct",
    displayName: "Llama-4-Scout-17B-16E-Instruct",
    family: "hf:meta-llama/Llama-4-Scout-17B-16E-Instruct",
    status: "stable",
    context: {"combinedMax":328000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:meta-llama/Llama-4-Scout-17B-16E-Instruct"],
    releasedAt: "2025-04-05",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2025-04-05",
  },
  {
    id: "synthetic:hf:moonshotai/Kimi-K2-Instruct",
    provider: "synthetic",
    vendorId: "hf:moonshotai/Kimi-K2-Instruct",
    displayName: "Kimi K2",
    family: "hf:moonshotai/Kimi-K2-Instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":2.5},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:moonshotai/Kimi-K2-Instruct"],
    releasedAt: "2025-07-11",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2025-07-11",
  },
  {
    id: "synthetic:hf:moonshotai/Kimi-K2-Instruct-0905",
    provider: "synthetic",
    vendorId: "hf:moonshotai/Kimi-K2-Instruct-0905",
    displayName: "Kimi K2 0905",
    family: "hf:moonshotai/Kimi-K2-Instruct-0905",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.2,"outputPerMTokens":1.2},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:moonshotai/Kimi-K2-Instruct-0905"],
    releasedAt: "2025-09-05",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2025-09-05",
  },
  {
    id: "synthetic:hf:openai/gpt-oss-120b",
    provider: "synthetic",
    vendorId: "hf:openai/gpt-oss-120b",
    displayName: "GPT OSS 120B",
    family: "hf:openai/gpt-oss-120b",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.1},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:openai/gpt-oss-120b"],
    releasedAt: "2025-08-05",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2025-08-05",
  },
  {
    id: "synthetic:hf:Qwen/Qwen2.5-Coder-32B-Instruct",
    provider: "synthetic",
    vendorId: "hf:Qwen/Qwen2.5-Coder-32B-Instruct",
    displayName: "Qwen2.5-Coder-32B-Instruct",
    family: "hf:Qwen/Qwen2.5-Coder-32B-Instruct",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.8,"outputPerMTokens":0.8},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:Qwen/Qwen2.5-Coder-32B-Instruct"],
    releasedAt: "2024-11-11",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2024-11-11",
  },
  {
    id: "synthetic:hf:Qwen/Qwen3-235B-A22B-Instruct-2507",
    provider: "synthetic",
    vendorId: "hf:Qwen/Qwen3-235B-A22B-Instruct-2507",
    displayName: "Qwen 3 235B Instruct",
    family: "hf:Qwen/Qwen3-235B-A22B-Instruct-2507",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:Qwen/Qwen3-235B-A22B-Instruct-2507"],
    releasedAt: "2025-04-28",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2025-07-21",
  },
  {
    id: "synthetic:hf:Qwen/Qwen3-235B-A22B-Thinking-2507",
    provider: "synthetic",
    vendorId: "hf:Qwen/Qwen3-235B-A22B-Thinking-2507",
    displayName: "Qwen3 235B A22B Thinking 2507",
    family: "hf:Qwen/Qwen3-235B-A22B-Thinking-2507",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.65,"outputPerMTokens":3},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:Qwen/Qwen3-235B-A22B-Thinking-2507"],
    releasedAt: "2025-07-25",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2025-07-25",
  },
  {
    id: "synthetic:hf:Qwen/Qwen3-Coder-480B-A35B-Instruct",
    provider: "synthetic",
    vendorId: "hf:Qwen/Qwen3-Coder-480B-A35B-Instruct",
    displayName: "Qwen 3 Coder 480B",
    family: "hf:Qwen/Qwen3-Coder-480B-A35B-Instruct",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:Qwen/Qwen3-Coder-480B-A35B-Instruct"],
    releasedAt: "2025-07-23",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2025-07-23",
  },
  {
    id: "synthetic:hf:zai-org/GLM-4.5",
    provider: "synthetic",
    vendorId: "hf:zai-org/GLM-4.5",
    displayName: "GLM 4.5",
    family: "hf:zai-org/GLM-4.5",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":96000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.55,"outputPerMTokens":2.19},
    pricingSource: "models.dev",
    aliases: ["synthetic/hf:zai-org/GLM-4.5"],
    releasedAt: "2025-07-28",
    source: "https://synthetic.new/pricing",
    contextSource: "https://synthetic.new/pricing",
    verifiedAt: "2025-07-28",
  },
  {
    id: "togetherai:deepseek-ai/DeepSeek-R1",
    provider: "togetherai",
    vendorId: "deepseek-ai/DeepSeek-R1",
    displayName: "DeepSeek R1",
    family: "deepseek-ai/DeepSeek-R1",
    status: "stable",
    context: {"combinedMax":163839,"outputMax":12288},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":7},
    pricingSource: "models.dev",
    aliases: ["togetherai/deepseek-ai/DeepSeek-R1"],
    releasedAt: "2024-12-26",
    source: "https://docs.together.ai/docs/serverless-models",
    contextSource: "https://docs.together.ai/docs/serverless-models",
    verifiedAt: "2025-03-24",
  },
  {
    id: "togetherai:deepseek-ai/DeepSeek-V3",
    provider: "togetherai",
    vendorId: "deepseek-ai/DeepSeek-V3",
    displayName: "DeepSeek V3",
    family: "deepseek-ai/DeepSeek-V3",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":12288},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":1.25},
    pricingSource: "models.dev",
    aliases: ["togetherai/deepseek-ai/DeepSeek-V3"],
    releasedAt: "2025-01-20",
    source: "https://docs.together.ai/docs/serverless-models",
    contextSource: "https://docs.together.ai/docs/serverless-models",
    verifiedAt: "2025-05-29",
  },
  {
    id: "togetherai:meta-llama/Llama-3.3-70B-Instruct-Turbo",
    provider: "togetherai",
    vendorId: "meta-llama/Llama-3.3-70B-Instruct-Turbo",
    displayName: "Llama 3.3 70B",
    family: "meta-llama/Llama-3.3-70B-Instruct-Turbo",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":66536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.88,"outputPerMTokens":0.88},
    pricingSource: "models.dev",
    aliases: ["togetherai/meta-llama/Llama-3.3-70B-Instruct-Turbo"],
    releasedAt: "2024-12-06",
    source: "https://docs.together.ai/docs/serverless-models",
    contextSource: "https://docs.together.ai/docs/serverless-models",
    verifiedAt: "2024-12-06",
  },
  {
    id: "togetherai:moonshotai/Kimi-K2-Instruct",
    provider: "togetherai",
    vendorId: "moonshotai/Kimi-K2-Instruct",
    displayName: "Kimi K2 Instruct",
    family: "moonshotai/Kimi-K2-Instruct",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1,"outputPerMTokens":3},
    pricingSource: "models.dev",
    aliases: ["togetherai/moonshotai/Kimi-K2-Instruct"],
    releasedAt: "2025-07-14",
    source: "https://docs.together.ai/docs/serverless-models",
    contextSource: "https://docs.together.ai/docs/serverless-models",
    verifiedAt: "2025-07-14",
  },
  {
    id: "togetherai:openai/gpt-oss-120b",
    provider: "togetherai",
    vendorId: "openai/gpt-oss-120b",
    displayName: "GPT OSS 120B",
    family: "openai/gpt-oss-120b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["togetherai/openai/gpt-oss-120b"],
    releasedAt: "2025-08-05",
    source: "https://docs.together.ai/docs/serverless-models",
    contextSource: "https://docs.together.ai/docs/serverless-models",
    verifiedAt: "2025-08-05",
  },
  {
    id: "togetherai:Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    provider: "togetherai",
    vendorId: "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    displayName: "Qwen3 Coder 480B A35B Instruct",
    family: "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":66536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["togetherai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8"],
    releasedAt: "2025-07-23",
    source: "https://docs.together.ai/docs/serverless-models",
    contextSource: "https://docs.together.ai/docs/serverless-models",
    verifiedAt: "2025-07-23",
  },
  {
    id: "upstage:solar-mini",
    provider: "upstage",
    vendorId: "solar-mini",
    displayName: "solar-mini",
    family: "solar-mini",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.15},
    pricingSource: "models.dev",
    aliases: ["upstage/solar-mini"],
    releasedAt: "2024-06-12",
    source: "https://developers.upstage.ai/docs/apis/chat",
    contextSource: "https://developers.upstage.ai/docs/apis/chat",
    verifiedAt: "2025-04-22",
  },
  {
    id: "upstage:solar-pro2",
    provider: "upstage",
    vendorId: "solar-pro2",
    displayName: "solar-pro2",
    family: "solar-pro2",
    status: "stable",
    context: {"combinedMax":65536,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.25,"outputPerMTokens":0.25},
    pricingSource: "models.dev",
    aliases: ["upstage/solar-pro2"],
    releasedAt: "2025-05-20",
    source: "https://developers.upstage.ai/docs/apis/chat",
    contextSource: "https://developers.upstage.ai/docs/apis/chat",
    verifiedAt: "2025-05-20",
  },
  {
    id: "v0:v0-1.0-md",
    provider: "v0",
    vendorId: "v0-1.0-md",
    displayName: "v0-1.0-md",
    family: "v0-1.0-md",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["v0/v0-1.0-md"],
    releasedAt: "2025-05-22",
    source: "https://sdk.vercel.ai/providers/ai-sdk-providers/vercel",
    contextSource: "https://sdk.vercel.ai/providers/ai-sdk-providers/vercel",
    verifiedAt: "2025-05-22",
  },
  {
    id: "v0:v0-1.5-lg",
    provider: "v0",
    vendorId: "v0-1.5-lg",
    displayName: "v0-1.5-lg",
    family: "v0-1.5-lg",
    status: "stable",
    context: {"combinedMax":512000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["v0/v0-1.5-lg"],
    releasedAt: "2025-06-09",
    source: "https://sdk.vercel.ai/providers/ai-sdk-providers/vercel",
    contextSource: "https://sdk.vercel.ai/providers/ai-sdk-providers/vercel",
    verifiedAt: "2025-06-09",
  },
  {
    id: "v0:v0-1.5-md",
    provider: "v0",
    vendorId: "v0-1.5-md",
    displayName: "v0-1.5-md",
    family: "v0-1.5-md",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["v0/v0-1.5-md"],
    releasedAt: "2025-06-09",
    source: "https://sdk.vercel.ai/providers/ai-sdk-providers/vercel",
    contextSource: "https://sdk.vercel.ai/providers/ai-sdk-providers/vercel",
    verifiedAt: "2025-06-09",
  },
  {
    id: "venice:deepseek-coder-v2-lite",
    provider: "venice",
    vendorId: "deepseek-coder-v2-lite",
    displayName: "DeepSeek Coder V2 Lite",
    family: "deepseek-coder-v2-lite",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.5,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["venice/deepseek-coder-v2-lite"],
    releasedAt: "2025-06-22",
    source: "https://docs.venice.ai",
    contextSource: "https://docs.venice.ai",
    verifiedAt: "2025-06-22",
  },
  {
    id: "venice:deepseek-r1-671b",
    provider: "venice",
    vendorId: "deepseek-r1-671b",
    displayName: "DeepSeek R1 671B",
    family: "deepseek-r1-671b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":3.5,"outputPerMTokens":14},
    pricingSource: "models.dev",
    aliases: ["venice/deepseek-r1-671b"],
    releasedAt: "2025-06-05",
    source: "https://docs.venice.ai",
    contextSource: "https://docs.venice.ai",
    verifiedAt: "2025-06-05",
  },
  {
    id: "venice:dolphin-2.9.2-qwen2-72b",
    provider: "venice",
    vendorId: "dolphin-2.9.2-qwen2-72b",
    displayName: "Dolphin 72B",
    family: "dolphin-2.9.2-qwen2-72b",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.7,"outputPerMTokens":2.8},
    pricingSource: "models.dev",
    aliases: ["venice/dolphin-2.9.2-qwen2-72b"],
    releasedAt: "2025-05-21",
    source: "https://docs.venice.ai",
    contextSource: "https://docs.venice.ai",
    verifiedAt: "2025-05-21",
  },
  {
    id: "venice:llama-3.1-405b",
    provider: "venice",
    vendorId: "llama-3.1-405b",
    displayName: "Llama 3.1 405B",
    family: "llama-3.1-405b",
    status: "stable",
    context: {"combinedMax":65536,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.5,"outputPerMTokens":6},
    pricingSource: "models.dev",
    aliases: ["venice/llama-3.1-405b"],
    releasedAt: "2025-06-30",
    source: "https://docs.venice.ai",
    contextSource: "https://docs.venice.ai",
    verifiedAt: "2025-06-30",
  },
  {
    id: "venice:llama-3.2-3b",
    provider: "venice",
    vendorId: "llama-3.2-3b",
    displayName: "Llama 3.2 3B",
    family: "llama-3.2-3b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["venice/llama-3.2-3b"],
    releasedAt: "2025-05-23",
    source: "https://docs.venice.ai",
    contextSource: "https://docs.venice.ai",
    verifiedAt: "2025-05-23",
  },
  {
    id: "venice:llama-3.3-70b",
    provider: "venice",
    vendorId: "llama-3.3-70b",
    displayName: "Llama 3.3 70B",
    family: "llama-3.3-70b",
    status: "stable",
    context: {"combinedMax":65536,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.7,"outputPerMTokens":2.8},
    pricingSource: "models.dev",
    aliases: ["venice/llama-3.3-70b"],
    releasedAt: "2025-06-09",
    source: "https://docs.venice.ai",
    contextSource: "https://docs.venice.ai",
    verifiedAt: "2025-06-09",
  },
  {
    id: "venice:mistral-31-24b",
    provider: "venice",
    vendorId: "mistral-31-24b",
    displayName: "Venice Medium",
    family: "mistral-31-24b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.5,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["venice/mistral-31-24b"],
    releasedAt: "2025-07-15",
    source: "https://docs.venice.ai",
    contextSource: "https://docs.venice.ai",
    verifiedAt: "2025-07-15",
  },
  {
    id: "venice:qwen-2.5-coder-32b",
    provider: "venice",
    vendorId: "qwen-2.5-coder-32b",
    displayName: "Qwen 2.5 Coder 32B",
    family: "qwen-2.5-coder-32b",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.5,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["venice/qwen-2.5-coder-32b"],
    releasedAt: "2025-06-14",
    source: "https://docs.venice.ai",
    contextSource: "https://docs.venice.ai",
    verifiedAt: "2025-06-14",
  },
  {
    id: "venice:qwen-2.5-qwq-32b",
    provider: "venice",
    vendorId: "qwen-2.5-qwq-32b",
    displayName: "Venice Reasoning",
    family: "qwen-2.5-qwq-32b",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.5,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["venice/qwen-2.5-qwq-32b"],
    releasedAt: "2025-07-08",
    source: "https://docs.venice.ai",
    contextSource: "https://docs.venice.ai",
    verifiedAt: "2025-07-08",
  },
  {
    id: "venice:qwen-2.5-vl",
    provider: "venice",
    vendorId: "qwen-2.5-vl",
    displayName: "Qwen 2.5 VL 72B",
    family: "qwen-2.5-vl",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.7,"outputPerMTokens":2.8},
    pricingSource: "models.dev",
    aliases: ["venice/qwen-2.5-vl"],
    releasedAt: "2025-06-09",
    source: "https://docs.venice.ai",
    contextSource: "https://docs.venice.ai",
    verifiedAt: "2025-06-09",
  },
  {
    id: "venice:qwen3-235b",
    provider: "venice",
    vendorId: "qwen3-235b",
    displayName: "Venice Large",
    family: "qwen3-235b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.5,"outputPerMTokens":6},
    pricingSource: "models.dev",
    aliases: ["venice/qwen3-235b"],
    releasedAt: "2025-07-27",
    source: "https://docs.venice.ai",
    contextSource: "https://docs.venice.ai",
    verifiedAt: "2025-07-27",
  },
  {
    id: "venice:qwen3-4b",
    provider: "venice",
    vendorId: "qwen3-4b",
    displayName: "Venice Small",
    family: "qwen3-4b",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["venice/qwen3-4b"],
    releasedAt: "2025-07-27",
    source: "https://docs.venice.ai",
    contextSource: "https://docs.venice.ai",
    verifiedAt: "2025-07-27",
  },
  {
    id: "venice:venice-uncensored",
    provider: "venice",
    vendorId: "venice-uncensored",
    displayName: "Venice Uncensored 1.1",
    family: "venice-uncensored",
    status: "stable",
    context: {"combinedMax":32768,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.5,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["venice/venice-uncensored"],
    releasedAt: "2025-07-15",
    source: "https://docs.venice.ai",
    contextSource: "https://docs.venice.ai",
    verifiedAt: "2025-07-15",
  },
  {
    id: "vercel:amazon/nova-lite",
    provider: "vercel",
    vendorId: "amazon/nova-lite",
    displayName: "Nova Lite",
    family: "amazon/nova-lite",
    status: "stable",
    context: {"combinedMax":300000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.06,"outputPerMTokens":0.24},
    pricingSource: "models.dev",
    aliases: ["vercel/amazon/nova-lite"],
    releasedAt: "2024-12-03",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-12-03",
  },
  {
    id: "vercel:amazon/nova-micro",
    provider: "vercel",
    vendorId: "amazon/nova-micro",
    displayName: "Nova Micro",
    family: "amazon/nova-micro",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.035,"outputPerMTokens":0.14},
    pricingSource: "models.dev",
    aliases: ["vercel/amazon/nova-micro"],
    releasedAt: "2024-12-03",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-12-03",
  },
  {
    id: "vercel:amazon/nova-pro",
    provider: "vercel",
    vendorId: "amazon/nova-pro",
    displayName: "Nova Pro",
    family: "amazon/nova-pro",
    status: "stable",
    context: {"combinedMax":300000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.8,"outputPerMTokens":3.2},
    pricingSource: "models.dev",
    aliases: ["vercel/amazon/nova-pro"],
    releasedAt: "2024-12-03",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-12-03",
  },
  {
    id: "vercel:anthropic/claude-3-5-haiku",
    provider: "vercel",
    vendorId: "anthropic/claude-3-5-haiku",
    displayName: "Claude Haiku 3.5",
    family: "anthropic/claude-3-5-haiku",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.8,"outputPerMTokens":4},
    pricingSource: "models.dev",
    aliases: ["vercel/anthropic/claude-3-5-haiku"],
    releasedAt: "2024-10-22",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-10-22",
  },
  {
    id: "vercel:anthropic/claude-3-haiku",
    provider: "vercel",
    vendorId: "anthropic/claude-3-haiku",
    displayName: "Claude Haiku 3",
    family: "anthropic/claude-3-haiku",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.25,"outputPerMTokens":1.25},
    pricingSource: "models.dev",
    aliases: ["vercel/anthropic/claude-3-haiku"],
    releasedAt: "2024-03-13",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-03-13",
  },
  {
    id: "vercel:anthropic/claude-3-opus",
    provider: "vercel",
    vendorId: "anthropic/claude-3-opus",
    displayName: "Claude Opus 3",
    family: "anthropic/claude-3-opus",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["vercel/anthropic/claude-3-opus"],
    releasedAt: "2024-02-29",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-02-29",
  },
  {
    id: "vercel:anthropic/claude-3.5-sonnet",
    provider: "vercel",
    vendorId: "anthropic/claude-3.5-sonnet",
    displayName: "Claude Sonnet 3.5 v2",
    family: "anthropic/claude-3.5-sonnet",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["vercel/anthropic/claude-3.5-sonnet"],
    releasedAt: "2024-10-22",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-10-22",
  },
  {
    id: "vercel:anthropic/claude-3.7-sonnet",
    provider: "vercel",
    vendorId: "anthropic/claude-3.7-sonnet",
    displayName: "Claude Sonnet 3.7",
    family: "anthropic/claude-3.7-sonnet",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["vercel/anthropic/claude-3.7-sonnet"],
    releasedAt: "2025-02-19",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-02-19",
  },
  {
    id: "vercel:anthropic/claude-4-1-opus",
    provider: "vercel",
    vendorId: "anthropic/claude-4-1-opus",
    displayName: "Claude Opus 4",
    family: "anthropic/claude-4-1-opus",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["vercel/anthropic/claude-4-1-opus"],
    releasedAt: "2025-05-22",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-05-22",
  },
  {
    id: "vercel:anthropic/claude-4-opus",
    provider: "vercel",
    vendorId: "anthropic/claude-4-opus",
    displayName: "Claude Opus 4",
    family: "anthropic/claude-4-opus",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":75},
    pricingSource: "models.dev",
    aliases: ["vercel/anthropic/claude-4-opus"],
    releasedAt: "2025-05-22",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-05-22",
  },
  {
    id: "vercel:anthropic/claude-4-sonnet",
    provider: "vercel",
    vendorId: "anthropic/claude-4-sonnet",
    displayName: "Claude Sonnet 4",
    family: "anthropic/claude-4-sonnet",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["vercel/anthropic/claude-4-sonnet"],
    releasedAt: "2025-05-22",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-05-22",
  },
  {
    id: "vercel:cerebras/qwen3-coder",
    provider: "vercel",
    vendorId: "cerebras/qwen3-coder",
    displayName: "Qwen 3 Coder 480B",
    family: "cerebras/qwen3-coder",
    status: "stable",
    context: {"combinedMax":131000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["vercel/cerebras/qwen3-coder"],
    releasedAt: "2025-07-23",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-07-23",
  },
  {
    id: "vercel:deepseek/deepseek-r1",
    provider: "vercel",
    vendorId: "deepseek/deepseek-r1",
    displayName: "DeepSeek-R1",
    family: "deepseek/deepseek-r1",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.35,"outputPerMTokens":5.4},
    pricingSource: "models.dev",
    aliases: ["vercel/deepseek/deepseek-r1"],
    releasedAt: "2025-01-20",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-05-29",
  },
  {
    id: "vercel:deepseek/deepseek-r1-distill-llama-70b",
    provider: "vercel",
    vendorId: "deepseek/deepseek-r1-distill-llama-70b",
    displayName: "DeepSeek R1 Distill Llama 70B",
    family: "deepseek/deepseek-r1-distill-llama-70b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.75,"outputPerMTokens":0.99},
    pricingSource: "models.dev",
    aliases: ["vercel/deepseek/deepseek-r1-distill-llama-70b"],
    releasedAt: "2025-01-20",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-01-20",
  },
  {
    id: "vercel:google/gemini-2.0-flash",
    provider: "vercel",
    vendorId: "google/gemini-2.0-flash",
    displayName: "Gemini 2.0 Flash",
    family: "google/gemini-2.0-flash",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.4},
    pricingSource: "models.dev",
    aliases: ["vercel/google/gemini-2.0-flash"],
    releasedAt: "2024-12-11",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-12-11",
  },
  {
    id: "vercel:google/gemini-2.0-flash-lite",
    provider: "vercel",
    vendorId: "google/gemini-2.0-flash-lite",
    displayName: "Gemini 2.0 Flash Lite",
    family: "google/gemini-2.0-flash-lite",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.075,"outputPerMTokens":0.3},
    pricingSource: "models.dev",
    aliases: ["vercel/google/gemini-2.0-flash-lite"],
    releasedAt: "2024-12-11",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-12-11",
  },
  {
    id: "vercel:google/gemini-2.5-flash",
    provider: "vercel",
    vendorId: "google/gemini-2.5-flash",
    displayName: "Gemini 2.5 Flash",
    family: "google/gemini-2.5-flash",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":2.5},
    pricingSource: "models.dev",
    aliases: ["vercel/google/gemini-2.5-flash"],
    releasedAt: "2025-03-20",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-06-05",
  },
  {
    id: "vercel:google/gemini-2.5-pro",
    provider: "vercel",
    vendorId: "google/gemini-2.5-pro",
    displayName: "Gemini 2.5 Pro",
    family: "google/gemini-2.5-pro",
    status: "stable",
    context: {"combinedMax":1048576,"outputMax":65536},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["vercel/google/gemini-2.5-pro"],
    releasedAt: "2025-03-20",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-06-05",
  },
  {
    id: "vercel:meta/llama-3.3-70b",
    provider: "vercel",
    vendorId: "meta/llama-3.3-70b",
    displayName: "Llama-3.3-70B-Instruct",
    family: "meta/llama-3.3-70b",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["vercel/meta/llama-3.3-70b"],
    releasedAt: "2024-12-06",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-12-06",
  },
  {
    id: "vercel:meta/llama-4-maverick",
    provider: "vercel",
    vendorId: "meta/llama-4-maverick",
    displayName: "Llama-4-Maverick-17B-128E-Instruct-FP8",
    family: "meta/llama-4-maverick",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["vercel/meta/llama-4-maverick"],
    releasedAt: "2025-04-05",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-04-05",
  },
  {
    id: "vercel:meta/llama-4-scout",
    provider: "vercel",
    vendorId: "meta/llama-4-scout",
    displayName: "Llama-4-Scout-17B-16E-Instruct-FP8",
    family: "meta/llama-4-scout",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["vercel/meta/llama-4-scout"],
    releasedAt: "2025-04-05",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-04-05",
  },
  {
    id: "vercel:mistral/codestral",
    provider: "vercel",
    vendorId: "mistral/codestral",
    displayName: "Codestral",
    family: "mistral/codestral",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":0.9},
    pricingSource: "models.dev",
    aliases: ["vercel/mistral/codestral"],
    releasedAt: "2024-05-29",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-01-04",
  },
  {
    id: "vercel:mistral/magistral-medium",
    provider: "vercel",
    vendorId: "mistral/magistral-medium",
    displayName: "Magistral Medium",
    family: "mistral/magistral-medium",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":5},
    pricingSource: "models.dev",
    aliases: ["vercel/mistral/magistral-medium"],
    releasedAt: "2025-03-17",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-03-20",
  },
  {
    id: "vercel:mistral/magistral-small",
    provider: "vercel",
    vendorId: "mistral/magistral-small",
    displayName: "Magistral Small",
    family: "mistral/magistral-small",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.5,"outputPerMTokens":1.5},
    pricingSource: "models.dev",
    aliases: ["vercel/mistral/magistral-small"],
    releasedAt: "2025-03-17",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-03-17",
  },
  {
    id: "vercel:mistral/ministral-3b",
    provider: "vercel",
    vendorId: "mistral/ministral-3b",
    displayName: "Ministral 3B",
    family: "mistral/ministral-3b",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.04,"outputPerMTokens":0.04},
    pricingSource: "models.dev",
    aliases: ["vercel/mistral/ministral-3b"],
    releasedAt: "2024-10-01",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-10-04",
  },
  {
    id: "vercel:mistral/ministral-8b",
    provider: "vercel",
    vendorId: "mistral/ministral-8b",
    displayName: "Ministral 8B",
    family: "mistral/ministral-8b",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.1},
    pricingSource: "models.dev",
    aliases: ["vercel/mistral/ministral-8b"],
    releasedAt: "2024-10-01",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-10-04",
  },
  {
    id: "vercel:mistral/mistral-large",
    provider: "vercel",
    vendorId: "mistral/mistral-large",
    displayName: "Mistral Large",
    family: "mistral/mistral-large",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":6},
    pricingSource: "models.dev",
    aliases: ["vercel/mistral/mistral-large"],
    releasedAt: "2024-11-01",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-11-04",
  },
  {
    id: "vercel:mistral/mistral-small",
    provider: "vercel",
    vendorId: "mistral/mistral-small",
    displayName: "Mistral Small",
    family: "mistral/mistral-small",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.3},
    pricingSource: "models.dev",
    aliases: ["vercel/mistral/mistral-small"],
    releasedAt: "2024-09-01",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-09-04",
  },
  {
    id: "vercel:mistral/mixtral-8x22b-instruct",
    provider: "vercel",
    vendorId: "mistral/mixtral-8x22b-instruct",
    displayName: "Mixtral 8x22B",
    family: "mistral/mixtral-8x22b-instruct",
    status: "stable",
    context: {"combinedMax":64000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":6},
    pricingSource: "models.dev",
    aliases: ["vercel/mistral/mixtral-8x22b-instruct"],
    releasedAt: "2024-04-17",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-04-17",
  },
  {
    id: "vercel:mistral/pixtral-12b",
    provider: "vercel",
    vendorId: "mistral/pixtral-12b",
    displayName: "Pixtral 12B",
    family: "mistral/pixtral-12b",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.15},
    pricingSource: "models.dev",
    aliases: ["vercel/mistral/pixtral-12b"],
    releasedAt: "2024-09-01",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-09-01",
  },
  {
    id: "vercel:mistral/pixtral-large",
    provider: "vercel",
    vendorId: "mistral/pixtral-large",
    displayName: "Pixtral Large",
    family: "mistral/pixtral-large",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":6},
    pricingSource: "models.dev",
    aliases: ["vercel/mistral/pixtral-large"],
    releasedAt: "2024-11-01",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-11-04",
  },
  {
    id: "vercel:moonshotai/kimi-k2",
    provider: "vercel",
    vendorId: "moonshotai/kimi-k2",
    displayName: "Kimi K2 Instruct",
    family: "moonshotai/kimi-k2",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1,"outputPerMTokens":3},
    pricingSource: "models.dev",
    aliases: ["vercel/moonshotai/kimi-k2"],
    releasedAt: "2025-07-14",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-07-14",
  },
  {
    id: "vercel:morph/morph-v3-fast",
    provider: "vercel",
    vendorId: "morph/morph-v3-fast",
    displayName: "Morph v3 Fast",
    family: "morph/morph-v3-fast",
    status: "stable",
    context: {"combinedMax":16000,"outputMax":16000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.8,"outputPerMTokens":1.2},
    pricingSource: "models.dev",
    aliases: ["vercel/morph/morph-v3-fast"],
    releasedAt: "2024-08-15",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-08-15",
  },
  {
    id: "vercel:morph/morph-v3-large",
    provider: "vercel",
    vendorId: "morph/morph-v3-large",
    displayName: "Morph v3 Large",
    family: "morph/morph-v3-large",
    status: "stable",
    context: {"combinedMax":32000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.9,"outputPerMTokens":1.9},
    pricingSource: "models.dev",
    aliases: ["vercel/morph/morph-v3-large"],
    releasedAt: "2024-08-15",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-08-15",
  },
  {
    id: "vercel:openai/gpt-4-turbo",
    provider: "vercel",
    vendorId: "openai/gpt-4-turbo",
    displayName: "GPT-4 Turbo",
    family: "openai/gpt-4-turbo",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":10,"outputPerMTokens":30},
    pricingSource: "models.dev",
    aliases: ["vercel/openai/gpt-4-turbo"],
    releasedAt: "2023-11-06",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-04-09",
  },
  {
    id: "vercel:openai/gpt-4.1",
    provider: "vercel",
    vendorId: "openai/gpt-4.1",
    displayName: "GPT-4.1",
    family: "openai/gpt-4.1",
    status: "stable",
    context: {"combinedMax":1047576,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":8},
    pricingSource: "models.dev",
    aliases: ["vercel/openai/gpt-4.1"],
    releasedAt: "2025-04-14",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-04-14",
  },
  {
    id: "vercel:openai/gpt-4.1-mini",
    provider: "vercel",
    vendorId: "openai/gpt-4.1-mini",
    displayName: "GPT-4.1 mini",
    family: "openai/gpt-4.1-mini",
    status: "stable",
    context: {"combinedMax":1047576,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.4,"outputPerMTokens":1.6},
    pricingSource: "models.dev",
    aliases: ["vercel/openai/gpt-4.1-mini"],
    releasedAt: "2025-04-14",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-04-14",
  },
  {
    id: "vercel:openai/gpt-4.1-nano",
    provider: "vercel",
    vendorId: "openai/gpt-4.1-nano",
    displayName: "GPT-4.1 nano",
    family: "openai/gpt-4.1-nano",
    status: "stable",
    context: {"combinedMax":1047576,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.4},
    pricingSource: "models.dev",
    aliases: ["vercel/openai/gpt-4.1-nano"],
    releasedAt: "2025-04-14",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-04-14",
  },
  {
    id: "vercel:openai/gpt-4o",
    provider: "vercel",
    vendorId: "openai/gpt-4o",
    displayName: "GPT-4o",
    family: "openai/gpt-4o",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2.5,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["vercel/openai/gpt-4o"],
    releasedAt: "2024-05-13",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-05-13",
  },
  {
    id: "vercel:openai/gpt-4o-mini",
    provider: "vercel",
    vendorId: "openai/gpt-4o-mini",
    displayName: "GPT-4o mini",
    family: "openai/gpt-4o-mini",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.15,"outputPerMTokens":0.6},
    pricingSource: "models.dev",
    aliases: ["vercel/openai/gpt-4o-mini"],
    releasedAt: "2024-07-18",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-07-18",
  },
  {
    id: "vercel:openai/gpt-5",
    provider: "vercel",
    vendorId: "openai/gpt-5",
    displayName: "GPT-5",
    family: "openai/gpt-5",
    status: "stable",
    context: {"combinedMax":400000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.25,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["vercel/openai/gpt-5"],
    releasedAt: "2025-08-07",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-08-07",
  },
  {
    id: "vercel:openai/gpt-5-mini",
    provider: "vercel",
    vendorId: "openai/gpt-5-mini",
    displayName: "GPT-5 Mini",
    family: "openai/gpt-5-mini",
    status: "stable",
    context: {"combinedMax":400000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.25,"outputPerMTokens":2},
    pricingSource: "models.dev",
    aliases: ["vercel/openai/gpt-5-mini"],
    releasedAt: "2025-08-07",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-08-07",
  },
  {
    id: "vercel:openai/gpt-5-nano",
    provider: "vercel",
    vendorId: "openai/gpt-5-nano",
    displayName: "GPT-5 Nano",
    family: "openai/gpt-5-nano",
    status: "stable",
    context: {"combinedMax":400000,"outputMax":128000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.05,"outputPerMTokens":0.4},
    pricingSource: "models.dev",
    aliases: ["vercel/openai/gpt-5-nano"],
    releasedAt: "2025-08-07",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-08-07",
  },
  {
    id: "vercel:openai/gpt-oss-120b",
    provider: "vercel",
    vendorId: "openai/gpt-oss-120b",
    displayName: "GPT OSS 120B",
    family: "openai/gpt-oss-120b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.5},
    pricingSource: "models.dev",
    aliases: ["vercel/openai/gpt-oss-120b"],
    releasedAt: "2025-08-05",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-08-05",
  },
  {
    id: "vercel:openai/gpt-oss-20b",
    provider: "vercel",
    vendorId: "openai/gpt-oss-20b",
    displayName: "GPT OSS 20B",
    family: "openai/gpt-oss-20b",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.07,"outputPerMTokens":0.3},
    pricingSource: "models.dev",
    aliases: ["vercel/openai/gpt-oss-20b"],
    releasedAt: "2025-08-05",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-08-05",
  },
  {
    id: "vercel:openai/o1",
    provider: "vercel",
    vendorId: "openai/o1",
    displayName: "o1",
    family: "openai/o1",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":15,"outputPerMTokens":60},
    pricingSource: "models.dev",
    aliases: ["vercel/openai/o1"],
    releasedAt: "2024-12-05",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-12-05",
  },
  {
    id: "vercel:openai/o3",
    provider: "vercel",
    vendorId: "openai/o3",
    displayName: "o3",
    family: "openai/o3",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":8},
    pricingSource: "models.dev",
    aliases: ["vercel/openai/o3"],
    releasedAt: "2025-04-16",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-04-16",
  },
  {
    id: "vercel:openai/o3-mini",
    provider: "vercel",
    vendorId: "openai/o3-mini",
    displayName: "o3-mini",
    family: "openai/o3-mini",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.1,"outputPerMTokens":4.4},
    pricingSource: "models.dev",
    aliases: ["vercel/openai/o3-mini"],
    releasedAt: "2024-12-20",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-01-29",
  },
  {
    id: "vercel:openai/o4-mini",
    provider: "vercel",
    vendorId: "openai/o4-mini",
    displayName: "o4-mini",
    family: "openai/o4-mini",
    status: "stable",
    context: {"combinedMax":200000,"outputMax":100000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":1.1,"outputPerMTokens":4.4},
    pricingSource: "models.dev",
    aliases: ["vercel/openai/o4-mini"],
    releasedAt: "2025-04-16",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-04-16",
  },
  {
    id: "vercel:vercel/v0-1.0-md",
    provider: "vercel",
    vendorId: "vercel/v0-1.0-md",
    displayName: "v0-1.0-md",
    family: "vercel/v0-1.0-md",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["vercel/vercel/v0-1.0-md"],
    releasedAt: "2025-05-22",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-05-22",
  },
  {
    id: "vercel:vercel/v0-1.5-md",
    provider: "vercel",
    vendorId: "vercel/v0-1.5-md",
    displayName: "v0-1.5-md",
    family: "vercel/v0-1.5-md",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32000},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["vercel/vercel/v0-1.5-md"],
    releasedAt: "2025-06-09",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-06-09",
  },
  {
    id: "vercel:xai/grok-2",
    provider: "vercel",
    vendorId: "xai/grok-2",
    displayName: "Grok 2",
    family: "xai/grok-2",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["vercel/xai/grok-2"],
    releasedAt: "2024-08-20",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-08-20",
  },
  {
    id: "vercel:xai/grok-2-vision",
    provider: "vercel",
    vendorId: "xai/grok-2-vision",
    displayName: "Grok 2 Vision",
    family: "xai/grok-2-vision",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["vercel/xai/grok-2-vision"],
    releasedAt: "2024-08-20",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2024-08-20",
  },
  {
    id: "vercel:xai/grok-3",
    provider: "vercel",
    vendorId: "xai/grok-3",
    displayName: "Grok 3",
    family: "xai/grok-3",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["vercel/xai/grok-3"],
    releasedAt: "2025-02-17",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-02-17",
  },
  {
    id: "vercel:xai/grok-3-fast",
    provider: "vercel",
    vendorId: "xai/grok-3-fast",
    displayName: "Grok 3 Fast",
    family: "xai/grok-3-fast",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":5,"outputPerMTokens":25},
    pricingSource: "models.dev",
    aliases: ["vercel/xai/grok-3-fast"],
    releasedAt: "2025-02-17",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-02-17",
  },
  {
    id: "vercel:xai/grok-3-mini",
    provider: "vercel",
    vendorId: "xai/grok-3-mini",
    displayName: "Grok 3 Mini",
    family: "xai/grok-3-mini",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":0.5},
    pricingSource: "models.dev",
    aliases: ["vercel/xai/grok-3-mini"],
    releasedAt: "2025-02-17",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-02-17",
  },
  {
    id: "vercel:xai/grok-3-mini-fast",
    provider: "vercel",
    vendorId: "xai/grok-3-mini-fast",
    displayName: "Grok 3 Mini Fast",
    family: "xai/grok-3-mini-fast",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":4},
    pricingSource: "models.dev",
    aliases: ["vercel/xai/grok-3-mini-fast"],
    releasedAt: "2025-02-17",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-02-17",
  },
  {
    id: "vercel:xai/grok-4",
    provider: "vercel",
    vendorId: "xai/grok-4",
    displayName: "Grok 4",
    family: "xai/grok-4",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["vercel/xai/grok-4"],
    releasedAt: "2025-07-09",
    source: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    contextSource: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    verifiedAt: "2025-07-09",
  },
  {
    id: "wandb:deepseek-ai/DeepSeek-R1-0528",
    provider: "wandb",
    vendorId: "deepseek-ai/DeepSeek-R1-0528",
    displayName: "DeepSeek-R1-0528",
    family: "deepseek-ai/DeepSeek-R1-0528",
    status: "stable",
    context: {"combinedMax":161000,"outputMax":163840},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.35,"outputPerMTokens":5.4},
    pricingSource: "models.dev",
    aliases: ["wandb/deepseek-ai/DeepSeek-R1-0528"],
    releasedAt: "2025-05-28",
    source: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    contextSource: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    verifiedAt: "2025-05-28",
  },
  {
    id: "wandb:deepseek-ai/DeepSeek-V3-0324",
    provider: "wandb",
    vendorId: "deepseek-ai/DeepSeek-V3-0324",
    displayName: "DeepSeek-V3-0324",
    family: "deepseek-ai/DeepSeek-V3-0324",
    status: "stable",
    context: {"combinedMax":161000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.14,"outputPerMTokens":2.75},
    pricingSource: "models.dev",
    aliases: ["wandb/deepseek-ai/DeepSeek-V3-0324"],
    releasedAt: "2025-03-24",
    source: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    contextSource: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    verifiedAt: "2025-03-24",
  },
  {
    id: "wandb:meta-llama/Llama-3.1-8B-Instruct",
    provider: "wandb",
    vendorId: "meta-llama/Llama-3.1-8B-Instruct",
    displayName: "Meta-Llama-3.1-8B-Instruct",
    family: "meta-llama/Llama-3.1-8B-Instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.22,"outputPerMTokens":0.22},
    pricingSource: "models.dev",
    aliases: ["wandb/meta-llama/Llama-3.1-8B-Instruct"],
    releasedAt: "2024-07-23",
    source: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    contextSource: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    verifiedAt: "2024-07-23",
  },
  {
    id: "wandb:meta-llama/Llama-3.3-70B-Instruct",
    provider: "wandb",
    vendorId: "meta-llama/Llama-3.3-70B-Instruct",
    displayName: "Llama-3.3-70B-Instruct",
    family: "meta-llama/Llama-3.3-70B-Instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":32768},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.71,"outputPerMTokens":0.71},
    pricingSource: "models.dev",
    aliases: ["wandb/meta-llama/Llama-3.3-70B-Instruct"],
    releasedAt: "2024-12-06",
    source: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    contextSource: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    verifiedAt: "2024-12-06",
  },
  {
    id: "wandb:meta-llama/Llama-4-Scout-17B-16E-Instruct",
    provider: "wandb",
    vendorId: "meta-llama/Llama-4-Scout-17B-16E-Instruct",
    displayName: "Llama 4 Scout 17B 16E Instruct",
    family: "meta-llama/Llama-4-Scout-17B-16E-Instruct",
    status: "stable",
    context: {"combinedMax":64000,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.17,"outputPerMTokens":0.66},
    pricingSource: "models.dev",
    aliases: ["wandb/meta-llama/Llama-4-Scout-17B-16E-Instruct"],
    releasedAt: "2025-01-31",
    source: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    contextSource: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    verifiedAt: "2025-01-31",
  },
  {
    id: "wandb:microsoft/Phi-4-mini-instruct",
    provider: "wandb",
    vendorId: "microsoft/Phi-4-mini-instruct",
    displayName: "Phi-4-mini-instruct",
    family: "microsoft/Phi-4-mini-instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.08,"outputPerMTokens":0.35},
    pricingSource: "models.dev",
    aliases: ["wandb/microsoft/Phi-4-mini-instruct"],
    releasedAt: "2024-12-11",
    source: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    contextSource: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    verifiedAt: "2024-12-11",
  },
  {
    id: "wandb:moonshotai/Kimi-K2-Instruct",
    provider: "wandb",
    vendorId: "moonshotai/Kimi-K2-Instruct",
    displayName: "Kimi-K2-Instruct",
    family: "moonshotai/Kimi-K2-Instruct",
    status: "stable",
    context: {"combinedMax":128000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1.35,"outputPerMTokens":4},
    pricingSource: "models.dev",
    aliases: ["wandb/moonshotai/Kimi-K2-Instruct"],
    releasedAt: "2025-07-14",
    source: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    contextSource: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    verifiedAt: "2025-07-14",
  },
  {
    id: "wandb:Qwen/Qwen3-235B-A22B-Instruct-2507",
    provider: "wandb",
    vendorId: "Qwen/Qwen3-235B-A22B-Instruct-2507",
    displayName: "Qwen3 235B A22B Instruct 2507",
    family: "Qwen/Qwen3-235B-A22B-Instruct-2507",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.1},
    pricingSource: "models.dev",
    aliases: ["wandb/Qwen/Qwen3-235B-A22B-Instruct-2507"],
    releasedAt: "2025-04-28",
    source: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    contextSource: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    verifiedAt: "2025-07-21",
  },
  {
    id: "wandb:Qwen/Qwen3-235B-A22B-Thinking-2507",
    provider: "wandb",
    vendorId: "Qwen/Qwen3-235B-A22B-Thinking-2507",
    displayName: "Qwen3-235B-A22B-Thinking-2507",
    family: "Qwen/Qwen3-235B-A22B-Thinking-2507",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":131072},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.1,"outputPerMTokens":0.1},
    pricingSource: "models.dev",
    aliases: ["wandb/Qwen/Qwen3-235B-A22B-Thinking-2507"],
    releasedAt: "2025-07-25",
    source: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    contextSource: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    verifiedAt: "2025-07-25",
  },
  {
    id: "wandb:Qwen/Qwen3-Coder-480B-A35B-Instruct",
    provider: "wandb",
    vendorId: "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    displayName: "Qwen3-Coder-480B-A35B-Instruct",
    family: "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    status: "stable",
    context: {"combinedMax":262144,"outputMax":66536},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":1,"outputPerMTokens":1.5},
    pricingSource: "models.dev",
    aliases: ["wandb/Qwen/Qwen3-Coder-480B-A35B-Instruct"],
    releasedAt: "2025-07-23",
    source: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    contextSource: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    verifiedAt: "2025-07-23",
  },
  {
    id: "xai:grok-2",
    provider: "xai",
    vendorId: "grok-2",
    displayName: "Grok 2",
    family: "grok-2",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["xai/grok-2"],
    releasedAt: "2024-08-20",
    source: "https://docs.x.ai/docs/models",
    contextSource: "https://docs.x.ai/docs/models",
    verifiedAt: "2024-08-20",
  },
  {
    id: "xai:grok-2-1212",
    provider: "xai",
    vendorId: "grok-2-1212",
    displayName: "Grok 2 (1212)",
    family: "grok-2-1212",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["xai/grok-2-1212"],
    releasedAt: "2024-12-12",
    source: "https://docs.x.ai/docs/models",
    contextSource: "https://docs.x.ai/docs/models",
    verifiedAt: "2024-12-12",
  },
  {
    id: "xai:grok-2-latest",
    provider: "xai",
    vendorId: "grok-2-latest",
    displayName: "Grok 2 Latest",
    family: "grok-2-latest",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["xai/grok-2-latest"],
    releasedAt: "2024-08-20",
    source: "https://docs.x.ai/docs/models",
    contextSource: "https://docs.x.ai/docs/models",
    verifiedAt: "2024-12-12",
  },
  {
    id: "xai:grok-2-vision",
    provider: "xai",
    vendorId: "grok-2-vision",
    displayName: "Grok 2 Vision",
    family: "grok-2-vision",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["xai/grok-2-vision"],
    releasedAt: "2024-08-20",
    source: "https://docs.x.ai/docs/models",
    contextSource: "https://docs.x.ai/docs/models",
    verifiedAt: "2024-08-20",
  },
  {
    id: "xai:grok-2-vision-1212",
    provider: "xai",
    vendorId: "grok-2-vision-1212",
    displayName: "Grok 2 Vision (1212)",
    family: "grok-2-vision-1212",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["xai/grok-2-vision-1212"],
    releasedAt: "2024-08-20",
    source: "https://docs.x.ai/docs/models",
    contextSource: "https://docs.x.ai/docs/models",
    verifiedAt: "2024-12-12",
  },
  {
    id: "xai:grok-2-vision-latest",
    provider: "xai",
    vendorId: "grok-2-vision-latest",
    displayName: "Grok 2 Vision Latest",
    family: "grok-2-vision-latest",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":2,"outputPerMTokens":10},
    pricingSource: "models.dev",
    aliases: ["xai/grok-2-vision-latest"],
    releasedAt: "2024-08-20",
    source: "https://docs.x.ai/docs/models",
    contextSource: "https://docs.x.ai/docs/models",
    verifiedAt: "2024-12-12",
  },
  {
    id: "xai:grok-3",
    provider: "xai",
    vendorId: "grok-3",
    displayName: "Grok 3",
    family: "grok-3",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["xai/grok-3"],
    releasedAt: "2025-02-17",
    source: "https://docs.x.ai/docs/models",
    contextSource: "https://docs.x.ai/docs/models",
    verifiedAt: "2025-02-17",
  },
  {
    id: "xai:grok-3-fast",
    provider: "xai",
    vendorId: "grok-3-fast",
    displayName: "Grok 3 Fast",
    family: "grok-3-fast",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":5,"outputPerMTokens":25},
    pricingSource: "models.dev",
    aliases: ["xai/grok-3-fast"],
    releasedAt: "2025-02-17",
    source: "https://docs.x.ai/docs/models",
    contextSource: "https://docs.x.ai/docs/models",
    verifiedAt: "2025-02-17",
  },
  {
    id: "xai:grok-3-fast-latest",
    provider: "xai",
    vendorId: "grok-3-fast-latest",
    displayName: "Grok 3 Fast Latest",
    family: "grok-3-fast-latest",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":5,"outputPerMTokens":25},
    pricingSource: "models.dev",
    aliases: ["xai/grok-3-fast-latest"],
    releasedAt: "2025-02-17",
    source: "https://docs.x.ai/docs/models",
    contextSource: "https://docs.x.ai/docs/models",
    verifiedAt: "2025-02-17",
  },
  {
    id: "xai:grok-3-latest",
    provider: "xai",
    vendorId: "grok-3-latest",
    displayName: "Grok 3 Latest",
    family: "grok-3-latest",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["xai/grok-3-latest"],
    releasedAt: "2025-02-17",
    source: "https://docs.x.ai/docs/models",
    contextSource: "https://docs.x.ai/docs/models",
    verifiedAt: "2025-02-17",
  },
  {
    id: "xai:grok-3-mini",
    provider: "xai",
    vendorId: "grok-3-mini",
    displayName: "Grok 3 Mini",
    family: "grok-3-mini",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":0.5},
    pricingSource: "models.dev",
    aliases: ["xai/grok-3-mini"],
    releasedAt: "2025-02-17",
    source: "https://docs.x.ai/docs/models",
    contextSource: "https://docs.x.ai/docs/models",
    verifiedAt: "2025-02-17",
  },
  {
    id: "xai:grok-3-mini-fast",
    provider: "xai",
    vendorId: "grok-3-mini-fast",
    displayName: "Grok 3 Mini Fast",
    family: "grok-3-mini-fast",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":4},
    pricingSource: "models.dev",
    aliases: ["xai/grok-3-mini-fast"],
    releasedAt: "2025-02-17",
    source: "https://docs.x.ai/docs/models",
    contextSource: "https://docs.x.ai/docs/models",
    verifiedAt: "2025-02-17",
  },
  {
    id: "xai:grok-3-mini-fast-latest",
    provider: "xai",
    vendorId: "grok-3-mini-fast-latest",
    displayName: "Grok 3 Mini Fast Latest",
    family: "grok-3-mini-fast-latest",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":4},
    pricingSource: "models.dev",
    aliases: ["xai/grok-3-mini-fast-latest"],
    releasedAt: "2025-02-17",
    source: "https://docs.x.ai/docs/models",
    contextSource: "https://docs.x.ai/docs/models",
    verifiedAt: "2025-02-17",
  },
  {
    id: "xai:grok-3-mini-latest",
    provider: "xai",
    vendorId: "grok-3-mini-latest",
    displayName: "Grok 3 Mini Latest",
    family: "grok-3-mini-latest",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":8192},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.3,"outputPerMTokens":0.5},
    pricingSource: "models.dev",
    aliases: ["xai/grok-3-mini-latest"],
    releasedAt: "2025-02-17",
    source: "https://docs.x.ai/docs/models",
    contextSource: "https://docs.x.ai/docs/models",
    verifiedAt: "2025-02-17",
  },
  {
    id: "xai:grok-4",
    provider: "xai",
    vendorId: "grok-4",
    displayName: "Grok 4",
    family: "grok-4",
    status: "stable",
    context: {"combinedMax":256000,"outputMax":64000},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":3,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["xai/grok-4"],
    releasedAt: "2025-07-09",
    source: "https://docs.x.ai/docs/models",
    contextSource: "https://docs.x.ai/docs/models",
    verifiedAt: "2025-07-09",
  },
  {
    id: "xai:grok-beta",
    provider: "xai",
    vendorId: "grok-beta",
    displayName: "Grok Beta",
    family: "grok-beta",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":5,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["xai/grok-beta"],
    releasedAt: "2024-11-01",
    source: "https://docs.x.ai/docs/models",
    contextSource: "https://docs.x.ai/docs/models",
    verifiedAt: "2024-11-01",
  },
  {
    id: "xai:grok-vision-beta",
    provider: "xai",
    vendorId: "grok-vision-beta",
    displayName: "Grok Vision Beta",
    family: "grok-vision-beta",
    status: "stable",
    context: {"combinedMax":8192,"outputMax":4096},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":5,"outputPerMTokens":15},
    pricingSource: "models.dev",
    aliases: ["xai/grok-vision-beta"],
    releasedAt: "2024-11-01",
    source: "https://docs.x.ai/docs/models",
    contextSource: "https://docs.x.ai/docs/models",
    verifiedAt: "2024-11-01",
  },
  {
    id: "zai:glm-4.5",
    provider: "zai",
    vendorId: "glm-4.5",
    displayName: "GLM-4.5",
    family: "glm-4.5",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":98304},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":2.2},
    pricingSource: "models.dev",
    aliases: ["zai/glm-4.5"],
    releasedAt: "2025-07-28",
    source: "https://docs.z.ai/guides/overview/pricing",
    contextSource: "https://docs.z.ai/guides/overview/pricing",
    verifiedAt: "2025-07-28",
  },
  {
    id: "zai:glm-4.5-air",
    provider: "zai",
    vendorId: "glm-4.5-air",
    displayName: "GLM-4.5-Air",
    family: "glm-4.5-air",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":98304},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":1.1},
    pricingSource: "models.dev",
    aliases: ["zai/glm-4.5-air"],
    releasedAt: "2025-07-28",
    source: "https://docs.z.ai/guides/overview/pricing",
    contextSource: "https://docs.z.ai/guides/overview/pricing",
    verifiedAt: "2025-07-28",
  },
  {
    id: "zai:glm-4.5-flash",
    provider: "zai",
    vendorId: "glm-4.5-flash",
    displayName: "GLM-4.5-Flash",
    family: "glm-4.5-flash",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":98304},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["zai/glm-4.5-flash"],
    releasedAt: "2025-07-28",
    source: "https://docs.z.ai/guides/overview/pricing",
    contextSource: "https://docs.z.ai/guides/overview/pricing",
    verifiedAt: "2025-07-28",
  },
  {
    id: "zai:glm-4.5v",
    provider: "zai",
    vendorId: "glm-4.5v",
    displayName: "GLM 4.5V",
    family: "glm-4.5v",
    status: "stable",
    context: {"combinedMax":64000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":1.8},
    pricingSource: "models.dev",
    aliases: ["zai/glm-4.5v"],
    releasedAt: "2025-08-11",
    source: "https://docs.z.ai/guides/overview/pricing",
    contextSource: "https://docs.z.ai/guides/overview/pricing",
    verifiedAt: "2025-08-11",
  },
  {
    id: "zhipuai:glm-4.5",
    provider: "zhipuai",
    vendorId: "glm-4.5",
    displayName: "GLM-4.5",
    family: "glm-4.5",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":98304},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":2.2},
    pricingSource: "models.dev",
    aliases: ["zhipuai/glm-4.5"],
    releasedAt: "2025-07-28",
    source: "https://docs.z.ai/guides/overview/pricing",
    contextSource: "https://docs.z.ai/guides/overview/pricing",
    verifiedAt: "2025-07-28",
  },
  {
    id: "zhipuai:glm-4.5-air",
    provider: "zhipuai",
    vendorId: "glm-4.5-air",
    displayName: "GLM-4.5-Air",
    family: "glm-4.5-air",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":98304},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0.2,"outputPerMTokens":1.1},
    pricingSource: "models.dev",
    aliases: ["zhipuai/glm-4.5-air"],
    releasedAt: "2025-07-28",
    source: "https://docs.z.ai/guides/overview/pricing",
    contextSource: "https://docs.z.ai/guides/overview/pricing",
    verifiedAt: "2025-07-28",
  },
  {
    id: "zhipuai:glm-4.5-flash",
    provider: "zhipuai",
    vendorId: "glm-4.5-flash",
    displayName: "GLM-4.5-Flash",
    family: "glm-4.5-flash",
    status: "stable",
    context: {"combinedMax":131072,"outputMax":98304},
    modalities: {"textIn":true,"textOut":true},
    pricing: {"inputPerMTokens":0,"outputPerMTokens":0},
    pricingSource: "models.dev",
    aliases: ["zhipuai/glm-4.5-flash"],
    releasedAt: "2025-07-28",
    source: "https://docs.z.ai/guides/overview/pricing",
    contextSource: "https://docs.z.ai/guides/overview/pricing",
    verifiedAt: "2025-07-28",
  },
  {
    id: "zhipuai:glm-4.5v",
    provider: "zhipuai",
    vendorId: "glm-4.5v",
    displayName: "GLM 4.5V",
    family: "glm-4.5v",
    status: "stable",
    context: {"combinedMax":64000,"outputMax":16384},
    modalities: {"textIn":true,"textOut":true,"imageIn":true},
    pricing: {"inputPerMTokens":0.6,"outputPerMTokens":1.8},
    pricingSource: "models.dev",
    aliases: ["zhipuai/glm-4.5v"],
    releasedAt: "2025-08-11",
    source: "https://docs.z.ai/guides/overview/pricing",
    contextSource: "https://docs.z.ai/guides/overview/pricing",
    verifiedAt: "2025-08-11",
  }
] as const satisfies readonly Model[];

